<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>天青色等烟雨</title>
  
  <subtitle>文不在多、有换则新、人不在挤、有来就行</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="yunke.science/"/>
  <updated>2018-05-17T04:06:45.000Z</updated>
  <id>yunke.science/</id>
  
  <author>
    <name>Young</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>微服务架构的优势</title>
    <link href="yunke.science/2018/05/17/microsrv-advant/"/>
    <id>yunke.science/2018/05/17/microsrv-advant/</id>
    <published>2018-05-17T04:06:06.000Z</published>
    <updated>2018-05-17T04:06:45.000Z</updated>
    
    <content type="html"><![CDATA[<p>微服务是当前互联网产品的一个技术架构趋势，近两年伴随着Docker容器计算的发展和普及,微服务架构在业界逐渐落地,那么驱动企业进行微服务化架构改造的根本推动力是什么?如何在企业内部实施微服务架构?实施微服务契构需要哪些技术框架和基础设施?这些都是企业技术人员需要了解并关心的问题,也是要具体讨论的问题。</p><a id="more"></a><p><strong>微服务作为对应单体应用出现的概念,其架构通常有哪些优势呢?</strong></p><ul><li><p><strong>项目工程简洁</strong>。一个复杂的产品功能集合,代码仓库规模往往随着业务复杂度的增加而线性增加。对于单体应用来说,代码的堆积意味着工程规模的迅速膨胀。而对于微服务来说,因为每个微服务承担的职责小而且单一,所以工程规模简洁可控。</p></li><li><p><strong>升级代价小</strong>。当一个产品所有的功能都集中在同一个应用时,对程序的升级会带来两方面的影响:一是项目工程过大造成的应用启动时间过久,我们见过有些产品一个应用实例的启动时间需要半个小时以上,这对业务来说显然不可行。二是每次hotfix都需要对整个应用重启,引起业务的不稳定,而微服务架构恰恰相反,每个服务独立升级,对业务整体的影响极小。</p></li><li><p><strong>扩展性好</strong>。对于互联网产品来说,产品迭代速度很重要。对于一个庞大的单体应用来说,牵一发而动全身,无论对产品功能的扩展性还是性能的扩展性来说,都是一个很大的挑战。通过微服务化,把业务中扩展性差的部分独立出去,不同的业务类型采用不同扩展方案,可以提升业务整体的可扩展性。</p></li><li><p><strong>稳定性好</strong>。单体应用的稳定性差主要体现在功能间的隔离性,对于单体应用而言,所有的功能都在同一个进程空间里,这意味着任何一个功能的bug可能会造成应用整个崩溃。微服务的好处是可以实现进程级别的隔离,单个服务异常很少会造成全局故障。</p></li><li><p><strong>人员变更影响小</strong>。项目中人员更迭并不少见,单体应用的交接要求被交接人员必须对整个项目非常熟悉,才有可能消化变更人员带来的负面影响,否则人员离职或转岗会影响项目的正常进度。实施微服务架构的团队往往同时也遵循“2 pizza&quot;原则的组织架构,团队小而精,人员变更影响小。</p></li><li><p><strong>技术栈丰富</strong>。单体应用因为都跑在同一个进程里,所以项目的整体技术栈就被这个进程锁死了,比如说一个Java单体应用,无论业界的其他编程语言和开发框架如何发展,我们也无法利用起来,无法实现技术反哺业务。而微服务可以采用一些通用的服务间通信方式(HTTP等)去集成,使得服务的实现方式不局限于某个技术栈，适合用最合适的技术实现功能。</p></li><li><p><strong>开发效率高</strong>。主要体现在为服务架构下项目的学习曲线平滑，因为工程规模小，所以开发人员能很快做到对项目有一个大而全的认识。</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">graph LR</span><br><span class="line">单体应用--&gt;|业务拆分微服务化| 应用1</span><br><span class="line">单体应用--&gt;|业务拆分微服务化| 应用2</span><br><span class="line">单体应用--&gt;|业务拆分微服务化| 应用3</span><br><span class="line">单体应用--&gt;|业务拆分微服务化| 应用4</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;微服务是当前互联网产品的一个技术架构趋势，近两年伴随着Docker容器计算的发展和普及,微服务架构在业界逐渐落地,那么驱动企业进行微服务化架构改造的根本推动力是什么?如何在企业内部实施微服务架构?实施微服务契构需要哪些技术框架和基础设施?这些都是企业技术人员需要了解并关心的问题,也是要具体讨论的问题。&lt;/p&gt;
    
    </summary>
    
      <category term="其他" scheme="yunke.science/categories/%E5%85%B6%E4%BB%96/"/>
    
    
      <category term="架构" scheme="yunke.science/tags/%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>分布式服务架构</title>
    <link href="yunke.science/2018/05/16/architec-distri/"/>
    <id>yunke.science/2018/05/16/architec-distri/</id>
    <published>2018-05-16T05:11:57.000Z</published>
    <updated>2018-05-16T07:08:37.056Z</updated>
    
    <content type="html"><![CDATA[<p>一般而言,企业经过初创期和成长期两个阶段的发展,就基本确定了业务的发展方向,接下来只要面对竞争对手的跟随和大量用户访问请求的问题。这些企业也会提供各种不同的子产品模块功能来满足业务的多样性发展,比如产品会设计不同的产品功能体系,运营人员会设计不同的运营活动,客服人员会接到不同的用户反馈等。</p><a id="more"></a><p><ul class="markdownIt-TOC"><li><a href="#%E4%B8%9A%E5%8A%A1%E9%9C%80%E6%B1%82">业务需求</a></li><li><a href="#%E5%BC%B9%E6%80%A7%E6%89%A9%E5%AE%B9">弹性扩容</a></li><li><a href="#%E6%9C%8D%E5%8A%A1%E5%8C%96">服务化</a></li></ul></p><p>这些需求叠加在一起,会导致整个业务越来越复杂,有些系统变得不再具有维护性,无法满足可用性的需求,只要一出现流量高峰,系统必定宕机,所以很多公司面临重构架构设计,甚至推翻重来,比如京东大部分的用户业务从.NET转到Java语言的重构,淘宝从PHP转到Java,升级2.0,再到3.0的架构转变,可以看到,这个时间点的转型或重构可能不会到生死攸关的地步,但其成本,是非常高的。因此,如何在一开始就能做好这种转变的预见性,对契构设计有相当大的挑战,本节先给出几点供读者来参考。</p><h2><span id="业务需求"> 业务需求</span></h2><p>通过云服务通常可以解决很多架构层面的问题,比如对象存储系统解决了文件分布式存储的问题, CDN解决了静态资源访问的性能问题,但实际上随着业务的不断发展,系统访问压力增大,还可能有很多的请求变慢或者超时,应用服务器或数据库服务的压力波动较大,只要不停地上线新业务,技术债就会越来越明显,业务的迭代也越来越跟不上产品需求。</p><p>为了解决这些问题,企业往往需要进行各种业务的拆分,把不同的功能模块拆分到不同的服务器上进行独立部署。比如用户模块、商品模块、购物车模块、订单模块和支付模块等,这些模块拆分并独立部署出来后,可以再进一步根据系统的瓶领进行细分。但是进行服务拆分之后,各模块之间的依赖又变得明显起来,比如数据库的建接效、数据的分<br>布式事务、数据库的性能开销等都是急切需要解决的问题。</p><p>同时,随着业务模块的拆分,除了上述的技术问题要解决外,还面临着工程实践的问题,比如在业务的不同分支中,需要保证开发人员、测试人员、运维人员快速地对开发环境、则试环境、预发布环境的搭建和发布。在高速发展的企业中迭代的频率非常高,以网易考拉平台为例,所有系统的日发布次数到达数千次,所以技术人员对效率的要求比较高。当扩大到一个公司多个产品线,整体的运行就要求像现代化工厂一样来运作,需要自动化<br>的平台去解决,纯手工根本无法满足企业的高效运转。</p><h2><span id="弹性扩容"> 弹性扩容</span></h2><p>随着需求和用户的不断增长,系统会出现波峰和波谷,为了更好地利用资源和成本预算,弹性扩容成了必要需求,在峰值的时候能够根据业务的压力自动扩容,分担流量,在压力低的时候目动缩容,藏少成本或提高资源的利用率,把缩容的资源做离线业务计算。</p><p>也许在过去是简单地通过垂直扩大规模能力来处理更多的需求,或者是购买更强的服务器,这在一定程度上是可行的,但过程很慢开且代价庞大,通过提前准备过多的资源,会导致只根据峰值使用量预测来规划能力值,比如根据服务器的最高计算能力购买硬件予以满足,这是不得已的做法。例如国外的黑色星期五、国内的双11等活动,当天请求非常高,需要足够的资源来满足业务请求,而平时这些服务器的使用率很低,所以,<strong>只有依赖云的弹性才能满足这种业务场景的需求</strong>。</p><h2><span id="服务化"> 服务化</span></h2><p>不管是互联网还是传统行业转型的企业,基本都是在原有基础业务上发展而来的,不可能把业务停止从零开始,因此,直接对原有系统进行微服务改造比较困难,风险也较大.这时基本上处于一种混合架构期,即新的业务会从头开发,逐步接入到老系统中,一步步替换老系统不满足的地方,通过不断地快速迭代来保证业务的可持续性,同时又保证新业务的快速需求。</p><p>著名的架构大师Martin Fowler从2013年正式提出微服务架构的综述文章。至今,都没有提供统一的最佳实践方案。现在微服务的架构实现方式也各种各样,通常根据应用的类型拆分成不同的微服务来实现,每个服务根据业务的特征采用不同的技术栈进行组合,把每个服务划分成可以独立部署的隔离进程来运行。目前,微服务的基本框架都类似,比如包括服务发现、降级、治理等方面。业务实现微服务的技术细节各不相同,没有统一的实现方案,比如服务发现有自建服务基础设施的,也有依赖第三方开源的,技术人员需要根据自己的场景来做选择。简化的架构模型如图所示。</p><img src="/2018/05/16/architec-distri/Distribute-Service-Architecture.png" title="Distribute-Service-Architecture"><hr><p>显然,这个架构模型只是整个业务服务架构的一部分,实际的系统可能要复杂几十倍。如果业务的迭代速度非常快,同时每个业务之间的依赖从设计、开发、测试、上线到运维都是一个非常庞大的复杂工程,因此,如何高效管理所依赖的服务和系统依赖,诊断并及时对业务反馈响应是对服务架构的考验。</p><p><strong>架构演化发展历程：</strong></p><ol><li><a href="/2018/05/16/architec-initial/">初创期架构</a></li><li><a href="/2018/05/16/architec-growth/">快速成长期架构</a></li><li><a href="/2018/05/16/architec-distri/">分布式服务架构</a></li></ol><p>参考：</p><ol><li>云原生应用架构实践 （网易云基础服务架构团队 著）</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;一般而言,企业经过初创期和成长期两个阶段的发展,就基本确定了业务的发展方向,接下来只要面对竞争对手的跟随和大量用户访问请求的问题。这些企业也会提供各种不同的子产品模块功能来满足业务的多样性发展,比如产品会设计不同的产品功能体系,运营人员会设计不同的运营活动,客服人员会接到不同的用户反馈等。&lt;/p&gt;
    
    </summary>
    
      <category term="其他" scheme="yunke.science/categories/%E5%85%B6%E4%BB%96/"/>
    
    
      <category term="架构" scheme="yunke.science/tags/%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>快速成长期架构</title>
    <link href="yunke.science/2018/05/16/architec-growth/"/>
    <id>yunke.science/2018/05/16/architec-growth/</id>
    <published>2018-05-16T05:08:29.000Z</published>
    <updated>2018-05-16T07:08:40.820Z</updated>
    
    <content type="html"><![CDATA[<p>初创公司随着业务的进一步发展,当DAU达到十万的时候,通常是最关键的时刻,既要保证业务的稳定运行,又要进行产品的快速迭代。到了这个阶段,由于业务模式得到了一定的验证和反馈,有可能会出现很多竞品或友商。一方面,随着风险资本的注入,会依赖更有质量的数据进行发展运营,另一方面,竞品的出现又导致了市场的加速前进.因此,能否在这个阶段保证业务与技术的和谐发展,是考验架构是否足够灵活的指标之一,本节主要说明几点。</p><a id="more"></a><p><ul class="markdownIt-TOC"><li><a href="#%E5%89%8D%E7%AB%AF%E5%8A%A0%E9%80%9F%E4%BC%98%E5%8C%96">前端加速优化</a></li><li><a href="#%E6%B0%B4%E5%B9%B3%E6%89%A9%E5%B1%95">水平扩展</a></li><li><a href="#%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8F%8A%E7%BC%93%E5%AD%98%E4%BC%98%E5%8C%96">数据库及缓存优化</a></li></ul></p><h2><span id="前端加速优化"> 前端加速优化</span></h2><p>首先基于浏览器端应用或者移动端应用,随着请求的不断增加,偶尔会看到Web服务出现性能瓶颈导致请求变慢或者失败,除去服务器本身的配置低外,更有可能由于架构设计或分离的原因,大量的Web并发请求被堵塞或者变慢,原因无非是服务器的CPU、磁盘、IO、带宽竞争激烈,导致相互影响,这时候我们就需要对架构进行前后端分解,合理配置或转发请求。</p><p>如果是前端的服务请求来不及处理或者有瓶颈,可以将图片、Js、 CSS、 HTML及应用服务相关的静态资源文件存储通过Nginx本地代理或者对象存储服务来进行物理加速,使用不同的域名来转发请求,并通过CDN将静态资源分布式缓存在各个节点实现“就近访问&quot;,主动或被动刷新CDN的缓存来加速前端服务。</p><p>如果是后端的动态请求压力过大或者有热点服务,可以把无状态的后端的服务再进一步水平扩展满足业务分担,有状态需要判断是否能通过垂直扩容来服务,否则只能进行代码、架构设计或者业务规划的调整来优化。</p><p>一般而言,通过将动态请求、静态请求的访问分离(“动静分离”),能有效解决服务器在CPU、磁盘IO、带宽方面的访问压力。当然,这需要在架构设计时采用一些方法来进行调整。</p><h2><span id="水平扩展"> 水平扩展</span></h2><p>上面提到垂直扩容能解决部分的问题,但由于业务和流量的快速增长及垂直资源有限,不同的应用场景需要依赖不同的策略分流,比如长连接的应用会依赖于4层的网络连接,互联网应用通常采用7层的模式来完成,甚至在游戏场景中,依赖UDP进行通信。</p><p>为了更多地分担服务器的压力和保证业务的高可用,负载均衡技术通常是这个阶段解决问题的一个方法,通过增加多台后端服务器就可以实现分流的功能,分流设计也面临很多原则与技巧,比如分流的路径、权重等。负戴均衡承担的角色也决定了后端的应用架构,比如无状态化设计才能实现水平扩展,另外还要考虑业务是否有亲缘性,同时在后端服务出现异常的情况下, 自动进行健康检查,异常的服务能及时进行下线操作,快速失败。</p><h2><span id="数据库及缓存优化"> 数据库及缓存优化</span></h2><p>数据库和缓存配合使用是解决后端结构化数据与非结构化问题的有效手段,根据不同的场景,要明白哪种数据使用结构化数据合适,哪种数据使用非结构化数据更合适,以及哪种方式在保证性能较好的情况下成本又可以接受。</p><p>同时,如何在数据库和缓存之间进行过渡也是需要考虑的,比如数据在更新的时候,如何保证缓存的一致性,如何保证热点数据一直被访问,提高缓存的命中率等。另外,当大量用户访问不存在的数据时,也有可能导致后端的压力非常大,甚至有可能造成雪崩效应。</p><p>每种服务独立承担对应的功能,各司其职,并且根据应用的特性区别提供不同的服务能力,比如应用服务器提供用户的接入服务,数据库服务专门承担结构化数据的存储,缓存承担或非结构化数据(KV键值对)的存储等,如果要提供搜索的功能,还需将数据进行分词、索引、检索等,不同服务器根据业务的功用需求来提供对应的服务。</p><hr><p>在这个阶段,除了必须保证满足业务的功能型需求,还要更多考虑非功能性需求。比如,通过前端负载均衡提供业务分流的能力,根据用户的特征进行不同的流量转发;数据库提供主备的能力,两者之间通过数据同步进行数据备份,当主数据库发生故障后,应用可以自动切换到备份的服务器来为用户提供服务;在用户体验方面,可能会引入缓存、CDN等基础服务来提供性能加速。</p><p><strong>架构演化发展历程：</strong></p><ol><li><a href="/2018/05/16/architec-initial/">初创期架构</a></li><li><a href="/2018/05/16/architec-growth/">快速成长期架构</a></li><li><a href="/2018/05/16/architec-distri/">分布式服务架构</a></li></ol><p>参考：</p><ol><li>云原生应用架构实践 （网易云基础服务架构团队 著）</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;初创公司随着业务的进一步发展,当DAU达到十万的时候,通常是最关键的时刻,既要保证业务的稳定运行,又要进行产品的快速迭代。到了这个阶段,由于业务模式得到了一定的验证和反馈,有可能会出现很多竞品或友商。一方面,随着风险资本的注入,会依赖更有质量的数据进行发展运营,另一方面,竞品的出现又导致了市场的加速前进.因此,能否在这个阶段保证业务与技术的和谐发展,是考验架构是否足够灵活的指标之一,本节主要说明几点。&lt;/p&gt;
    
    </summary>
    
      <category term="其他" scheme="yunke.science/categories/%E5%85%B6%E4%BB%96/"/>
    
    
      <category term="架构" scheme="yunke.science/tags/%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>初创期架构</title>
    <link href="yunke.science/2018/05/16/architec-initial/"/>
    <id>yunke.science/2018/05/16/architec-initial/</id>
    <published>2018-05-16T04:28:03.000Z</published>
    <updated>2018-05-16T07:08:45.615Z</updated>
    
    <content type="html"><![CDATA[<p>创业公司在开始新业务的时期,基本处在试错或原型验证阶段,这个阶段更多是关注业务的本身是否有前景或商业模式,而不会把非常多的精力放在技术的系统架构上,尤其是对于非技术型或不确定型的项目立项阶段。尽管很多技术人员也预料到前期需要很多时间去好好设计系统,才能保证支撑后续可能的业务快速发展,但往往由于时间成本或人力等原因而无法很好地执行。</p><a id="more"></a><p><ul class="markdownIt-TOC"><li><a href="#%E5%8D%95%E4%BD%93%E6%9E%B6%E6%9E%84">单体架构</a></li><li><a href="#%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%88%86%E7%A6%BB">服务器分离</a></li><li><a href="#%E4%B8%9A%E5%8A%A1%E6%A8%A1%E5%9E%8B">业务模型</a></li></ul></p><p>一般来讲,创业型的项目对时间的要求非常苛刻,需要在3到6个月时间内完成系统的上线,否则有可能由于业务无法快速上线验证,导致无法获取相关的原始数据进行下<br>个目标验证,更严重的有可能造成资金链的断裂。罗马不是一天建成的,因此这个阶段会使用相对简单的架构方式来进行设计,本节先从最主要的几点进行说明.</p><h2><span id="单体架构"> 单体架构</span></h2><p>对于创业型公司来说,由于人才、技术、资金等重要因素的影响,同时,技术人员为了配合产品的需求,会采用最简单的架构来完成最原始阶段开发,根据我们接触的不少用户反馈,有些企业考虑成本因素,甚至只使用一台服务器或者容器服务。另外,传统官网、论坛等应用,由于早期的设计采用了单体架构来实现,只需要一台服务器或容器来服务即可。对于其他的应用服务器、数据库、静态文件等资源,也是部署到同一台服务器或容器上来服务。最简单的架构模型如图所示。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">graph LR</span><br><span class="line">PHP--&gt;Apache</span><br><span class="line">Apache--&gt;Mysql</span><br></pre></td></tr></table></figure><p>对于早期的单体应用,应用服务+数据库服务基本上就组成了最原始的架构模型,技术人更多会考虑技术的选型,包括编程语言、版本管理、数据库的类型等。比如PHP的开发者选择PHP-MySQL, Java的开发者采用Tomcat-MySOL等开发方式。</p><h2><span id="服务器分离"> 服务器分离</span></h2><p>根据线上运行经验,一般的业务的类型,如果每日的用户访问量在百万级别以内,只要进行简单的Web应用性能参数调优、数据库索引优化等,基本上就能保证服务的稳定运行,当然,随着访问量的不断增加,部署在同一台服务器上的应用及数据库服务,会造成服务器的CPU/内存/磁盘/带宽等系统资源竞争,从而相互影响,显然很容易出现性能瓶颈,如果这台服务器出现了宕机或无法恢复的错误,就有可能导致全站不可访问或者数据丢失等情况,后果非常严重,因此大部分产品会将Web应用服务器和数据库服务器进行物理分离,独立部署,相互热备提供服务,只需要增加很少的成本,就能解决对应性能和数据的可靠性等问题.</p><p>初期由于各种条件存在不能很好地进行新项目前景的预见,技术人员如果能在最小成本的情况下保证架构的合理性,还能很好地服务产品功能需求,甚至只要在部署架构上稍做调整,就可以防止出现灾难性的问题,这其中也包括很多技术架构上的考虑。</p><h2><span id="业务模型"> 业务模型</span></h2><p>一般而言,现阶段的业务比较简单,产品也比较单一,业务会随时根据其运营数据进行调整,因此,这时需要技术人能够较好地把不同的模块分离出来,对于偏业务相关的功能,需要有较好的心态接收随时变化的不确定性,对于后续可能复用或大量依赖的工程,需要进行较好的设计,否则可能在业务爆发时导致业务开发的进度越来越慢,甚至阻碍业务的发展,造成业务时常中断,即使有人力或时间来对系统进行重新设计,也会令技术人员产生抵触心理,同时也会引入较高的风险,因此,基于云原生应用的设计模式在最基础的阶段对架构也有很大的作用,包括考虑如何使用云的弹性,将不可变优势融合到系统的设计中,合理的业务模型分界也是确保后续能发展的重要步骤之一。</p><hr><p>总而言之,在早期项目原型验证或者快速试错阶段,采用单体架构具有很大的技术优势,产品的想法也在项目的初始阶段就能进行比较好的迭代开发,发布和部署也比较灵活。然而,随着业务的增长,如果架构还是一成不变的话,带来的技术风险就越来越高.<br>比如,代码行数的增加影响技术人员的学习成本、业务的变更速度、业务的可靠性、安全性及工程变大后的发布效率等,每次修改都必须反复测试,否则全站随时可能不可用,导致业务中断或者丢失市场的机会,因此,这部分的技术债务必须在业务快速发展的同时,进行技术架构的改造,使其能保证后期业务的支撑,所以,除了业务的发展判断外,对开发人员的技术能力储备和架构远见判断也将成为考虑的事情之一.</p><p><strong>架构演化发展历程：</strong></p><ol><li><a href="/2018/05/16/architec-initial/">初创期架构</a></li><li><a href="/2018/05/16/architec-growth/">快速成长期架构</a></li><li><a href="/2018/05/16/architec-distri/">分布式服务架构</a></li></ol><p>参考：</p><ol><li>云原生应用架构实践 （网易云基础服务架构团队 著）</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;创业公司在开始新业务的时期,基本处在试错或原型验证阶段,这个阶段更多是关注业务的本身是否有前景或商业模式,而不会把非常多的精力放在技术的系统架构上,尤其是对于非技术型或不确定型的项目立项阶段。尽管很多技术人员也预料到前期需要很多时间去好好设计系统,才能保证支撑后续可能的业务快速发展,但往往由于时间成本或人力等原因而无法很好地执行。&lt;/p&gt;
    
    </summary>
    
      <category term="其他" scheme="yunke.science/categories/%E5%85%B6%E4%BB%96/"/>
    
    
      <category term="架构" scheme="yunke.science/tags/%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>filebeat 5.+ 与 6.+ 版本的主要更改</title>
    <link href="yunke.science/2018/05/04/beats56changelog/"/>
    <id>yunke.science/2018/05/04/beats56changelog/</id>
    <published>2018-05-04T07:56:52.000Z</published>
    <updated>2018-05-04T07:59:12.000Z</updated>
    
    <content type="html"><![CDATA[<p>本节讨论如果将Beats从版本5.x升级到6.x时应注意的主要更改.</p><a id="more"></a><p><ul class="markdownIt-TOC"><li><a href="#spooler-%E7%BB%84%E4%BB%B6%E5%88%A0%E9%99%A4">Spooler 组件删除</a></li><li><a href="#%E5%8F%AA%E8%83%BD%E5%90%AF%E7%94%A8%E4%B8%80%E4%B8%AA%E8%BE%93%E5%87%BA">只能启用一个输出</a></li><li><a href="#logstash%E7%B4%A2%E5%BC%95%E8%AE%BE%E7%BD%AE%E7%8E%B0%E5%9C%A8%E9%9C%80%E8%A6%81%E7%89%88%E6%9C%AC">Logstash索引设置现在需要版本</a></li><li><a href="#filebeat-prospector-%E7%B1%BB%E5%9E%8B-%E5%92%8C-document-%E7%B1%BB%E5%9E%8B-%E7%9A%84%E6%94%B9%E5%8F%98">Filebeat prospector 类型 和 document 类型 的改变</a></li><li><a href="#%E5%9C%A8%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E4%B8%AD%E7%A6%81%E7%94%A8filebeat%E9%BB%98%E8%AE%A4%E6%8E%A2%E5%8B%98%E5%99%A8">在配置文件中禁用Filebeat默认探勘器</a></li><li><a href="#%E5%85%B6%E4%BB%96%E6%9B%B4%E6%96%B0%E7%9A%84%E8%AE%BE%E7%BD%AE">其他更新的设置</a></li><li><a href="#%E5%AF%BC%E5%85%A5kibana%E4%BB%AA%E8%A1%A8%E6%9D%BF%E7%9A%84%E6%9B%B4%E6%94%B9">导入Kibana仪表板的更改</a></li><li><a href="#metricbeat%E8%BF%87%E6%BB%A4%E5%99%A8%E9%87%8D%E5%91%BD%E5%90%8D%E4%B8%BA%E5%A4%84%E7%90%86%E5%99%A8">Metricbeat过滤器重命名为处理器</a></li><li><a href="#%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%87%E4%BB%B6%E6%98%AF%E9%92%88%E5%AF%B9libc%E5%8A%A8%E6%80%81%E7%BC%96%E8%AF%91%E7%9A%84">二进制文件是针对libc动态编译的</a></li></ul></p><p><a href="https://www.elastic.co/guide/en/beats/libbeat/master/breaking-changes-6.0.html" target="_blank" rel="noopener">Beats Platform Reference [master] » Breaking changes » Breaking changes in 6.0</a></p><h2><span id="spooler-组件删除"> Spooler 组件删除</span></h2><p><a href="https://www.elastic.co/guide/en/beats/libbeat/master/breaking-changes-6.0.html#breaking-changes-spooler-removed" target="_blank" rel="noopener">filebeat spooler removed</a></p><p>6.0版本为所有Beats的内部管道提供了一种新的体系结构。这种架构重构主要是内部的，但更明显的效果之一是Filebeat的Spooler组件被删除</p><ul><li><code>filebeat.spool_size</code></li><li><code>filebeat.publish_as</code></li><li><code>filebeat.idle_timeo</code></li><li><code>queue_size</code></li><li><code>bulk_queue_size</code></li></ul><p>前三个特定于<code>Filebeat</code>，而<code>queue_size</code>和<code>bulk_queue_size</code>存在于所有<code>Beats</code>中。如果设置了这些选项中的任何一个，<code>Filebeat 6.0+</code>将拒绝启动。</p><p>引入queue.mem设置，而不是上面的设置。如果您之前必须调整spool_size或queue_size，则可能需要在升级时调整queue.mem.events。但是，最好将queue.mem的其余部分保留为默认值，因为它们适用于所有负载。</p><p>publish_async选项（从5.3开始不推荐使用）被删除，因为新管道默认已经异步工作。</p><h2><span id="只能启用一个输出"> 只能启用一个输出</span></h2><p>6.0之前，您可以同时启用多个输出，但仅限于不同的类型。例如，您可以启用Elasticsearch和Logstash输出，但不能启用两个Logstash输出。</p><p>6.0+删除了同时启用多个输出的选项。这有助于简化管道并明确Beats中输出的范围。</p><p>如果您需要多个输出，您有以下选择：</p><ul><li>使用Logstash输出，然后使用Logstash将事件传送到多个输出</li><li>同一节点运行多个实例</li><li>如果您使用 <code>file or console</code> 输出进行调试，除了主输出之外，我们还建议使用<code>-d &quot;publish&quot;</code>选项，将发布的事件记录在Filebeat日志中。</li></ul><h2><span id="logstash索引设置现在需要版本"> Logstash索引设置现在需要版本</span></h2><p>如果使用 <code>Logstash output</code> 将数据从<code>Beats</code>发送到<code>Logstash</code>，则需要更新<code>Logstash</code>配置中的索引设置以包含<code>Beat</code>版本：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">output &#123;</span><br><span class="line">  elasticsearch &#123;</span><br><span class="line">    hosts =&gt; &quot;localhost:9200&quot;</span><br><span class="line">    manage_template =&gt; false</span><br><span class="line">    index =&gt; &quot;%&#123;[@metadata][beat]&#125;-%&#123;[@metadata][version]&#125;-%&#123;+YYYY.MM.dd&#125;&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在6.0之前，推荐的设置是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">index =&gt; &quot;%&#123;[@metadata][beat]&#125;-%&#123;+YYYY.MM.dd&#125;&quot;</span><br></pre></td></tr></table></figure><p>6.0的索引模板应用于与模式 <code>[beat]-[version]-*</code> 匹配的新索引。 您必须更新您的<code>Logstash</code>配置，否则模板将不会被应用。</p><h2><span id="filebeat-prospector-类型-和-document-类型-的改变"> Filebeat prospector 类型 和 document 类型 的改变</span></h2><p><a href="https://www.elastic.co/guide/en/beats/libbeat/master/breaking-changes-6.0.html#breaking-changes-types" target="_blank" rel="noopener">Filebeat prospector type and document type changes</a></p><p>来自 <code>prospector</code> 配置的 <code>document_type</code> 设置已被删除，因为<code>_type</code>概念正在从<code>Elasticsearch</code>中移除。 您可以使用自定义字段，而不是<code>document_type</code>设置。</p><p>这也导致了将<code>input_type</code> 重命名为<code>type</code>。 这种改变是向后兼容的，因为旧的设置仍然有效。 但是，<code>input_type</code>输出字段已重命名为<code>prospector.type</code> 。</p><h2><span id="在配置文件中禁用filebeat默认探勘器"> 在配置文件中禁用Filebeat默认探勘器</span></h2><p>Filebeat的默认启动行为（基于包含的示例配置）是读取所有匹配 <code>/var/log/*.log</code> 模式的文件。</p><p>从版本6.0开始，Filebeat不会以默认配置读取任何文件。 但是，您可以轻松启用系统模块，例如使用CLI标志：</p><p><code>filebeat --modules = system</code></p><h2><span id="其他更新的设置"> 其他更新的设置</span></h2><p><code>outputs.elasticsearch.template.*</code> 移动到 <code>setup.template.*</code> 下面，其他保持不变。</p><p><code>dashboards.*</code> 移动到 <code>setup.dashboards.*</code> 下面，其他保持不变。</p><p>Filebeat 移除选项 <code>force_close_files</code> 和 <code>close_older</code> 。</p><h2><span id="导入kibana仪表板的更改"> 导入Kibana仪表板的更改</span></h2><p>用于在先前版本的Beats中加载Kibana仪表板的import_dashboards程序已由setup命令替换。 例如，以下命令：<br><code>./scripts/import_dashboards -user elastic -pass YOUR_PASSWORD</code><br>由以下命令代替：<br><code>./filebeat setup -E &quot;output.elasticsearch.username=elastic&quot; -E &quot;output.elasticsearch.password=YOUR_PASSWORD&quot;</code></p><p>请注意，只有在配置文件中尚未配置Elasticsearch输出的情况下才需要 <code>-E</code> 标志。</p><p>除了命令的更改之外，请注意，加载Kibana仪表板在6.0版本的堆栈中工作方式不同。 在6.0之前，仪表板被直接插入到.kibana Elasticsearch索引中。 从6.0开始，Beats使用Kibana服务器API。 这意味着加载仪表板的Beat需要直接访问Kibana，并且需要设置Kibana URL。 设置Kibana URL的选项是<code>setup.kibana.host</code>，您可以在配置文件中或通过<code>-E CLI</code>标志设置该选项：</p><p><code>./filebeat setup -E &quot;setup.kibana.host=http://kibana-host:5601&quot;</code></p><p>Kibana主机的默认值是 <code>localhost:5601</code>。</p><h2><span id="metricbeat过滤器重命名为处理器"> Metricbeat过滤器重命名为处理器</span></h2><p>在本模块级配置的“本地”处理器过去在Metricbeat中称为过滤器，但它们提供与全局处理器相似的功能。 两者之间的显着区别在于筛选器相对于度量标准集（例如，<code>mount_point</code>）访问字段，而处理器则以其全限定名称（例如<code>system.filesystem.mount_point</code>）引用字段。</p><p>从版本6.0开始，筛选器将重命名为处理器，并且只能使用完全限定名称访问这些字段。</p><h2><span id="二进制文件是针对libc动态编译的"> 二进制文件是针对libc动态编译的</span></h2><p>在6.0之前，使用Cgo编译<code>Metricbeat</code> 和 <code>Packetbeat</code>，而使用纯<code>Go</code>编译器编译<code>Filebeat</code>，<code>Winlogbeat</code>和<code>Heartbeat</code>。 编译Cgo的一个优势是libc是动态编译的。</p><p>从6.0开始，所有Beats都使用Cgo进行编译，因此可以针对libc进行动态编译。 这可以降低二进制文件的可移植性，但是所有受支持的平台都不受影响。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本节讨论如果将Beats从版本5.x升级到6.x时应注意的主要更改.&lt;/p&gt;
    
    </summary>
    
      <category term="elk" scheme="yunke.science/categories/elk/"/>
    
    
      <category term="elk" scheme="yunke.science/tags/elk/"/>
    
  </entry>
  
  <entry>
    <title>大规模Elasticsearch集群优化管理</title>
    <link href="yunke.science/2018/05/04/elk6-optimize/"/>
    <id>yunke.science/2018/05/04/elk6-optimize/</id>
    <published>2018-05-04T07:49:33.000Z</published>
    <updated>2018-05-04T07:52:14.000Z</updated>
    
    <content type="html"><![CDATA[<p>简单的优化，让集群发挥更大的效率。</p><a id="more"></a><p><ul class="markdownIt-TOC"><li><a href="#%E5%AE%89%E8%A3%85">安装</a></li><li><a href="#%E7%AE%A1%E7%90%86">管理</a><ul><li><a href="#%E5%AF%B9es%E7%9A%84%E7%BB%93%E7%82%B9%E5%81%9A%E8%A7%92%E8%89%B2%E5%88%92%E5%88%86%E5%92%8C%E9%9A%94%E7%A6%BB">对ES的结点做角色划分和隔离</a></li><li><a href="#%E9%81%BF%E5%85%8D%E8%BF%87%E9%AB%98%E7%9A%84%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6shard%E6%95%B0%E9%87%8F%E5%92%8Cthreadpool%E7%9A%84%E6%95%B0%E9%87%8F">避免过高的并发，控制shard数量和threadpool的数量</a></li><li><a href="#%E5%86%B7%E7%83%AD%E6%95%B0%E6%8D%AE%E6%9C%80%E5%A5%BD%E5%81%9A%E5%88%86%E7%A6%BB">冷热数据最好做分离</a></li><li><a href="#%E4%B8%8D%E5%90%8C%E6%95%B0%E6%8D%AE%E9%87%8F%E7%BA%A7%E7%9A%84shard%E6%9C%80%E5%A5%BD%E9%9A%94%E7%A6%BB%E5%88%B0%E4%B8%8D%E5%90%8C%E7%BB%84%E5%88%AB%E7%9A%84%E7%BB%93%E7%82%B9">不同数据量级的shard最好隔离到不同组别的结点</a></li><li><a href="#%E5%AF%B9%E7%B4%A2%E5%BC%95%E7%9A%84%E4%B8%80%E4%BA%9B%E6%93%8D%E4%BD%9C">对索引的一些操作</a><ul><li><a href="#%E5%88%A0%E9%99%A4%E4%B8%8D%E7%94%A8%E7%9A%84%E7%B4%A2%E5%BC%95">删除不用的索引</a></li><li><a href="#%E5%85%B3%E9%97%AD%E7%B4%A2%E5%BC%95-%E6%96%87%E4%BB%B6%E4%BB%8D%E7%84%B6%E5%AD%98%E5%9C%A8%E4%BA%8E%E7%A3%81%E7%9B%98%E5%8F%AA%E6%98%AF%E9%87%8A%E6%94%BE%E6%8E%89%E5%86%85%E5%AD%98-%E9%9C%80%E8%A6%81%E7%9A%84%E6%97%B6%E5%80%99%E5%8F%AF%E4%BB%A5%E9%87%8D%E6%96%B0%E6%89%93%E5%BC%80">关闭索引 （文件仍然存在于磁盘，只是释放掉内存）。需要的时候可以重新打开。</a></li><li><a href="#%E5%AE%9A%E6%9C%9F%E5%81%9A%E7%B4%A2%E5%BC%95%E7%9A%84force-merge">定期做索引的force merge</a></li></ul></li><li><a href="#%E5%BD%93%E8%8A%82%E7%82%B9%E7%A6%BB%E5%BC%80%E6%97%B6%E5%BB%B6%E8%BF%9F%E5%88%86%E9%85%8D">当节点离开时延迟分配</a></li></ul></li><li><a href="#%E7%9B%91%E6%8E%A7">监控</a></li></ul></p><h2><span id="安装"> 安装</span></h2><ol><li><p>从一开始，哪怕就只有几个node，就应该使用分布式配置管理工具来做集群的部署。随着应用的成熟，集群规模的逐步扩大，效率的提升会凸显。 官方提供了 <a href="https://github.com/elastic/puppet-elasticsearch" target="_blank" rel="noopener">puppet-elasticsearch</a> 和 Chef <a href="https://github.com/elastic/cookbook-elasticsearch" target="_blank" rel="noopener">cookbook-elasticsearch</a> ，熟悉这两个工具的同学可以直接拿过来用。用熟这类工具，对于集群的初始部署，配置批量更改，集群版本升级，重启故障结点都会快捷和安全许多。</p></li><li><p>第二个必备利器就是sense插件。通过这个插件直接调用集群的restful API，在做集群和索引的状态查看，索引配置更改的时候非常方便。语法提示和自动补全功能更是实用，减少了翻看文档的频率。在Kibana5里面，sense已经成为一个内置的控制台，无需额外安装。</p></li></ol><h2><span id="管理"> 管理</span></h2><h3><span id="对es的结点做角色划分和隔离"> 对ES的结点做角色划分和隔离</span></h3><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-node.html" target="_blank" rel="noopener">Elasticsearch Reference  » Modules » Node</a></p><p>默认情况下，每个节点都有成为主节点的资格，也会存储数据，还会处理客户端的请求。 这对于小型群集非常方便，但随着群集的增长，考虑将专用主节点从专用数据节点中分离出来非常重要。</p><p>对于一个规模较大，用户较多的集群，master和client在一些极端使用情况下可能会有性能瓶颈甚至内存溢出，从而使得共存的data node故障。data node的故障恢复涉及到数据的迁移，对集群资源有一定消耗，容易造成数据写入延迟或者查询减慢。如果将master和client独立出来，一旦出现问题，重启后几乎是瞬间就恢复的，对用户几乎没有任何影响。另外将这些角色独立出来的以后，也将对应的计算资源消耗从data node剥离出来，更容易掌握data node资源消耗与写入量和查询量之间的联系，便于做容量管理和规划。</p><p>所有节点都知道群集中的所有其他节点，并且可以将客户端请求转发到适当的节点。 除此之外，每个节点都有一个或多个目的：</p><ul><li>具有master资格的节点<br><code>node.master</code>设置为<code>true</code> （默认）的节点，这使得它有资格被选为控制集群的主节点 。</li><li>数据节点<br><code>node.data</code>设置为<code>true</code>节点（默认）。 数据节点保存数据并执行数据相关的操作，如CRUD，搜索和聚合。</li><li>数据提取节点,client节点<br><code>node.ingest</code>设置为<code>true</code>节点（默认）。 摄取节点可以执行由一个或多个摄取处理器组成的预处理流水线。 根据摄取处理器执行的操作类型和所需资源，具有专用摄入节点可能是有意义的，它只会执行此特定任务。负责处理用户请求，实现请求转发，负载均衡等功能。</li><li>多个集群查询请求分发节点<br>通过<code>tribe.*</code>设置配置的集群节点是一种特殊类型的协调节点，可以连接到多个群集并在所有连接的群集中执行搜索和其他操作。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">通过将对应的参数设置为 true ，来启用某个功能  </span><br><span class="line">node.master: true </span><br><span class="line">node.data: false </span><br><span class="line">node.ingest: false </span><br><span class="line">search.remote.connect: false </span><br><span class="line"></span><br><span class="line">node.master 角色默认启用。</span><br><span class="line">禁用 node.data 角色（默认情况下启用）。</span><br><span class="line">禁用 node.ingest 角色（默认情况下启用）。</span><br><span class="line">禁用跨群集搜索（默认启用）。</span><br></pre></td></tr></table></figure><h3><span id="避免过高的并发控制shard数量和threadpool的数量"> 避免过高的并发，控制shard数量和threadpool的数量</span></h3><p>在写入量和查询性能能够满足的前提下，为索引分配尽量少的分片。</p><p>分片过多会带来诸多负面影响，例如：每次查询后需要汇总排序的数据更多；过多的并发带来的线程切换造成过多的CPU损耗；索引的删除和配置更新更慢Issue#18776;<br>过多的shard也带来更多小的segment，而过多的小segment会带来非常显著的heap内存消耗，特别是如果查询线程配置得很多的情况下。</p><p>配置过大的threadpool更是会产生很多诡异的性能问题Issue#18161里所描述的问题就是我们所经历过的。 默认的Theadpool大小一般来说工作得很不错了。</p><h3><span id="冷热数据最好做分离"> 冷热数据最好做分离</span></h3><p>对于日志型应用来说，一般是每天建立一个新索引，当天的热索引在写入的同时也会有较多的查询。如果上面还存有比较长时间之前的冷数据，那么当用户做大跨度的历史数据查询的时候，过多的磁盘IO和CPU消耗很容易拖慢写入，造成数据的延迟。</p><p>所以我们用了一部分机器来做冷数据的存储，利用ES可以给结点配置自定义属性的功能，为冷结点加上&quot;boxtype&quot;:&quot;weak&quot;的标识，每晚通过维护脚本更新冷数据的索引路由设置index.routing.allocation.{require|include|exclude}，让数据自动向冷结点迁移。</p><p>冷数据的特性是不再写入，用户查的频率较低，但量级可能很大。比如我们有个索引每天2TB，并且用户要求保持过去90天数据随时可查。保持这么大量的索引为open状态，并非只消耗磁盘空间。ES为了快速访问磁盘上的索引文件，需要在内存里驻留一些数据(索引文件的索引)，也就是所谓的segment memory。</p><p>稍微熟悉ES的同学知道，JVM heap分配不能超过32GB，对于我们128GB RAM, 48TB磁盘空间的机器而言，如果只跑一个ES实例，只能利用到32GB不到的heap，当heap快用饱和的时候，磁盘上保存的索引文件还不到10TB，这样显然是不经济的。 因此我们决定在冷结点上跑3个ES实例，每个分配31GB heap空间，从而可以在一台物理服务器上存储30多TB的索引数据并保持open状态，供用户随时搜索。 实际使用下来，由于冷数据搜索频率不高，也没有写入，即时只剩余35GB内存给os做文件系统缓存，查询性能还是可以满足需求的。</p><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/shard-allocation-filtering.html" target="_blank" rel="noopener">索引分片分配过滤</a><br>碎片分配过滤允许您指定允许哪些节点托管特定索引的碎片。</p><p>在启动时可以为每个节点分配任意的元数据属性。 例如，可以为节点分配一个rack和一个size属性，如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># elasticsearch.yml</span><br><span class="line">node.attr.rack: rack1</span><br><span class="line">node.attr.size: big</span><br></pre></td></tr></table></figure><p>这些元数据属性可以与<code>index.routing.allocation.*</code>设置一起使用，以将索引分配给特定的一组节点。   例如，我们可以将索引test移动到big或medium节点，如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">PUT test/_settings</span><br><span class="line">&#123;</span><br><span class="line">  &quot;index.routing.allocation.include.size&quot;: &quot;big,medium&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>或者，我们可以使用exclude规则将索引test 从 small节点移开：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">PUT test/_settings</span><br><span class="line">&#123;</span><br><span class="line">  &quot;index.routing.allocation.exclude.size&quot;: &quot;small&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以指定多个规则，在这种情况下必须满足所有条件。 例如，我们可以使用以下命令将索引test移动到rack1 big节点上：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">PUT test/_settings</span><br><span class="line">&#123;</span><br><span class="line">  &quot;index.routing.allocation.include.size&quot;: &quot;big&quot;,</span><br><span class="line">  &quot;index.routing.allocation.include.rack&quot;: &quot;rack1&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><em>如果某些条件不能满足，则碎片不会被移动。</em><br>以下设置是动态的 ，允许将活动索引从一组节点移动到另一组节点：</p><ul><li><code>index.routing.allocation.include.{attribute}</code> 将索引分配给<code>{attribute}</code>至少有一个逗号分隔值的节点。</li><li><code>index.routing.allocation.require.{attribute}</code> 将索引分配给<code>{attribute}</code>具有所有逗号分隔值的节点。</li><li><code>index.routing.allocation.exclude.{attribute}</code> 将索引分配给<code>{attribute}</code>包含任何逗号分隔值的节点。</li></ul><p>这些特殊属性也受支持：</p><table><thead><tr><th>attr</th><th>说明</th></tr></thead><tbody><tr><td><code>_name</code></td><td>按节点名称匹配节点</td></tr><tr><td><code>_host_ip</code></td><td>通过主机IP地址匹配节点（与主机名关联的IP）</td></tr><tr><td><code>_publish_ip</code></td><td>通过发布IP地址匹配节点</td></tr><tr><td><code>_ip</code></td><td>匹配<code>_host_ip</code>或<code>_publish_ip</code></td></tr><tr><td><code>_host</code></td><td>通过主机名匹配节点</td></tr></tbody></table><p>所有属性值都可以用通配符指定，例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">PUT test/_settings</span><br><span class="line">&#123;</span><br><span class="line">  &quot;index.routing.allocation.include._ip&quot;: &quot;192.168.2.*&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3><span id="不同数据量级的shard最好隔离到不同组别的结点"> 不同数据量级的shard最好隔离到不同组别的结点</span></h3><p>大家知道ES会自己平衡shard在集群的分布，这个自动平衡的逻辑主要考量三个因素。</p><p>其一同一索引下的shard尽量分散到不同的结点;其二每个结点上的shard数量尽量接近;其三结点的磁盘有足够的剩余空间。<br>这个策略只能保证shard数量分布均匀，而并不能保证数据大小分布均匀。</p><p>实际应用中，我们有200多种索引，数据量级差别很大，大的一天几个TB，小的一个月才几个GB，并且每种类型的数据保留时长又千差万别。抛出的问题，就是如何能比较平衡并充分的利用所有节点的资源。</p><p>针对这个问题，我们还是<strong>通过对结点添加属性标签来做分组，结合index routing控制的方式来做一些精细化的控制</strong>。<strong>尽量让不同量级的数据使用不同组别的结点，使得每个组内结点上的数据量比较容易自动平衡</strong>。</p><h3><span id="对索引的一些操作"> 对索引的一些操作</span></h3><p>ES的查询速度和缓存相关，对于内存的消耗，和很多因素相关，诸如数据总量、mapping设置、查询方式、查询频度等等。<br>那么有哪些途径减少data node上的segment memory占用呢？ 总结起来有三种方法:</p><h4><span id="删除不用的索引"> 删除不用的索引</span></h4><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-delete.html" target="_blank" rel="noopener">Delete API</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DELETE /twitter/_doc/1</span><br></pre></td></tr></table></figure><h4><span id="关闭索引-文件仍然存在于磁盘只是释放掉内存-需要的时候可以重新打开"> 关闭索引 （文件仍然存在于磁盘，只是释放掉内存）。需要的时候可以重新打开。</span></h4><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.2/indices-open-close.html#indices-open-close" target="_blank" rel="noopener">Open / Close Index API</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">POST /my_index/_close</span><br><span class="line"></span><br><span class="line">POST /my_index/_open</span><br></pre></td></tr></table></figure><p>所有操作可以使用<code>_all</code>作为索引名称或指定识别它们的模式（例如<code>*</code> ），立即打开或关闭。</p><h4><span id="定期做索引的force-merge"> 定期做索引的force merge</span></h4><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-forcemerge.html" target="_blank" rel="noopener">Elasticsearch Reference  » Indices APIs » Force Merge</a></p><p>强制合并API允许强制通过API合并一个或多个索引。 合并涉及Lucene索引在每个分片中保存的分段数量。 强制合并操作允许通过合并它们来减少分段的数量。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">POST /twitter/_forcemerge?max_num_segments=1</span><br></pre></td></tr></table></figure><p>强制合并API可以通过一次调用应用于多个索引，甚至可以<code>_all</code>所有索引。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">POST /kimchy,elasticsearch/_forcemerge</span><br><span class="line"></span><br><span class="line">POST /_forcemerge</span><br></pre></td></tr></table></figure><p><em>max_num_segments<br>要合并到的段数。 要完全合并索引，请将其设置为1 。 默认仅仅检查一个合并是否需要执行，如果是的话，执行它。</em></p><p>合并示例：</p><p><code>GET /_cat/indices?v</code><br>原始索引 segment的memory占用情况,size.memory之和为 <code>1147554</code><br><code>GET /_cat/segments/nginx-mse-2018.04.19?h=index,shard,segment,size,size.memory</code></p><p>索引 <code>nginx-mse-2018.04.19</code> 的 <code>segments</code> 数量：<br><code>GET /_cat/segments/nginx-mse-2018.04.19?v</code><br>共有 81 行。</p><p><strong>执行合并操作：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">POST /nginx-mse-2018.04.18,nginx-mse-2018.04.19,nginx-mse-2018.04.20/_forcemerge?max_num_segments=1</span><br></pre></td></tr></table></figure><p>segment的memory占用情况比较，size.memory之和为 <code>492797</code>,减少<code>1/2</code>多一点<br><code>GET /_cat/segments/nginx-mse-2018.04.19?h=index,shard,segment,size,size.memory</code></p><p>查看索引的 <code>segments</code>数量：<br>合并后，segments实际个数为logstash客户端个数。</p><p>查看节点 <code>segments</code> 内存占用情况<br><code>get /_cat/nodes?v&amp;h=segments.count,segments.memory,segments.index_writer_memory,segments.version_map_memory,segments.fixed_bitset_memory</code></p><h3><span id="当节点离开时延迟分配"> 当节点离开时延迟分配</span></h3><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/delayed-allocation.html#delayed-allocation" target="_blank" rel="noopener">Elasticsearch Reference » Index Modules » Index Shard Allocation » Delaying allocation when a node leaves</a></p><p>当一个节点出于任何原因离开集群时，主动地或以其他方式作出反应：</p><ul><li>将副本分片提升为主节点以替换节点上的任何初选。</li><li>分配副本分片以替换缺失的副本（假设有足够的节点）。</li><li>将剩余节点上的碎片均衡重新平衡。</li></ul><p>这些操作旨在通过确保每个碎片尽快完全复制来保护集群免遭数据丢失。</p><p>尽管我们在节点级别和集群级别上节省并发恢复，但这种“碎片整理”仍然会给群集带来很多额外的负载，如果缺少的节点很快可能会返回，这可能不是必需的。</p><p>由于节点已离开而变成未分配副本碎片的分配可以通过<code>index.unassigned.node_left.delayed_timeout</code>动态设置进行延迟，默认值为1m 。</p><p>此设置可以在实时索引（或所有索引）上更新：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">PUT _all/_settings</span><br><span class="line">&#123;</span><br><span class="line">  &quot;settings&quot;: &#123;</span><br><span class="line">    &quot;index.unassigned.node_left.delayed_timeout&quot;: &quot;5m&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>永久删除节点<br>如果一个节点不会返回，并且您希望Elasticsearch立即分配丢失的碎片，只需将超时更新为零即可：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">PUT _all/_settings</span><br><span class="line">&#123;</span><br><span class="line">  &quot;settings&quot;: &#123;</span><br><span class="line">    &quot;index.unassigned.node_left.delayed_timeout&quot;: &quot;0&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2><span id="监控"> 监控</span></h2><p>不差钱没空折腾的建议还是买官方的xpack省心，有精力折腾的，利用ES各种丰富的stats api，用自己熟悉的监控工具采集数据，可视化出来就好了。</p><p>那么多监控指标，最最关键的还是以下几类:</p><p>各类Thread pool的使用情况，active/queue/reject 可视化出来。 <code>get /_nodes/stats</code></p><p>判断集群是否有性能瓶颈了，看看业务高峰期各类queue是不是很高，reject是不是经常发生，基本可以做到心里有数。</p><p>JVM的heap used%以及old GC的频率，如果old GC频率很高，并且多次GC过后heap used%几乎下不来，说明heap压力太大，要考虑扩容了。（也有可能是有问题的查询或者聚合造成的，需要结合用户访问记录来判断)。</p><p>Segment memory大小和Segment的数量。节点上存放的索引较多的时候，这两个指标就值得关注，要知道segment memory是常驻heap不会被GC回收的，因此当heap压力太大的时候，可以结合这个指标判断是否是因为节点上存放的数据过多，需要扩容。Segement的数量也是比较关键的，如果小的segment非常多，比如有几千，即使segment memory本身不多，但是在搜索线程很多的情况下，依然会吃掉相当多的heap，原因是lucene为每个segment会在thread local里记录状态信息，这块的heap内存开销和(segment数量* thread数量)相关。</p><p>很有必要记录用户的访问记录。我们只开放了http api给用户，前置了一个nginx做http代理，将用户第三方api的访问记录通过access log全部记录下来。通过分析访问记录，可以在集群出现性能问题时，快速找到问题根源，对于问题排查和性能优化都很有帮助。</p><p>参考链接：</p><ol><li><a href="https://elasticsearch.cn/article/110" target="_blank" rel="noopener">Day1: 大规模Elasticsearch集群管理心得</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/delayed-allocation.html" target="_blank" rel="noopener">Delaying allocation when a node leaves</a></li><li><a href="http://www.cnblogs.com/liang1101/p/7284205.html" target="_blank" rel="noopener">http://www.cnblogs.com/liang1101/p/7284205.html</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/shard-allocation-filtering.html" target="_blank" rel="noopener">Shard Allocation Filtering</a></li><li><a href="https://elasticsearch.cn/article/32" target="_blank" rel="noopener">ES内存那点事</a></li><li><a href="http://docs.flycloud.me/docs/ELKStack/elasticsearch/monitor/api/node-stats.html" target="_blank" rel="noopener">节点状态监控接口</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;简单的优化，让集群发挥更大的效率。&lt;/p&gt;
    
    </summary>
    
      <category term="elk" scheme="yunke.science/categories/elk/"/>
    
    
      <category term="elk" scheme="yunke.science/tags/elk/"/>
    
  </entry>
  
  <entry>
    <title>elasticsearch 加快搜索速度</title>
    <link href="yunke.science/2018/05/01/elk-searchspeed/"/>
    <id>yunke.science/2018/05/01/elk-searchspeed/</id>
    <published>2018-05-01T08:58:03.000Z</published>
    <updated>2018-05-04T03:01:54.000Z</updated>
    
    <content type="html"><![CDATA[<p>Elastic Stack 在最近两年迅速崛起，成为机器数据分析，或者说实时日志处理领域，开源界的第一选择。和传统的日志处理方案相比，Elastic Stack 具有如下几个优点：</p><ol><li>处理方式灵活,实时全文索引;</li><li>配置简易上手,采用 JSON 接口;</li><li>检索性能高效,实时计算基本可以达到全天数据查询的秒级响应；</li><li>集群线性扩展;</li><li>Kibana仪表板操作炫丽.</li></ol><a id="more"></a><h1><span id="elasticsearch-加快搜索速度的几种方法"> elasticsearch 加快搜索速度的几种方法</span></h1><p><ul class="markdownIt-TOC"><li><a href="#%E7%BB%99%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%BC%93%E5%AD%98%E7%95%99%E5%87%BA%E5%86%85%E5%AD%98">给文件系统缓存留出内存</a></li><li><a href="#%E4%BD%BF%E7%94%A8%E6%9B%B4%E5%BF%AB%E7%9A%84%E7%A1%AC%E4%BB%B6">使用更快的硬件</a></li><li><a href="#%E6%96%87%E6%A1%A3%E5%BB%BA%E6%A8%A1">文档建模</a></li><li><a href="#%E9%A2%84%E5%85%88%E7%B4%A2%E5%BC%95%E6%95%B0%E6%8D%AE">预先索引数据</a></li><li><a href="#%E6%98%A0%E5%B0%84">映射</a></li><li><a href="#%E9%81%BF%E5%85%8D%E8%84%9A%E6%9C%AC">避免脚本</a></li><li><a href="#%E6%90%9C%E7%B4%A2%E6%97%A5%E6%9C%9F%E8%8C%83%E5%9B%B4">搜索日期范围</a></li><li><a href="#%E5%BC%BA%E5%88%B6%E5%90%88%E5%B9%B6%E5%8F%AA%E8%AF%BB%E7%B4%A2%E5%BC%95">强制合并只读索引</a></li><li><a href="#%E5%B0%86%E5%85%A8%E5%B1%80%E5%BA%8F%E5%8F%B7%E5%8A%A0%E5%85%A5%E7%83%AD%E6%95%B0%E6%8D%AE">将全局序号加入热数据</a></li><li><a href="#%E9%A2%84%E7%83%AD%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%BC%93%E5%AD%98">预热文件系统缓存</a></li><li><a href="#%E5%B0%86%E6%A0%87%E8%AF%86%E7%AC%A6%E6%98%A0%E5%B0%84%E4%B8%BAkeyword">将标识符映射为<code>keyword</code></a></li><li><a href="#%E4%BD%BF%E7%94%A8%E7%B4%A2%E5%BC%95%E6%8E%92%E5%BA%8F%E6%9D%A5%E5%8A%A0%E9%80%9F%E8%BF%9E%E6%8E%A5">使用索引排序来加速连接。</a></li><li><a href="#%E4%BD%BF%E7%94%A8-preference-%E6%9D%A5%E4%BC%98%E5%8C%96%E7%BC%93%E5%AD%98%E5%88%A9%E7%94%A8%E7%8E%87">使用 <code>preference</code> 来优化缓存利用率</a></li><li><a href="#%E5%89%AF%E6%9C%AC%E5%8F%AF%E8%83%BD%E6%9C%89%E5%8A%A9%E4%BA%8E%E5%90%9E%E5%90%90%E9%87%8F%E4%BD%86%E5%B9%B6%E9%9D%9E%E6%80%BB%E6%98%AF%E5%A6%82%E6%AD%A4">副本可能有助于吞吐量，但并非总是如此</a></li><li><a href="#%E6%89%93%E5%BC%80%E8%87%AA%E9%80%82%E5%BA%94%E5%89%AF%E6%9C%AC%E9%80%89%E6%8B%A9">打开自适应副本选择</a></li></ul></p><h2><span id="给文件系统缓存留出内存"> 给文件系统缓存留出内存</span></h2><p>Elasticsearch严重依赖文件系统缓存来快速搜索。<br>通常，您应该确保至少为文件系统缓存预留一半的可用内存，以便Elasticsearch可以将索引的热数据保留在物理内存中。</p><h2><span id="使用更快的硬件"> 使用更快的硬件</span></h2><p>如果您的搜索依赖大量的 I/O，您应该研究为文件系统缓存提供更多内存（见上文）或购买更快的磁盘IO。 SSD磁盘比普通磁盘执行得更好。</p><p>始终使用本地存储，应避免使用远程文件系统（如NFS或SMB） 。 还要注意虚拟化存储，如亚马逊的Elastic Block Storage 。<br>虚拟化存储在Elasticsearch上运行得非常好，而且它非常吸引人，因为它设置起来非常快速且简单，但与专用本地存储相比，它本质上不太稳定。<br>如果您在EBS上创建索引，请务必使用预配置的IOPS，否则操作可能会迅速受到限制。</p><p>如果您的搜索是CPU依赖型的，则应该购买更快的CPU。</p><h2><span id="文档建模"> 文档建模</span></h2><p>文件应该建模，以便搜索时间操作尽可能简洁。</p><p>特别是，应该避免使用joins 。 nested可以使查询慢几倍， parent-child关系可以使查询速度降低数百倍。<br>因此，如果同样的问题可以通过规范化文档来解决，那么就可以获取显著的速度。</p><h2><span id="预先索引数据"> 预先索引数据</span></h2><p>您应该利用查询中的模式来优化数据的索引方式。</p><p>例如，如果所有的文档都有一个price字段，并且大多数查询在一个固定的范围列表上运行range聚合，那么您可以通过将范围预先索引到索引中并使用terms聚合来加快这个聚合。</p><p>例如，如果文档看起来像这样：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">PUT index/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  &quot;designation&quot;: &quot;spoon&quot;,</span><br><span class="line">  &quot;price&quot;: 13</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>搜索请求如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">GET index/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;aggs&quot;: &#123;</span><br><span class="line">    &quot;price_ranges&quot;: &#123;</span><br><span class="line">      &quot;range&quot;: &#123;</span><br><span class="line">        &quot;field&quot;: &quot;price&quot;,</span><br><span class="line">        &quot;ranges&quot;: [</span><br><span class="line">          &#123; &quot;to&quot;: 10 &#125;,</span><br><span class="line">          &#123; &quot;from&quot;: 10, &quot;to&quot;: 100 &#125;,</span><br><span class="line">          &#123; &quot;from&quot;: 100 &#125;</span><br><span class="line">        ]</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后可以在索引时通过 price_range 字段丰富文档，该字段应该映射为<code>keyword</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">PUT index</span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;_doc&quot;: &#123;</span><br><span class="line">      &quot;properties&quot;: &#123;</span><br><span class="line">        &quot;price_range&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PUT index/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  &quot;designation&quot;: &quot;spoon&quot;,</span><br><span class="line">  &quot;price&quot;: 13,</span><br><span class="line">  &quot;price_range&quot;: &quot;10-100&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后搜索请求可以聚合这个新字段<code>price_range</code>，而不是在<code>price</code>字段上运行<code>range</code> 聚合。</p><h2><span id="映射"> 映射</span></h2><p>一些数据是数字的事实并不意味着它应该总是被映射为数字字段 <code>numeric field</code> 。 通常，存储标识符(如ISBN或标识来自另一个数据库的记录的任何数字的字段)映射为<code>keyword</code>而非<code>integer</code>或<code>long integer</code>,或许会更好 。</p><h2><span id="避免脚本"> 避免脚本</span></h2><p>一般来说，脚本应该避免。 如果他们绝对需要，你应该更喜欢<code>painless</code>和<code>expressions</code>引擎。</p><h2><span id="搜索日期范围"> 搜索日期范围</span></h2><p>now使用的日期字段的查询通常无法缓存，因为匹配的范围一直在变化。然而，在用户体验方面，切换到一个整数日期通常是可以接受的，并且有更好地使用查询缓存的好处。</p><p>例如下面的查询：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">PUT index/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  &quot;my_date&quot;: &quot;2016-05-11T16:30:55.328Z&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GET index/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;constant_score&quot;: &#123;</span><br><span class="line">      &quot;filter&quot;: &#123;</span><br><span class="line">        &quot;range&quot;: &#123;</span><br><span class="line">          &quot;my_date&quot;: &#123;</span><br><span class="line">            &quot;gte&quot;: &quot;now-1h&quot;,</span><br><span class="line">            &quot;lte&quot;: &quot;now&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以替换为以下查询：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">GET index/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;constant_score&quot;: &#123;</span><br><span class="line">      &quot;filter&quot;: &#123;</span><br><span class="line">        &quot;range&quot;: &#123;</span><br><span class="line">          &quot;my_date&quot;: &#123;</span><br><span class="line">            &quot;gte&quot;: &quot;now-1h/m&quot;,</span><br><span class="line">            &quot;lte&quot;: &quot;now/m&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这种情况下，我们四舍五入到分钟，所以如果当前时间是<code>16:31:29</code>，范围查询将匹配my_date字段的值介于<code>15:31:00</code>和<code>16:31:59</code>之间的所有内容。<br>如果多个用户在同一分钟内运行包含此范围的查询，则查询缓存可以帮助加快速度。<br>用于舍入的时间间隔越长，查询缓存可以提供的帮助就越多，但要注意过于积极的舍入也可能会伤害用户体验。</p><p><em>注意<br>为了能够利用查询缓存，可能很容易将范围分割成一个大的可缓存部分和较小的不可缓存部分，如下所示：</em></p><p>以下查询分为三个部分：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">GET index/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;constant_score&quot;: &#123;</span><br><span class="line">      &quot;filter&quot;: &#123;</span><br><span class="line">        &quot;bool&quot;: &#123;</span><br><span class="line">          &quot;should&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">              &quot;range&quot;: &#123;</span><br><span class="line">                &quot;my_date&quot;: &#123;</span><br><span class="line">                  &quot;gte&quot;: &quot;now-1h&quot;,</span><br><span class="line">                  &quot;lte&quot;: &quot;now-1h/m&quot;</span><br><span class="line">                &#125;</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">              &quot;range&quot;: &#123;</span><br><span class="line">                &quot;my_date&quot;: &#123;</span><br><span class="line">                  &quot;gt&quot;: &quot;now-1h/m&quot;,</span><br><span class="line">                  &quot;lt&quot;: &quot;now/m&quot;</span><br><span class="line">                &#125;</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">              &quot;range&quot;: &#123;</span><br><span class="line">                &quot;my_date&quot;: &#123;</span><br><span class="line">                  &quot;gte&quot;: &quot;now/m&quot;,</span><br><span class="line">                  &quot;lte&quot;: &quot;now&quot;</span><br><span class="line">                &#125;</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          ]</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>但是，这种做法可能会使查询在某些情况下运行速度变慢，因为bool查询引入的开销可能会因更好地利用查询缓存而失败。</p><h2><span id="强制合并只读索引"> 强制合并只读索引</span></h2><p>只读的索引的多个分段合并到单个分段中将会更好的查询速度。 基于时间的索引通常就是这种情况：只有当前时间帧的索引正在获取新文档，而旧索引是只读的。<br><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-forcemerge.html" target="_blank" rel="noopener">merged down to a single segment</a> 。</p><p><em>重要<br>不要强制合并仍在写入的索引 - 将合并留给后台合并进程。</em></p><h2><span id="将全局序号加入热数据"> 将全局序号加入热数据</span></h2><p>全局序号是用于在<code>keyword</code>字段上运行<code>terms</code>聚合的数据结构。<br>由于Elasticsearch不知道哪些字段将用于<code>terms</code>聚合以及哪些字段不会使用，所以它们在内存中被延迟加载。<br>您可以通过如下所述配置映射来告诉Elasticsearch在刷新时刻加载全局序号：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">PUT index</span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;_doc&quot;: &#123;</span><br><span class="line">      &quot;properties&quot;: &#123;</span><br><span class="line">        &quot;foo&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;keyword&quot;,</span><br><span class="line">          &quot;eager_global_ordinals&quot;: true</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2><span id="预热文件系统缓存"> 预热文件系统缓存</span></h2><p>如果运行Elasticsearch的计算机重新启动，则文件系统缓存将为空，因此操作系统将索引的热区域加载到内存中需要一些时间，以便搜索操作很快。 您可以使用<code>index.store.preload</code>设置根据文件扩展名明确告诉操作系统哪些文件应该加载到内存中。</p><p><em>警告<br>如果文件系统缓存不够大，无法容纳所有数据，那么将数据加载到文件系统缓存中的索引过多或文件太多会使搜索速度变慢。 谨慎使用。</em></p><h2><span id="将标识符映射为keyword"> 将标识符映射为<code>keyword</code></span></h2><p>当你的文档中有数字标识符时，很容易将它们映射为数字，这与他们的json类型一致。<br>但是，Elasticsearch索引编号优化范围查询的方式，<code>keyword</code>字段在词条查询方面更好。 由于范围查询中从不使用标识符，因此应将其映射为<code>keyword</code>。</p><h2><span id="使用索引排序来加速连接"> 使用索引排序来加速连接。</span></h2><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules-index-sorting.html" target="_blank" rel="noopener">索引排序</a>是有用的，以便使连接更快而以略微慢的索引为代价。在<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules-index-sorting-conjunctions.html" target="_blank" rel="noopener">索引分类文档</a>中阅读更多信息。</p><h2><span id="使用-preference-来优化缓存利用率"> 使用 <code>preference</code> 来优化缓存利用率</span></h2><p>有多个缓存可以帮助提高搜索性能，例如文件系统缓存，请求缓存或查询缓存。<br>然而，所有这些缓存都维护在节点级别，这意味着如果您连续运行两次相同的请求，请使用一个或多个副本并使用循环，默认路由算法，那么这两个请求将转到不同的分片副本 ，阻止节点级别的缓存帮助。</p><p>由于搜索应用程序的用户一个接一个地运行类似请求很常见，例如为了分析索引的较窄子集，使用标识当前用户或会话的首选项值可以帮助优化高速缓存的使用。</p><h2><span id="副本可能有助于吞吐量但并非总是如此"> 副本可能有助于吞吐量，但并非总是如此</span></h2><p>除了提高弹性外，副本可以帮助提高吞吐量。例如，如果您有单个分片索引和三个节点，则需要将副本数设置为2，以便共有3个分片副本，以便使用所有节点。</p><p>现在想象一下你有一个2个分片索引和两个节点。在一种情况下，副本数量为0，这意味着每个节点拥有一个分片。在第二种情况下，副本的数量是1，这意味着每个节点都有两个碎片。哪种设置在搜索性能方面表现最佳？通常，每个节点总共拥有更少分片的设置将会表现更好。原因在于它将可用文件系统缓存的份额提高到了每个碎片，文件系统缓存可能是Elasticsearch的1号性能因子。同时，要注意，没有副本的设置在单节点故障的情况下会出现故障，因此需要在吞吐量和可用性之间进行权衡。</p><p>那么副本的合理的数量是多少？如果您有一个具有<code>num_nodes</code>节点的群集，则总数为<code>num_primaries</code>主分片，如果您希望能够一次处理<code>max_failures</code>节点故障，那么适合您的副本数量为<code>max(max_failures, ceil(num_nodes / num_primaries) - 1)</code>。</p><p><em>默认为五个分片，2个副本</em></p><h2><span id="打开自适应副本选择"> 打开自适应副本选择</span></h2><p>当存在多个数据副本时，elasticsearch可以使用一组称为<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search.html#search-adaptive-replica" target="_blank" rel="noopener">自适应副本选择</a>的条件，根据包含碎片每个副本的节点的响应时间，服务时间和队列大小选择最佳数据副本。 这可以提高查询吞吐量并减少搜索量大的应用程序的延迟。</p><p>参考链接：</p><ol><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-search-speed.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-search-speed.html</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Elastic Stack 在最近两年迅速崛起，成为机器数据分析，或者说实时日志处理领域，开源界的第一选择。和传统的日志处理方案相比，Elastic Stack 具有如下几个优点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;处理方式灵活,实时全文索引;&lt;/li&gt;
&lt;li&gt;配置简易上手,采用 JSON 接口;&lt;/li&gt;
&lt;li&gt;检索性能高效,实时计算基本可以达到全天数据查询的秒级响应；&lt;/li&gt;
&lt;li&gt;集群线性扩展;&lt;/li&gt;
&lt;li&gt;Kibana仪表板操作炫丽.&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="elk" scheme="yunke.science/categories/elk/"/>
    
    
      <category term="elk" scheme="yunke.science/tags/elk/"/>
    
  </entry>
  
  <entry>
    <title>微服务部署：蓝绿部署、滚动部署、AB测试发布、灰度发布</title>
    <link href="yunke.science/2018/05/01/deploy-method/"/>
    <id>yunke.science/2018/05/01/deploy-method/</id>
    <published>2018-05-01T02:39:58.000Z</published>
    <updated>2018-05-01T02:43:38.544Z</updated>
    
    <content type="html"><![CDATA[<p>在项目迭代的过程中，不可避免需要<code>上线</code>。上线对应着部署，或者重新部署；部署对应着修改；修改则意味着风险。<br>目前有很多用于部署的技术，有的简单，有的复杂；有的需要停机，有的不需要停机即可完成部署。本文的目的就是将目前常用的布署方案做一个总结。</p><a id="more"></a><p><ul class="markdownIt-TOC"><li><a href="#%E8%93%9D%E7%BB%BF%E9%83%A8%E7%BD%B2-bluegreen-deployment">蓝绿部署 Blue/Green Deployment</a></li><li><a href="#%E6%BB%9A%E5%8A%A8%E9%83%A8%E7%BD%B2-rolling-update">滚动部署 Rolling update</a></li><li><a href="#ab-%E6%B5%8B%E8%AF%95%E5%8F%91%E5%B8%83-ab-testing">A/B 测试发布 A/B Testing</a></li><li><a href="#%E7%81%B0%E5%BA%A6%E5%8F%91%E5%B8%83%E9%87%91%E4%B8%9D%E9%9B%80%E5%8F%91%E5%B8%83">灰度发布／金丝雀发布</a></li></ul></p><h2><span id="蓝绿部署-bluegreen-deployment"> 蓝绿部署 Blue/Green Deployment</span></h2><ol><li><p>定义<br>蓝绿部署是不停老版本，部署新版本然后进行测试，确认OK，将流量切到新版本，然后老版本同时也升级到新版本。<br>简单来说，你需要准备两个相同的环境（基础架构），在蓝色环境运行当前生产环境中的应用，也就是旧版本应用，另一个环境运行新版本应用。</p></li><li><p>特点<br>蓝绿部署无需停机，并且风险较小。</p></li><li><p>部署过程<br>旧版本应用，如图中 App1 version1 、 App2 version1 、 App3 version3 。</p></li></ol><img src="/2018/05/01/deploy-method/Blue-green-deployment-01.png" title="Blue-green-deployment-01"><p>当你想要升级 App2 到 version2 ，在蓝色环境中进行操作，即部署新版本应用，并进行测试。如果测试没问题，就可以把负载均衡器／反向代理／路由指向蓝色环境了。</p><img src="/2018/05/01/deploy-method/Blue-green-deployment-02.png" title="Blue-green-deployment-02"><ol start="3"><li><p>小结<br>从过程不难发现，在部署的过程中，我们的应用始终在线。并且，新版本上线的过程中，并没有修改老版本的任何内容，在部署期间，老版本的状态不受影响。<br>这样风险很小，并且，只要老版本的资源不被删除，理论上，我们可以在任何时间回滚到老版本。</p></li><li><p>蓝绿发布的注意事项<br>当你切换到蓝色环境时，需要妥当处理未完成的业务和新的业务。如果你的数据库后端无法处理，会是一个比较麻烦的问题；</p></li></ol><ul><li>可能会出现需要同时处理<code>微服务架构应用</code>和<code>传统架构应用</code>的情况，如果在蓝绿部署中协调不好这两者，还是有可能会导致服务停止。</li><li>需要提前考虑数据库与应用部署同步迁移 /回滚的问题。</li><li>蓝绿部署需要有基础设施支持。</li><li>在非隔离基础架构（ VM 、 Docker 等）上执行蓝绿部署，蓝色环境和绿色环境有被摧毁的风险。</li></ul><h2><span id="滚动部署-rolling-update"> 滚动部署 Rolling update</span></h2><ol><li><p>定义<br>滚动发布：一般是取出一个或者多个服务器停止服务，执行更新，并重新将其投入使用。周而复始，直到集群中所有的实例都更新成新版本。</p></li><li><p>特点<br>这种部署方式相对于蓝绿部署，更加节约资源——它不需要运行两个集群、两倍的实例数。我们可以部分部署，例如每次只取出集群的20%进行升级。</p></li></ol><img src="/2018/05/01/deploy-method/k8s服务更新过程.png" title="k8s服务更新过程"><p>这种方式也有很多缺点，例如：</p><ol><li>没有一个确定OK的环境。使用蓝绿部署，我们能够清晰地知道老版本是OK的，而使用滚动发布，我们无法确定。</li><li>修改了现有的环境。</li><li>如果需要回滚，很困难。举个例子，在某一次发布中，我们需要更新100个实例，每次更新10个实例，每次部署需要5分钟。当滚动发布到第80个实例时，发现了问1. 需要回滚，这个回滚却是一个痛苦，并且漫长的过程。</li><li>有的时候，我们还可能对系统进行动态伸缩，如果部署期间，系统自动扩容/缩容了，我们还需判断到底哪个节点使用的是哪个代码。尽管有一些自动化的运维工具1. 是依然令人心惊胆战。</li><li>因为是逐步更新，那么我们在上线代码的时候，就会短暂出现新老版本不一致的情况，如果对上线要求较高的场景，那么就需要考虑如何做好兼容的问题。</li></ol><h2><span id="ab-测试发布-ab-testing"> A/B 测试发布 A/B Testing</span></h2><p>A/B 测试跟蓝绿部署完全是两码事。</p><p>A/B 测试是用来测试应用功能表现的方法，例如可用性、受欢迎程度、可见性等等。 A/B 测试通常用在应用的前端上，不过当然需要后端来支持。</p><img src="/2018/05/01/deploy-method/AB-test.png" title="AB-test"><p>A/B 测试与蓝绿部署的区别在于， A/B 测试目的在于通过科学的实验设计、采样样本代表性、流量分割与小流量测试等方式来获得具有代表性的实验结论，并确信该结论在推广到全部流量可信；蓝绿部署的目的是安全稳定地发布新版本应用，并在必要时回滚。</p><p>A/B 测试和蓝绿部署可以同时使用。</p><h2><span id="灰度发布金丝雀发布"> 灰度发布／金丝雀发布</span></h2><p>灰度发布是指在黑与白之间，能够平滑过渡的一种发布方式。<br>AB test就是一种灰度发布方式，让一部分用户继续用A，一部分用户开始用B，如果用户对B没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到B上面来。<br>灰度发布可以保证整体系统的稳定，在初始灰度的时候就可以发现、调整问题，以保证其影响度。</p><img src="/2018/05/01/deploy-method/Grayscale-publishing.png" title="Grayscale-publishing"><p>灰度发布／金丝雀发布由以下几个步骤组成：</p><ul><li>准备好部署各个阶段的工件，包括：构建工件，测试脚本，配置文件和部署清单文件。</li><li>从负载均衡列表中移除掉“金丝雀”服务器。</li><li>升级“金丝雀”应用（排掉原有流量并进行部署）。</li><li>对应用进行自动化测试。</li><li>将“金丝雀”服务器重新添加到负载均衡列表中（连通性和健康检查）。</li><li>如果“金丝雀”在线使用测试成功，升级剩余的其他服务器。（否则就回滚）</li></ul><p>除此之外灰度发布还可以设置路由权重，动态调整不同的权重来进行新老版本的验证。</p><p>参考链接：</p><ol><li><a href="https://www.jianshu.com/p/022685baba7d" target="_blank" rel="noopener">https://www.jianshu.com/p/022685baba7d</a></li><li><a href="https://www.v2ex.com/t/344341" target="_blank" rel="noopener">https://www.v2ex.com/t/344341</a></li><li><a href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/" target="_blank" rel="noopener">https://kubernetes.io/docs/concepts/workloads/controllers/deployment/</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在项目迭代的过程中，不可避免需要&lt;code&gt;上线&lt;/code&gt;。上线对应着部署，或者重新部署；部署对应着修改；修改则意味着风险。&lt;br&gt;
目前有很多用于部署的技术，有的简单，有的复杂；有的需要停机，有的不需要停机即可完成部署。本文的目的就是将目前常用的布署方案做一个总结。&lt;/p&gt;
    
    </summary>
    
      <category term="Kubernetes" scheme="yunke.science/categories/Kubernetes/"/>
    
    
      <category term="Kubernetes" scheme="yunke.science/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Redis AOF文件 重写操作导致的磁盘和内存不足的问题</title>
    <link href="yunke.science/2018/04/30/redis-aof/"/>
    <id>yunke.science/2018/04/30/redis-aof/</id>
    <published>2018-04-30T04:02:47.000Z</published>
    <updated>2018-04-30T04:09:10.227Z</updated>
    
    <content type="html"><![CDATA[<p>Redis AOF文件 重写操作导致的磁盘和内存不足的问题</p><a id="more"></a><p><ul class="markdownIt-TOC"><li><a href="#%E9%97%AE%E9%A2%98%E8%AF%B4%E6%98%8E">问题说明</a></li><li><a href="#%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5">问题排查</a></li><li><a href="#%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86">问题处理</a></li><li><a href="#%E9%99%84bgrewriteaof%E5%91%BD%E4%BB%A4">附：BGREWRITEAOF命令</a></li><li><a href="#%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5">参考链接</a></li></ul></p><h2><span id="问题说明"> 问题说明</span></h2><p>收到 redis 服务器磁盘报警，内存不足报警。</p><h2><span id="问题排查"> 问题排查</span></h2><p>登录服务器，查看磁盘使用率已经接近 100% 。<br>redis data目录存在大量的文件 temp-rewriteaof.aof ，把磁盘撑爆了</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">-rw-rw-r-- 1 myuser myuser 18044223152 4月   8 12:01 appendonly.aof</span><br><span class="line">-rw-rw-r-- 1 myuser myuser  3603981186 4月   8 12:01 temp-rewriteaof-8116.aof</span><br><span class="line">-rw-rw-r-- 1 myuser myuser  4083774382 4月   8 11:46 temp-rewriteaof-8117.aof</span><br><span class="line">-rw-rw-r-- 1 myuser myuser  4326578230 4月   8 11:21 temp-rewriteaof-8118.aof</span><br><span class="line">-rw-rw-r-- 1 myuser myuser  3603981186 4月   8 12:01 temp-rewriteaof-8119.aof</span><br><span class="line">-rw-rw-r-- 1 myuser myuser  4083774382 4月   8 11:46 temp-rewriteaof-8120.aof</span><br><span class="line">-rw-rw-r-- 1 myuser myuser  4326578230 4月   8 11:21 temp-rewriteaof-8121.aof</span><br><span class="line">-rw-rw-r-- 1 myuser myuser  3603981186 4月   8 12:01 temp-rewriteaof-8122.aof</span><br><span class="line">-rw-rw-r-- 1 myuser myuser  4083774382 4月   8 11:46 temp-rewriteaof-8123.aof</span><br><span class="line">-rw-rw-r-- 1 myuser myuser  4326578230 4月   8 11:21 temp-rewriteaof-8124.aof</span><br></pre></td></tr></table></figure><p>网上查询资料，temp-rewriteaof 是redis在进行 BGREWRITEAOF 时产生的临时文件。</p><p>BGREWRITEAOF命令 执行一个 AOF文件重写操作。重写会创建一个当前 AOF 文件的体积优化版本。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">AOF 文件的体积优化的原理：</span><br><span class="line"></span><br><span class="line">随着写操作的执行，AOF变得越来越大。 </span><br><span class="line">例如，如果您将计数器递增100次，则最终数据集中将包含一个包含最终值的单个键，但AOF中将包含100个条目，这些条目中其余99个不需要的记录将被优化掉。</span><br><span class="line">如果在某一段时间添加了大量的key，在某一时间又删除了这些key，这些添加和删除的操作将被优化掉。</span><br><span class="line"></span><br><span class="line">因此，Redis支持一个有趣的功能：它能够在不中断向客户端提供服务的情况下在后台重建AOF。 </span><br><span class="line">每当您发出BGREWRITEAOF Redis时，都会编写在内存中重建当前数据集所需的最短命令序列。 </span><br><span class="line">如果您在Redis 2.2中使用AOF，则需要不时运行BGREWRITEAOF。 Redis 2.4能够自动触发日志重写（有关更多信息，请参阅2.4示例配置文件）。</span><br></pre></td></tr></table></figure><p>查看日志文件 /var/log/messages ，非常多的OOM日志。如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Apr 19 09:31:17 kernel: Out of memory: Kill process 27359 (redis-server) score 912 or sacrifice child</span><br><span class="line">Apr 19 09:31:17 kernel: Killed process 27359 (redis-server) total-vm:11344292kB, anon-rss:3321344kB, file-rss:0kB, shmem-rss:0kB</span><br><span class="line">Apr 19 09:31:30 kernel: redis-server invoked oom-killer: gfp_mask=0x200da, order=0, oom_score_adj=0</span><br><span class="line">Apr 19 09:31:30 kernel: redis-server cpuset=da6138be06a7a917780f1890812508644db4f530d5e16a507109ad542192d05e mems_allowed=0</span><br></pre></td></tr></table></figure><p>查看监控，内存使用情况</p><img src="/2018/04/30/redis-aof/memory_usage.png" title="系统剩余内存监控"><img src="/2018/04/30/redis-aof/redis_used_memory_rss.png" title="redis内存使用监控"><p>temp-rewriteaof-8116.aof 中8116 为rewrite子进程的pid，多个temp文件，时间相近，PID 相近。</p><p>判断 redis-server 在做AOF文件重写操作BGREWRITEAOF时，由于内存不足，被系统kill掉 rewrite 子进程，而 redis-server又重新启动新的rewrite子进程。</p><p>为什么aof重写会导致内存爆涨？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">AOF 是redis的一种持久化方式，用来记录所有的写操作，但是随着时间增加，aof文件会越来越大，所以需要进行重写，将内存中的数据重新以命令的方式写入aof文件。</span><br><span class="line">在重写的过程中，由于redis还会有新的写入，为了避免数据丢失，会开辟一块内存用于存放重写期间产生的写入操作，等到重写完毕后会将这块内存中的操作再追加到aof文件中。</span><br></pre></td></tr></table></figure><p>从原理中可以了解到，如果在重写过程中redis的写入很频繁或写入量很大，就会导致占用大量额外的内存来缓存写操作，导致内存爆涨。</p><h2><span id="问题处理"> 问题处理</span></h2><ol><li>对 redis keys总数进行监控 <code>DBSIZE</code> , 对redis list长度进行监控 <code>llen listName</code> , 对redis 内存监控<code>info</code>,数量或者增量超过一定值触发报警。</li><li>调整 BGREWRITEAOF 的频率，默认当达到100%增长时触发BGREWRITEAOF ，根据实际业务增加或者降低触发频率。</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379[6]&gt; config get auto-aof-rewrite-percentage</span><br><span class="line">1) &quot;auto-aof-rewrite-percentage&quot;</span><br><span class="line">2) &quot;100&quot;</span><br><span class="line">127.0.0.1:6379[6]&gt; config set auto-aof-rewrite-percentage 800</span><br><span class="line">OK</span><br><span class="line">127.</span><br></pre></td></tr></table></figure><ol start="3"><li>根据业务需要，判断是否需要持久化。取消AOF <code>config set appendonly no</code>， 使用 rdb。</li><li>使用 kafka 代替 redis 。</li></ol><h2><span id="附bgrewriteaof命令"> 附：BGREWRITEAOF命令</span></h2><p><strong>BGREWRITEAOF</strong></p><p>执行一个 AOF文件 重写操作。重写会创建一个当前 AOF 文件的体积优化版本。</p><p>即使 BGREWRITEAOF 执行失败，也不会有任何数据丢失，因为旧的 AOF 文件在 BGREWRITEAOF 成功之前不会被修改。</p><p>重写操作只会在没有其他持久化工作在后台执行时被触发，也就是说：</p><p>如果 Redis 的子进程正在执行快照的保存工作，那么 AOF 重写的操作会被预定(scheduled)，等到保存工作完成之后再执行 AOF 重写。在这种情况下， BGREWRITEAOF 的返回值仍然是 OK ，但还会加上一条额外的信息，说明 BGREWRITEAOF 要等到保存操作完成之后才能执行。在 Redis 2.6 或以上的版本，可以使用 INFO 命令查看 BGREWRITEAOF 是否被预定。</p><p>如果已经有别的 AOF 文件重写在执行，那么 BGREWRITEAOF 返回一个错误，并且这个新的 BGREWRITEAOF 请求也不会被预定到下次执行。<br>从 Redis 2.4 开始， AOF 重写由 Redis 自行触发， BGREWRITEAOF 仅仅用于手动触发重写操作。</p><h2><span id="参考链接"> 参考链接</span></h2><ol><li><a href="http://blog.51cto.com/xiao987334176/1881015" target="_blank" rel="noopener">http://blog.51cto.com/xiao987334176/1881015</a></li><li><a href="http://sparkgis.com/uncategorized/2018/04/%E4%BC%98%E5%8C%96-redis-aof%E9%87%8D%E5%86%99%E5%AF%BC%E8%87%B4%E7%9A%84%E5%86%85%E5%AD%98%E9%97%AE%E9%A2%98-%E5%8E%9F-%E8%8D%90-%E4%BC%98%E5%8C%96-redis-aof%E9%87%8D%E5%86%99%E5%AF%BC%E8%87%B4-3/" target="_blank" rel="noopener">http://sparkgis.com/uncategorized/2018/04/优化-redis-aof重写导致的内存问题-原-荐-优化-redis-aof重写导致-3/</a></li><li><a href="https://redis.io/topics/persistence" target="_blank" rel="noopener">https://redis.io/topics/persistence</a></li><li><a href="http://redisdoc.com/server/bgrewriteaof.html" target="_blank" rel="noopener">http://redisdoc.com/server/bgrewriteaof.html</a></li><li><a href="http://redisdoc.com/server/info.html" target="_blank" rel="noopener">http://redisdoc.com/server/info.html</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Redis AOF文件 重写操作导致的磁盘和内存不足的问题&lt;/p&gt;
    
    </summary>
    
      <category term="redis" scheme="yunke.science/categories/redis/"/>
    
    
      <category term="redis" scheme="yunke.science/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>Nginx 指令的执行顺序</title>
    <link href="yunke.science/2018/04/28/nginx-process/"/>
    <id>yunke.science/2018/04/28/nginx-process/</id>
    <published>2018-04-28T01:39:27.000Z</published>
    <updated>2018-04-28T01:40:36.000Z</updated>
    
    <content type="html"><![CDATA[<p>nginx的处理过程总共分为11个阶段，分别是<code>post-read</code>、<code>server-rewrite</code>、<code>find-config</code>、<code>rewrite</code>、<code>post-rewrite</code>、<code>preaccess</code>、<code>access</code>、<code>post-access</code>、<code>try-files</code>、<code>content</code>, <code>log</code>。</p><a id="more"></a><p><ul class="markdownIt-TOC"><li><a href="#post-read">post-read</a></li><li><a href="#server-rewrite">server-rewrite</a></li><li><a href="#find-config">find-config</a></li><li><a href="#rewrite">rewrite</a></li><li><a href="#post-rewrite">post-rewrite</a></li><li><a href="#preaccess-%E9%98%B6%E6%AE%B5">preaccess 阶段</a></li><li><a href="#access-%E9%98%B6%E6%AE%B5">access 阶段</a></li><li><a href="#post-access-%E9%98%B6%E6%AE%B5">post-access 阶段</a></li><li><a href="#try-files-%E9%98%B6%E6%AE%B5">try-files 阶段</a></li><li><a href="#content-%E9%98%B6%E6%AE%B5">content 阶段</a></li><li><a href="#log-%E9%98%B6%E6%AE%B5">log 阶段</a></li></ul></p><h2><span id="post-read"> post-read</span></h2><p>在nginx读取解析请求头后执行: <code>set_real_ip_from</code> ,<code>read_ip_head</code></p><p>该阶段是在Nginx读取并解析完请求头（request headers）之后就立即开始执行的，标准模块的ngx_realip就是在post-read阶段注册了处理程序。它的功能是迫使 Nginx 认为当前请求的来源地址是指定的某一个请求头的值。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">        listen 8080;</span><br><span class="line"></span><br><span class="line">        set_real_ip_from 127.0.0.1;</span><br><span class="line">        real_ip_header   X-My-IP;</span><br><span class="line"></span><br><span class="line">        location /test &#123;</span><br><span class="line">            set $addr $remote_addr;</span><br><span class="line">            echo &quot;from: $addr&quot;;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>这里的配置是让 Nginx 把那些来自 127.0.0.1 的所有请求的来源地址，都改写为请求头 X-My-IP 所指定的值。同时该例使用了标准内建变量 $remote_addr 来输出当前请求的来源地址，以确认是否被成功改写。</p><h2><span id="server-rewrite"> server-rewrite</span></h2><p>当 ngx_rewrite 模块的配置指令直接书写在 server 配置块中时，基本上都是运行在 server-rewrite 阶段</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">        listen 8080;</span><br><span class="line"></span><br><span class="line">        location /test &#123;</span><br><span class="line">            set $b &quot;$a, world&quot;;</span><br><span class="line">            echo $b;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        set $a hello;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>配置语句 set $a hello 直接写在了 server 配置块中，因此它就运行在 server-rewrite 阶段</p><h2><span id="find-config"> find-config</span></h2><p>紧接在 server-rewrite 阶段后边的是 find-config 阶段。这个阶段并不支持 Nginx 模块注册处理程序，而是由 Nginx 核心来完成当前请求与 location 配置块之间的配对工作。换句话说，在此阶段之前，请求并没有与任何 location 配置块相关联。因此，对于运行在 find-config 阶段之前的 post-read 和 server-rewrite 阶段来说，只有 server 配置块以及更外层作用域中的配置指令才会起作用。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">location /hello &#123;</span><br><span class="line">    echo &quot;hello world&quot;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果启用了 Nginx 的“调试日志”，那么当请求 /hello 接口时，便可以在 error.log 文件中过滤出下面这一行信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ grep &apos;using config&apos; logs/error.log</span><br><span class="line">[debug] 84579#0: *1 using configuration &quot;/hello&quot;</span><br></pre></td></tr></table></figure><h2><span id="rewrite"> rewrite</span></h2><p>运行在 find-config 阶段之后的便是我们的老朋友 rewrite 阶段。由于 Nginx 已经在 find-config 阶段完成了当前请求与 location 的配对，所以从 rewrite 阶段开始，location 配置块中的指令便可以产生作用。前面已经介绍过，当 ngx_rewrite 模块的指令用于 location 块中时，便是运行在这个 rewrite 阶段。</p><h2><span id="post-rewrite"> post-rewrite</span></h2><p>rewrite 阶段再往后便是所谓的 post-rewrite 阶段。这个阶段也像 find-config 阶段那样不接受 Nginx 模块注册处理程序，而是由 Nginx 核心完成 rewrite 阶段所要求的“内部跳转”操作（如果 rewrite 阶段有此要求的话）。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">        listen 8080;</span><br><span class="line"></span><br><span class="line">        location /foo &#123;</span><br><span class="line">            set $a hello;</span><br><span class="line">            rewrite ^ /bar;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        location /bar &#123;</span><br><span class="line">            echo &quot;a = [$a]&quot;;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>这里在 location /foo 中通过 rewrite 指令把当前请求的 URI 无条件地改写为 /bar，同时发起一个“内部跳转”，最终跳进了 location /bar 中。这里比较有趣的地方是内部跳转的工作原理。内部跳转 本质上其实就是把当前的请求处理阶段强行倒退到 find-config 阶段，以便重新进行请求 URI 与 location 配置块的配对。比如上例中，运行在 rewrite 阶段的 rewrite 指令就让当前请求的处理阶段倒退回了 find-config 阶段。由于此时当前请求的 URI 已经被 rewrite 指令修改为了 /bar，所以这一次换成了 location /bar 与当前请求相关联，然后再接着从 rewrite 阶段往下执行。</p><p>不过这里更有趣的地方是，倒退回 find-config 阶段的动作并不是发生在 rewrite 阶段，而是发生在后面的 post-rewrite 阶段。上例中的 rewrite 指令只是简单地指示 Nginx 有必要在 post-rewrite 阶段发起“内部跳转”。这个设计对于 Nginx 初学者来说，或许显得有些古怪：“为什么不直接在 rewrite 指令执行时立即进行跳转呢？”答案其实很简单，那就是为了在最初匹配的 location 块中支持多次反复地改写 URI，例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">location /foo &#123;</span><br><span class="line">        rewrite ^ /bar;</span><br><span class="line">        rewrite ^ /baz;</span><br><span class="line"></span><br><span class="line">        echo foo;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    location /bar &#123;</span><br><span class="line">        echo bar;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    location /baz &#123;</span><br><span class="line">        echo baz;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>这里在 location /foo 中连续把当前请求的 URI 改写了两遍：第一遍先无条件地改写为 /bar，第二遍再无条件地改写为 /baz. 而这两条 rewrite 语句只会最终导致 post-rewrite 阶段发生一次“内部跳转”操作，从而不至于在第一次改写 URI 时就直接跳离了当前的 location 而导致后面的 rewrite 语句没有机会执行。请求 /foo 接口的结果证实了这一点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ curl localhost:8080/foo</span><br><span class="line">baz</span><br></pre></td></tr></table></figure><p>从输出结果可以看到，上例确实成功地从 /foo 一步跳到了 /baz 中。如果启用 Nginx “调试日志”的话，还可以从 find-config 阶段生成的 location 块的匹配信息中进一步证实这一点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ grep &apos;using config&apos; logs/error.log</span><br><span class="line">[debug] 89449#0: *1 using configuration &quot;/foo&quot;</span><br><span class="line">[debug] 89449#0: *1 using configuration &quot;/baz&quot;</span><br></pre></td></tr></table></figure><p>我们看到，对于该次请求，Nginx 一共只匹配过 /foo 和 /baz 这两个 location，从而只发生过一次“内部跳转”。</p><p>当然，如果在 server 配置块中直接使用 rewrite 配置指令对请求 URI 进行改写，则不会涉及“内部跳转”，因为此时 URI 改写发生在 server-rewrite 阶段，早于执行 location 配对的 find-config 阶段。比如下面这个例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">        listen 8080;</span><br><span class="line"></span><br><span class="line">        rewrite ^/foo /bar;</span><br><span class="line"></span><br><span class="line">        location /foo &#123;</span><br><span class="line">            echo foo;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        location /bar &#123;</span><br><span class="line">            echo bar;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>这里，我们在 server-rewrite 阶段就把那些以 /foo 起始的 URI 改写为 /bar，而此时请求并没有和任何 location 相关联，所以 Nginx 正常往下运行 find-config 阶段，完成最终的 location 匹配。如果我们请求上例中的 /foo 接口，那么 location /foo 根本就没有机会匹配，因为在第一次（也是唯一的一次）运行 find-config 阶段时，当前请求的 URI 已经被改写为 /bar，从而只会匹配 location /bar.</p><h2><span id="preaccess-阶段"> preaccess 阶段</span></h2><p>标准模块 ngx_limit_req 和 ngx_limit_zone 就运行在此阶段，前者可以控制请求的访问频度，而后者可以限制访问的并发度。</p><h2><span id="access-阶段"> access 阶段</span></h2><p>标准模块 ngx_access、第三方模块 ngx_auth_request 以及第三方模块 ngx_lua 的 access_by_lua 指令就运行在这个阶段。</p><h2><span id="post-access-阶段"> post-access 阶段</span></h2><p>post-access 阶段主要用于配合 access 阶段实现标准 ngx_http_core 模块提供的配置指令 satisfy 的功能。<br>对于多个 Nginx 模块注册在 access 阶段的处理程序， satisfy 配置指令可以用于控制它们彼此之间的协作方式。比如模块 A 和 B 都在 access 阶段注册了与访问控制相关的处理程序，那就有两种协作方式，一是模块 A 和模块 B 都得通过验证才算通过，二是模块 A 和模块 B 只要其中任一个通过验证就算通过。第一种协作方式称为 all 方式（或者说“与关系”），第二种方式则被称为 any 方式（或者说“或关系”）。默认情况下，Nginx 使用的是 all 方式。下面是一个例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">location /test &#123;</span><br><span class="line">        satisfy all;</span><br><span class="line"></span><br><span class="line">        deny all;</span><br><span class="line">        access_by_lua &apos;ngx.exit(ngx.OK)&apos;;</span><br><span class="line"></span><br><span class="line">        echo something important;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>这里，我们在 /test 接口中同时配置了 ngx_access 模块和 ngx_lua 模块，这样 access 阶段就由这两个模块一起来做检验工作。其中，语句 deny all 会让 ngx_access 模块的处理程序总是拒绝当前请求，而语句 access_by_lua ‘ngx.exit(ngx.OK)’ 则总是允许访问。当我们通过 satisfy 指令配置了 all 方式时，就需要 access 阶段的所有模块都通过验证，但不幸的是，这里 ngx_access 模块总是会拒绝访问，所以整个请求就会被拒.</p><h2><span id="try-files-阶段"> try-files 阶段</span></h2><p>这个阶段专门用于实现标准配置指令 try_files 的功能，并不支持 Nginx 模块注册处理程序。<br>try_files 指令接受两个以上任意数量的参数，每个参数都指定了一个 URI. 这里假设配置了 N 个参数，则 Nginx 会在 try-files 阶段，依次把前 N-1 个参数映射为文件系统上的对象（文件或者目录），然后检查这些对象是否存在。一旦 Nginx 发现某个文件系统对象存在，就会在 try-files 阶段把当前请求的 URI 改写为该对象所对应的参数 URI（但不会包含末尾的斜杠字符，也不会发生 “内部跳转”）。如果前 N-1 个参数所对应的文件系统对象都不存在，try-files 阶段就会立即发起“内部跳转”到最后一个参数（即第 N 个参数）所指定的 URI.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">root /var/www/;</span><br><span class="line"></span><br><span class="line">    location /test &#123;</span><br><span class="line">        try_files /foo /bar/ /baz;</span><br><span class="line">        echo &quot;uri: $uri&quot;;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    location /foo &#123;</span><br><span class="line">        echo foo;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    location /bar/ &#123;</span><br><span class="line">        echo bar;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    location /baz &#123;</span><br><span class="line">        echo baz;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>这里通过 root 指令把“文档根目录”配置为 /var/www/，如果你系统中的 /var/www/ 路径下存放有重要数据，则可以把它替换为其他任意路径，但此路径对运行 Nginx worker 进程的系统帐号至少有可读权限。我们在 location /test 中使用了 try_files 配置指令，并提供了三个参数，/foo、/bar/ 和 /baz. 根据前面对 try_files 指令的介绍，我们可以知道，它会在 try-files 阶段依次检查前两个参数 /foo 和 /bar/ 所对应的文件系统对象是否存在。</p><p>不妨先来做一组实验。假设现在 /var/www/ 路径下是空的，则第一个参数 /foo 映射成的文件 /var/www/foo 是不存在的；同样，对于第二个参数 /bar/ 所映射成的目录 /var/www/bar/ 也是不存在的。于是此时 Nginx 会在 try-files 阶段发起到最后一个参数所指定的 URI（即 /baz）的“内部跳转”。实际的请求结果证实了这一点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ curl localhost:8080/test</span><br><span class="line">baz</span><br></pre></td></tr></table></figure><p>显然，该请求最终和 location /baz 绑定在一起，执行了输出 baz 字符串的工作。上例中定义的 location /foo 和 location /bar/ 完全不会参与这里的运行过程，因为对于 try_files 的前 N-1 个参数，Nginx 只会检查文件系统，而不会去执行 URI 与 location 之间的匹配。</p><p>try-files 阶段发生的事情：Nginx 依次检查了文件 /var/www/foo 和目录 /var/www/bar，末了又处理了最后一个参数 /baz. 这里最后一条“调试信息”容易产生误解，会让人误以为 Nginx 也把最后一个参数 /baz 给映射成了文件系统对象进行检查，事实并非如此。当 try_files 指令处理到它的最后一个参数时，总是直接执行“内部跳转”，而不论其对应的文件系统对象是否存在。</p><h2><span id="content-阶段"> content 阶段</span></h2><p>content阶段主要是处理内容输出的阶段。这里要注意的是绝大多数 Nginx 模块在向 content 阶段注册配置指令时，本质上是在当前的 location 配置块中注册所谓的“内容处理程序”（content handler）。每一个 location 只能有一个“内容处理程序”，因此，当在 location 中同时使用多个模块的 content 阶段指令时，只有其中一个模块能成功注册“内容处理程序”。例如 echo 和 content_by_lua 如果同时注册，最终只会有一个生效，但具体是哪一个生效是不稳定的。</p><h2><span id="log-阶段"> log 阶段</span></h2><p>日志的记录阶段</p><p>参考链接：</p><ol><li><a href="https://www.jianshu.com/p/0cc0f4c9a005" target="_blank" rel="noopener">https://www.jianshu.com/p/0cc0f4c9a005</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;nginx的处理过程总共分为11个阶段，分别是&lt;code&gt;post-read&lt;/code&gt;、&lt;code&gt;server-rewrite&lt;/code&gt;、&lt;code&gt;find-config&lt;/code&gt;、&lt;code&gt;rewrite&lt;/code&gt;、&lt;code&gt;post-rewrite&lt;/code&gt;、&lt;code&gt;preaccess&lt;/code&gt;、&lt;code&gt;access&lt;/code&gt;、&lt;code&gt;post-access&lt;/code&gt;、&lt;code&gt;try-files&lt;/code&gt;、&lt;code&gt;content&lt;/code&gt;, &lt;code&gt;log&lt;/code&gt;。&lt;/p&gt;
    
    </summary>
    
      <category term="nginx" scheme="yunke.science/categories/nginx/"/>
    
    
      <category term="nginx" scheme="yunke.science/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>创建NGINX重写规则</title>
    <link href="yunke.science/2018/04/26/nginx-rewrite/"/>
    <id>yunke.science/2018/04/26/nginx-rewrite/</id>
    <published>2018-04-26T08:50:50.000Z</published>
    <updated>2018-04-26T09:04:39.000Z</updated>
    
    <content type="html"><![CDATA[<p>在这篇文章中，我们讨论如何创建NGINX重写规则return, rewrite,和try_files指令。</p><a id="more"></a><p><ul class="markdownIt-TOC"><li><a href="#%E5%AF%B9%E6%AF%94return-rewrite%E5%92%8Ctry_files%E6%8C%87%E4%BB%A4">对比return, rewrite,和try_files指令</a><ul><li><a href="#return%E6%8C%87%E4%BB%A4">return指令</a></li><li><a href="#rewrite%E6%8C%87%E4%BB%A4">rewrite指令</a><ul><li><a href="#rewrtie%E5%9B%9B%E7%A7%8Dflag">rewrtie四种flag</a></li></ul></li><li><a href="#try_files-%E6%8C%87%E4%BB%A4">try_files 指令</a></li></ul></li><li><a href="#%E7%A4%BA%E4%BE%8B-%E6%A0%87%E5%87%86%E5%8C%96%E5%9F%9F%E5%90%8D">示例 – 标准化域名</a><ul><li><a href="#%E4%BB%8E%E6%97%A7%E7%9A%84%E5%90%8D%E7%A7%B0%E9%87%8D%E5%AE%9A%E5%90%91%E5%88%B0%E6%96%B0%E7%9A%84%E5%90%8D%E7%A7%B0">从旧的名称重定向到新的名称</a></li><li><a href="#%E6%B7%BB%E5%8A%A0%E5%92%8C%E5%88%A0%E9%99%A4www%E5%89%8D%E7%BC%80">添加和删除www前缀</a></li><li><a href="#%E9%87%8D%E5%AE%9A%E5%90%91%E6%89%80%E6%9C%89%E7%9A%84%E6%B5%81%E9%87%8F%E5%88%B0%E6%AD%A3%E5%B8%B8%E7%9A%84%E5%9F%9F%E5%90%8D">重定向所有的流量到正常的域名</a></li></ul></li><li><a href="#%E7%A4%BA%E4%BE%8B%E5%BC%BA%E5%88%B6%E6%89%80%E6%9C%89%E8%AF%B7%E6%B1%82%E4%BD%BF%E7%94%A8-ssltls">示例：强制所有请求使用 SSL/TLS</a></li><li><a href="#%E7%A4%BA%E4%BE%8B-%E4%B8%BAwordpress%E7%BD%91%E7%AB%99%E5%90%AF%E7%94%A8%E6%BC%82%E4%BA%AE%E7%9A%84%E5%9B%BA%E5%AE%9A%E9%93%BE%E6%8E%A5">示例 – 为WordPress网站启用漂亮的固定链接</a></li><li><a href="#%E7%A4%BA%E4%BE%8B-%E4%B8%A2%E5%BC%83%E4%B8%8D%E5%8F%97%E6%94%AF%E6%8C%81%E7%9A%84%E6%96%87%E4%BB%B6%E6%89%A9%E5%B1%95%E5%90%8D%E7%9A%84%E8%AF%B7%E6%B1%82">示例 – 丢弃不受支持的文件扩展名的请求</a></li><li><a href="#%E7%A4%BA%E4%BE%8B-%E9%85%8D%E7%BD%AE%E8%87%AA%E5%AE%9A%E4%B9%89%E9%87%8D%E6%96%B0%E8%B7%AF%E7%94%B1">示例 – 配置自定义重新路由</a></li></ul></p><p>重写规则会更改客户请求中的部分或全部网址，通常用于以下两个目的之一：</p><ul><li><strong>通知客户端他们请求的资源现在位于不同的位置。</strong><br>示例用例是您的网站的域名发生更改时，您希望客户端使用规范网址格式（带或不带www前缀），以及当您想要捕获和更正您的域名的常见拼写错误时。 返回和重写指令适合于这些目的。</li><li><strong>控制NGINX和NGINX Plus中的处理流程。</strong><br>例如，在需要动态生成内容时，将请求转发到应用程序服务器。 try_files指令通常用于此目的。</li></ul><p><em>注意：学习如何转换Apache重写规则到Nginx重写规则，查看另一片文章<br>Converting Apache Rewrite Rules to NGINX Rewrite Rules.<br>我们假设你已经熟悉HTTP响应码及正则表达式相关知识（nginx和nginx plus使用Perl语法）。</em></p><h2><span id="对比return-rewrite和try_files指令"> 对比return, rewrite,和try_files指令</span></h2><p>通用NGINX重写的两个指令是return 和 rewrite，而try_files指令是将请求定向到应用程序服务器的一种方便的方法。 让我们回顾一下指令的作用以及它们之间的区别。</p><h3><span id="return指令"> return指令</span></h3><p>return指令是两个通用指令中的更简单的，因此我们建议在可能的情况下使用它而不是rewrite（更多的是为什么和什么时候）。 将返回值放在指定要重写的URL的服务器或位置上下文中，并定义客户端在将来对资源的请求中使用的已更正（重写）的URL。</p><p>这有一个简单的示例，重定向客户端到一个新的域名：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen 80;</span><br><span class="line">    listen 443 ssl;</span><br><span class="line">    server_name www.old-name.com;</span><br><span class="line">    return 301 $scheme://www.new-name.com$request_uri;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>listen指令意味着server 块应用于HTTP和HTTPS流量。</li><li>server_name指令匹配具有域名www.old-name.com的请求URL。 - return指令告诉NGINX停止处理请求，并立即向客户端发送代码301（Moved Permanently）和指定的重写URL。 - 重写的URL使用两个NGINX变量来捕获和复制原始请求URL中的值</li><li>$ scheme是协议（http或https）</li><li>$ request_uri是包含参数的完整URI</li></ul><p>对于3xx系列中的代码，url参数定义新的（重写的）URL。<br><code>return (301 | 302 | 303 | 307) url;</code><br>对于其他的代码，你可以选择定义一个用于显示在响应正文的文本字符串（HTTP代码的标准文本，例如404的Not Found，仍包含在标题中）。这个文本字符串可以包含nginx变量。<br><code>return (1xx | 2xx | 4xx | 5xx) [&quot;text&quot;];</code><br>如下，对于非法的认证，当拒绝请求时返回的内容：<br><code>return 401 &quot;Access denied because token is expired or invalid&quot;;</code><br>还有一些可以使用的语法快捷方式，例如省略302的代码; 请参阅return指令的参考文档。<br>（在某些情况下，您可能希望返回一个比在文本字符串中可以实现的更复杂或更细微的响应。使用error_page指令，您可以为每个HTTP代码返回完整的自定义HTML页面，以及更改 响应代码或执行重定向。）<br>所以 <strong>return指令使用很简单，适合当重定向满足两个条件：重写的URL适合于每个匹配server 或location 的请求，您可以使用标准的NGINX变量构建重写的URL。</strong></p><h3><span id="rewrite指令"> rewrite指令</span></h3><p>但是，如果你需要测试更复杂的URL之间的区别，捕获原始URL中没有相应的NGINX变量的元素，或者更改或添加路径中的元素，怎么办？ 在这种情况下，可以使用rewrite伪指令。</p><p>类似return指令，在server或这两个指令与类似的更加不同，并且rewrite指令可能更复杂地使用正确。<br>它的语法很简单：在server 或location块中添加rewrite指令用于定义重定向的URL。另外，这两个指令与类似的更加不同，并且rewrite指令要使用正确可能更复杂。它的语法很简单：</p><p><code>rewrite regex URL [flag];</code></p><ul><li>第一个参数regex意味着NGINX Plus和NGINX只有在匹配指定的正则表达式（除了匹配server 或location - 指令之外）才重写URL。 附加测试意味着NGINX必须做更多的处理。</li><li>第二个不同是rewrite指令只能返回301或302代码。要返回其他的代码，你需要在rewrite指令之后包含一个return指令（看- 下面的例子）。</li><li>最后，rewrite指令不一定会阻止NGINX对返回请求的处理，并且不一定向客户端发送重定向。</li></ul><p>除非你明确指出（使用标志或URL的语法）你希望NGINX停止处理或发送重定向，它运行通过整个配置寻找在Rewrite模块中定义的指令（break，if，return，rewrite ，set），并按顺序处理它们。 如果重写的URL与重写模块中的后续指令匹配，NGINX对重写的URL执行指示的操作（通常再次重写）。<br>这就是让人疑惑的地方，你需要仔细计划如何编写指令以获得所需的结果。 例如，如果原始location和NGINX重写规则在其中匹配重写的URL，NGINX可以进入一个循环，应用重写覆盖到内置的限制10次。 要了解所有详细信息，请参阅Rewrite模块的文档。 如前所述，我们建议尽可能使用return指令。<br>下面是一个使用rewrite指令的nginx重写规则。他匹配以 /download起始的字符串，后面跟/media/  或者 /audio/  目录及后面其他的内容。他使用/mp3/ 和增加文件扩展名.mp3 或者.ra 替换以上的元素. $1 和 $2 变量捕获不变的路径元素。例如，/download/cdn-west/media/file1 变为 /download/cdn-west/mp3/file1.mp3.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    ...</span><br><span class="line">    rewrite ^(/download/.*)/media/(.*)\..*$ $1/mp3/$2.mp3 last;</span><br><span class="line">    rewrite ^(/download/.*)/audio/(.*)\..*$ $1/mp3/$2.ra  last;</span><br><span class="line">    return  403;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们上面提到你可以添加标志到rewrite指令来控制处理的流程。 示例中的最后一个标志是其中之一：它指示NGINX跳过当前服务器或位置块中的任何后续Rewrite-module伪指令，并开始搜索与重写的URL匹配的新位置。<br>在这个例子中的最终return指令意味着如果URL不匹配rewrite指令，代码403返回到客户端。</p><h4><span id="rewrtie四种flag"> rewrtie四种flag</span></h4><p>对于rewrtie有四种不同的flag，分别是redirect、permanent、break和last。<br>其中前两种是跳转型的flag，后两种是代理型。跳转型是指有客户端浏览器重新对新地址进行请求，代理型是在WEB服务器内部实现跳转的。</p><ul><li>redirect：302跳转到rewrtie后面的地址。</li><li>permanent：301永久调整到rewrtie后面的地址，即当前地址已经永久迁移到新地址，一般是为了对搜索引擎友好。</li><li>last：<mark>将rewrite后的地址重新在server标签执行。</mark></li><li>break：<mark>将rewrite后地址重新在当前的location标签执行。</mark></li></ul><h3><span id="try_files-指令"> try_files 指令</span></h3><p>类似return和 rewrite指令，try_files  指令位于server和location块中。它需要一个或多个文件和目录以及最终URI的列表作为参数：</p><p><code>try_files file … uri;</code></p><p>NGINX按顺序检查文件和目录的存在（从 root 和alias指令的设置构造每个文件的完整路径），并提供它找到的第一个。 要指定目录，请在元素名称的末尾添加一个斜杠。 如果没有文件或目录存在，NGINX将执行内部重定向到由最后一个元素（uri）定义的URI。</p><p>为了使try_files指令正常工作，您还需要定义一个捕获内部重定向的location 块，如下面的示例所示。 最终元素可以是命名位置，由初始at符号（@）指示。</p><p>try_files指令通常使用$uri 变量，它表示域名后的URL部分。</p><p>在以下示例中，如果客户端请求的文件不存在，则NGINX提供默认的GIF文件。 当客户端请求（例如）<a href="http://www.domain.com/images/image1.gif%E6%97%B6%EF%BC%8CNGINX%E9%A6%96%E5%85%88%E5%9C%A8%E7%94%B1%E6%A0%B9%E6%88%96alias%E6%8C%87%E4%BB%A4%E6%8C%87%E5%AE%9A%E7%9A%84%E6%9C%AC%E5%9C%B0%E7%9B%AE%E5%BD%95%E4%B8%AD%E6%9F%A5%E6%89%BE%E9%80%82%E7%94%A8%E4%BA%8E%E8%AF%A5%E4%BD%8D%E7%BD%AE%E7%9A%84%E5%9B%BE%E5%83%8F%EF%BC%88%E6%9C%AA%E7%A4%BA%E5%87%BA%EF%BC%89" target="_blank" rel="noopener">http://www.domain.com/images/image1.gif时，NGINX首先在由根或alias指令指定的本地目录中查找适用于该位置的图像（未示出）</a> 在代码段中）。 如果image1.gif不存在，NGINX寻找image1.gif /，如果不存在，它会重定向到/images/default.gif。 该值与第二个位置指令完全匹配，因此处理停止，NGINX提供该文件并将其标记为缓存30秒。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">location /images/ &#123;</span><br><span class="line"> try_files $uri $uri/ /images/default.gif;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">location = /images/default.gif &#123;</span><br><span class="line"> expires 30s;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2><span id="示例-标准化域名"> 示例 – 标准化域名</span></h2><p><strong>NGINX重写规则最常见的用途之一是捕获弃用或非标准版本的网站域名，并将其重定向到当前域名。</strong> 有几个相关的用例。</p><h3><span id="从旧的名称重定向到新的名称"> 从旧的名称重定向到新的名称</span></h3><p>此示例NGINX重写规则将请求从 <a href="http://www.old-name.com" target="_blank" rel="noopener">www.old-name.com</a> 和 <a href="http://old-name.com" target="_blank" rel="noopener">old-name.com</a> 永久重定向到 <a href="http://www.new-name.com" target="_blank" rel="noopener">www.new-name.com</a> ，使用的两个NGINX变量是从原始请求URL中捕获的值。 scheme是原始协议 （http或https），request_uri是完整的URI（域名后），包括参数：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen 80;</span><br><span class="line">    listen 443 ssl;</span><br><span class="line">    server_name www.old-name.com old-name.com;</span><br><span class="line">    return 301 $scheme://www.new-name.com$request_uri;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>因为$ request_uri捕获了域名后面的URL的部分，所以如果新旧网站之间存在一一对应的页面，则此重写是合适的（例如， <a href="http://www.new-name.com/about" target="_blank" rel="noopener">www.new-name.com/about</a>  与 <a href="http://www.old-name.com/about" target="_blank" rel="noopener">www.old-name.com/about</a> 相同的基本内容）。<br>如果您在更改域名之外重新组织了网站，则可以通过省略 $request_uri来将所有请求重定向到主页，这样更安全：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen 80;</span><br><span class="line">    listen 443 ssl;</span><br><span class="line">    server_name www.old-name.com old-name.com;</span><br><span class="line">    return 301 $scheme://www.new-name.com;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>一些其他关于在NGINX中重写URL的博客对这些用例使用rewrite指令，像这样：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># NOT RECOMMENDED</span><br><span class="line">rewrite ^ $scheme://www.new-name.com$request_uri permanent;</span><br></pre></td></tr></table></figure><p><strong>这比return指令效率低，因为它需要处理NGINX正则表达式，虽然是一个简单的（符号[^]，它匹配完整的原始URL）。</strong><br>对应的return指令对于读者来说也更容易解释：return 301更清楚地指示NGINX返回代码301而不是rewrite …permanent 。</p><h3><span id="添加和删除www前缀"> 添加和删除www前缀</span></h3><p>如下示例添加和删除www前缀：</p><p>添加’www’</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen 80;</span><br><span class="line">    listen 443 ssl;</span><br><span class="line">    server_name domain.com;</span><br><span class="line">    return 301 $scheme://www.domain.com$request_uri;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>删除’www’</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line"> listen 80;</span><br><span class="line"> listen 443 ssl;</span><br><span class="line"> server_name www.domain.com;</span><br><span class="line"> return 301 $scheme://domain.com$request_uri;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>同样，<strong>return 效率更高于rewrite</strong>，如下。 重写需要解释正则表达式 – ^（。*）$ – 并创建一个自定义变量（$ 1），实际上等价于内置的 $request_uri 变量。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># NOT RECOMMENDED</span><br><span class="line">rewrite ^(.*)$ $scheme://www.domain.com$1 permanent;</span><br></pre></td></tr></table></figure><h3><span id="重定向所有的流量到正常的域名"> 重定向所有的流量到正常的域名</span></h3><p>这是一种特殊情况，当请求网址与任何服务器和位置块不匹配时，可能是因为域名拼写错误，将入站流量重定向到网站的主页。 它的工作原理是将default_server参数与listen指令组合，将下划线 _ 作为server_name指令的参数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen 80 default_server;</span><br><span class="line">    listen 443 ssl default_server;</span><br><span class="line">    server_name _;</span><br><span class="line">    return 301 $scheme://www.domain.com;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们使用下划线作为server_name的参数，以避免无意中匹配真实的域名 – 可以安全地假设任何站点都不会有下划线作为其域名。 但是，与配置中的任何其他服务器块不匹配的请求都在这里，而且监听的default_server参数告诉NGINX为它们使用此块。 通过从重写的URL中省略$ request_uri变量，我们将所有请求重定向到主页，这是一个好主意，因为具有错误域名的请求尤其可能使用网站上不存在的URI。</p><h2><span id="示例强制所有请求使用-ssltls"> 示例：强制所有请求使用 SSL/TLS</span></h2><p>此server 块强制所有访问者对您的网站使用安全（SSL / TLS）连接。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen 80;</span><br><span class="line">    server_name www.domain.com;</span><br><span class="line">    return 301 https://www.domain.com$request_uri;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>一些关于NGINX重写规则的其他博客使用if测试和rewrite指令来处理这个用例，像这样：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># NOT RECOMMENDED</span><br><span class="line">if ($scheme != &quot;https&quot;) &#123;</span><br><span class="line">    rewrite ^ https://www.mydomain.com$uri permanent;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>但是此方法需要额外的处理，因为NGINX必须同时判断if条件并处理rewrite指令中的正则表达式。</p><h2><span id="示例-为wordpress网站启用漂亮的固定链接"> 示例 – 为WordPress网站启用漂亮的固定链接</span></h2><p>NGINX和NGINX Plus是使用WordPress的网站非常受欢迎的应用交付平台。 下面的try_files指令告诉NGINX检查文件uri，然后是目录uri/的存在。 如果文件或目录不存在，NGINX将返回到/index.php的重定向并传递query-string参数，这些参数由$args参数捕获。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">location / &#123;</span><br><span class="line">    try_files $uri $uri/ /index.php?$args;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2><span id="示例-丢弃不受支持的文件扩展名的请求"> 示例 – 丢弃不受支持的文件扩展名的请求</span></h2><p>由于种种原因，您的网站可能会收到以与您未运行的应用程序服务器相对应的文件扩展名结尾的请求网址。 在本示例中，从Engine Yard博客，应用程序服务器是Ruby on Rails，因此无法处理由其他应用程序服务器（活动服务器页面，PHP，CGI等）处理的文件类型的请求，并且需要拒绝它们。 在将动态生成的资源的任何请求传递给应用程序的server 块中，此位置指令在非Rails文件类型的请求到达Rails队列之前丢弃该请求。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">location ~ \.(aspx|php|jsp|cgi)$ &#123;</span><br><span class="line">    return 410;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>严格地说，响应代码410（Gone）意在用于在所请求的资源在该URL处可用但不再是可用的情况，并且服务器不知道其当前位置（如果有的话）。 它相对于响应代码404的优点是它明确地指示资源永久不可用，因此客户端不会再次发送请求。</p><p>您可能希望通过返回响应代码403（禁止）和诸如“服务器仅处理Ruby请求”这样的解释作为文本字符串，为客户端提供更准确的失败原因指示。 作为替代，deny all伪指令返回403，不作解释：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">location ~ \.(aspx|php|jsp|cgi)$ &#123;</span><br><span class="line">    deny all;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>代码403隐式地确认所请求的资源存在，因此如果想要通过向客户端提供尽可能少的信息来实现“通过模糊的安全性”，则代码404可能是更好的选择。 缺点是客户端可能会反复重试请求，因为404不指示失败是临时还是永久。</p><h2><span id="示例-配置自定义重新路由"> 示例 – 配置自定义重新路由</span></h2><p>在本示例中，您有一个资源，作为一组URL的控制器。 您的用户可以为资源使用更易读的名称，并重写（不重定向）它由控制器在listing.html处理。</p><p><code>rewrite ^/listings/(.*)$ /listing.html?listing=$1 last;</code></p><p>作为示例，用户友好的URL <a href="http://mysite.com/listings/123" target="_blank" rel="noopener">http://mysite.com/listings/123</a> 被重写为由 listing.html 控制器处理的URL， <a href="http://mysite.com/listing.html?listing=123" target="_blank" rel="noopener">http://mysite.com/listing.html?listing=123</a> 。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">翻译自：https://www.nginx.com/blog/creating-nginx-rewrite-rules/</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在这篇文章中，我们讨论如何创建NGINX重写规则return, rewrite,和try_files指令。&lt;/p&gt;
    
    </summary>
    
      <category term="nginx" scheme="yunke.science/categories/nginx/"/>
    
    
      <category term="nginx" scheme="yunke.science/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>对于大多数普通人而言，情商比智商更重要？</title>
    <link href="yunke.science/2018/04/25/meiwen02/"/>
    <id>yunke.science/2018/04/25/meiwen02/</id>
    <published>2018-04-25T02:10:35.000Z</published>
    <updated>2018-04-25T02:14:05.000Z</updated>
    
    <content type="html"><![CDATA[<p>如何在麻将桌上赢你们公司总裁五块钱？</p><p>打五块钱一胡的麻将。你运筹帷幄，察言观色，声东击西，最后凭借高超的牌技和一点点运气，赢回这五块钱。观者都为你赞叹，牌技真好。</p><p>但我们的问题是，如何在麻将桌上赢你们公司总裁五块钱？里面最大的挑战其实是：你的总裁凭什么要跟你坐一桌打麻将。</p><a id="more"></a><p>没有想到这隐含一问的人，都觉得牌技是取胜的关键。想到的人才知道，想秀出你的牌技，得先上得了桌才行。很简单的道理，人有时候意识不到，因为大多数人开始思考这个问题的时候，他们已经坐定在某张桌子跟前，眼前就只有这张桌上的一局牌了。他们看见左手边的牌友艺高人胆大，打得风声水起，看见右边的牌友缩手缩脚，输得一塌糊涂，于是他们觉得牌技是这个世界上最重要的事情，就像他们觉得情商是生活中最重要的东西一样。不知道在人生中的某一个时刻，他们会不会自问：如果这个世界上还存在其它生活方式呢？</p><p>智商本身意义不大，但是智商与努力能带给人更好的专业技术，把人带到更高的平台上。情商决定你怎么和人打交道，但是你的技术和专业从最一开始就决定你和谁打交道。情商高永远不会吃亏的，它特别有用，情商低很危险，会限制人的发展。但这一切的前提是，99%的人，只能把他们的情商施展在自己身处的层次上。</p><p>某A顶尖高校毕业，在银行业工作了十年，而后MBA，会三国语言，在多个国家工作过。之前和他的执行经理说起过这个人。因为我和执行经理私交比较好，他比较隐晦的提出，这个人工作还行，但和整个团队都不是很融洽，简而言之就是有点儿“奇葩”。当时我内心也是唏嘘了一阵，这么漂亮的简历，可能就因为和人都处不来，这辈子也就是小中层到头了，情商真的很重要。但是我写这个故事，是想告诉大家，这个人情商不够，受到限制，所以这辈子只能是年薪八十万港币的小职员了，只能在青衣买一个二手小房。你明白吗？大多数自认情商很高的人，这辈子有没有可能达到年薪八十万港币的水准？奋斗一辈子有没有可能在香港买房？没有。</p><p>和一个做教授的朋友聊天，说起某人最近在学界混得风声水起，朋友非常不忿，说其研究品味不高，发的都是灌水文章，因为“会来事儿”，受到大佬赏识，“给”了他一个关键的委员会的位子和其它一些好处，后来就顺风顺水了。朋友就是那种闷头做研究的闷葫芦，有时候说话太直，我也接受不了。他读博的时候就因为这样的原因换过一次老板，七八年才毕业，现在还在等副教授。没到副教授，年年都得跟系里汇报自己的工作进度，接受评审，大抵是有些不得志的。我写这个故事，就是告诉大家，我这个朋友情商不行，哪怕是在学界也不能如鱼得水，没有大佬提携，自己一个人苦苦打拼，可能终其一生，也不过就是211高校的一名普通教授，而已。大多数自认情商很高的人，终其一生，能成为高校教授吗？不能。</p><p>上面的例子可能太玄乎了，说个现实点儿的。之前跟京城某企业家吃饭，说起家里的子侄小辈，企业家很感慨，说自己哥哥一辈子不容易，他要把哥哥的两个儿子照顾好。说大侄子“特别好”，怎么好？对爷爷奶奶孝顺，有眼色。企业家在北京多年，不能回家尽孝，大侄子就经常陪着爷爷奶奶来北京小住几天，照顾得妥妥帖帖，他看得心里喜欢，大侄子县城的房子是他给出的钱。二侄子呢？“这孩子实在”。吃饭的时候二侄子也在，我也看出来了，小子确实“实在”，吃饭的时候也不说话，干坐着，席间他叔提醒了他多次“xxx, 给咱们把酒倒上”。故事讲完了，看出来问题在哪儿了吗？大侄子有眼色，在县城加油站工作。二侄子没眼色，却给安排在北京工作，跟我们坐一桌吃饭。因为什么？大侄子没念出书来，二侄子是本科毕业。再护犊子，再偏袒，再喜欢，没念出书来，给点儿钱还行，但真没办法培养你。</p><p>大家都是MBA，你情商高，升职就比别人快。大家都拿到教职，你情商高，你就能整合更多的资源。大家都是名校毕业专业对口的本科生，你情商高，你就能拿到更好的工作。可即便是这些人，也只能把目光局限在自己眼跟前的这一摊事情上，而忘了，可能80%的成败，已经由你所能到达的平台所决定了。</p><p>自己觉得情商很高，靠情商做成很多事情的朋友，也可以深刻反思一下，你之所以能搞定这么多人，谈成这么多合作，真的是全凭一张嘴？你们自己觉得情商高，可是全中国情商比你们高的人不知道有多少，领导的司机，服装店卖衣服的明星销售员，论察言观色，论把握人的心理，他们不知道比你高到哪里去了。对高大上的知乎用户说，虽然你只是个普通人，但经你手的资源，你接触的人，肯定还是和上述这些摸爬滚打的人不一样的。他们过得很辛苦，而你有可能会小有成就。区别真的不是拿情商解释得了的，尤其是在今天，市场经济愈发成熟，产业不断升级转型，小学毕业一夜爆富越来越不可能。身无一技之长，空有和人打交道的本事的人，生存空间会越来越小。</p><p>天赋异禀 的人，即便早年走了弯路，读书没读好，早期的几步没走好，也能迎头赶上，突破平台对自己的限制。而越是普通人，突破平台对自己的限制的可能就越低，你上到的平台有多高，你大概就能成就多高。再加上如今甚嚣尘上的阶级固化说，你再不靠自己的智力劳动，再不重视专业资本的积累，再不上到一个适合发展的平台，你要到哪里去贩卖你的情商？</p><p>生活中有很多后辈就情商这个问题问过我，我都礼貌并隐晦地指出，不要瞎想那么多，先好好努力，好好提高自己，考上本科，学好知识，工作里面好好积累经验，以后争取在你们当地的业内有一点儿话语权。</p><p>不礼貌一点的说法，就是要争取上桌，先上了桌再说。</p><p>跟总裁打麻将输了的人，那也是跟总裁打麻将输了。跟阿土伯打麻将赢了的人，也不过就是赢了阿土伯而已。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">作者：公子V</span><br><span class="line">链接：https://www.zhihu.com/question/20252336/answer/375473310</span><br><span class="line">来源：知乎</span><br><span class="line">著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;如何在麻将桌上赢你们公司总裁五块钱？&lt;/p&gt;
&lt;p&gt;打五块钱一胡的麻将。你运筹帷幄，察言观色，声东击西，最后凭借高超的牌技和一点点运气，赢回这五块钱。观者都为你赞叹，牌技真好。&lt;/p&gt;
&lt;p&gt;但我们的问题是，如何在麻将桌上赢你们公司总裁五块钱？里面最大的挑战其实是：你的总裁凭什么要跟你坐一桌打麻将。&lt;/p&gt;
    
    </summary>
    
      <category term="美文" scheme="yunke.science/categories/%E7%BE%8E%E6%96%87/"/>
    
    
      <category term="情商" scheme="yunke.science/tags/%E6%83%85%E5%95%86/"/>
    
      <category term="智商" scheme="yunke.science/tags/%E6%99%BA%E5%95%86/"/>
    
  </entry>
  
  <entry>
    <title>云原生时代下的12-Factor应用与实践</title>
    <link href="yunke.science/2018/04/24/apps12factor/"/>
    <id>yunke.science/2018/04/24/apps12factor/</id>
    <published>2018-04-24T14:40:30.000Z</published>
    <updated>2018-04-25T04:00:12.000Z</updated>
    
    <content type="html"><![CDATA[<p>如今，软件通常会作为一种服务来交付，它们被称为网络应用程序，或软件即服务（SaaS）。12-Factor 为构建如下的 SaaS 应用提供了方法论：</p><ul><li>使用<strong>标准化</strong>流程自动配置，从而使新的开发者花费最少的学习成本加入这个项目。</li><li>和操作系统之间尽可能的<strong>划清界限</strong>，在各个系统中提供<strong>最大的可移植性</strong>。</li><li>适合<strong>部署</strong>在现代的<strong>云计算平台</strong>，从而在服务器和系统管理方面节省资源。</li><li>将开发环境和生产环境的<strong>差异降至最低</strong>，并使用<strong>持续交付</strong>实施敏捷开发。</li><li>可以在工具、架构和开发流程不发生明显变化的前提下实现<strong>扩展</strong>。</li></ul><p>这套理论适用于任意语言和后端服务（数据库、消息队列、缓存等）开发的应用程序。</p><a id="more"></a><p><ul class="markdownIt-TOC"><li><a href="#%E8%83%8C%E6%99%AF">背景</a></li><li><a href="#i-%E5%9F%BA%E5%87%86%E4%BB%A3%E7%A0%81">[I. 基准代码]</a></li><li><a href="#ii-%E4%BE%9D%E8%B5%96">[II. 依赖]</a></li><li><a href="#iii-%E9%85%8D%E7%BD%AE">[III. 配置]</a></li><li><a href="#iv-%E5%90%8E%E7%AB%AF%E6%9C%8D%E5%8A%A1">[IV. 后端服务]</a></li><li><a href="#v-%E6%9E%84%E5%BB%BA%E5%8F%91%E5%B8%83%E8%BF%90%E8%A1%8C">[V. 构建，发布，运行]</a></li><li><a href="#vi-%E8%BF%9B%E7%A8%8B">[VI. 进程]</a></li><li><a href="#vii-%E7%AB%AF%E5%8F%A3%E7%BB%91%E5%AE%9A">[VII. 端口绑定]</a></li><li><a href="#viii-%E5%B9%B6%E5%8F%91">[VIII. 并发]</a></li><li><a href="#ix-%E6%98%93%E5%A4%84%E7%90%86">[IX. 易处理]</a></li><li><a href="#x-%E5%BC%80%E5%8F%91%E6%B5%8B%E8%AF%95%E7%8E%AF%E5%A2%83%E4%B8%8E%E7%BA%BF%E4%B8%8A%E7%8E%AF%E5%A2%83%E7%AD%89%E4%BB%B7">[X. 开发测试环境与线上环境等价]</a></li><li><a href="#xi-%E6%97%A5%E5%BF%97">[XI. 日志]</a></li><li><a href="#xii-%E7%AE%A1%E7%90%86%E8%BF%9B%E7%A8%8B">[XII. 管理进程]</a></li></ul></p><h2><span id="背景"> 背景</span></h2><p>==========</p><p>本文的贡献者者参与过数以百计的应用程序的开发和部署，并通过 <a href="http://www.heroku.com/" target="_blank" rel="noopener">Heroku</a> 平台间接见证了数十万应用程序的开发，运作以及扩展的过程。</p><p>本文综合了我们关于 SaaS 应用几乎所有的经验和智慧，是开发此类应用的理想实践标准，并特别关注于应用程序如何保持良性成长，开发者之间如何进行有效的代码协作，以及如何 <a href="http://blog.heroku.com/archives/2011/6/28/the_new_heroku_4_erosion_resistance_explicit_contracts/" target="_blank" rel="noopener">避免软件污染</a> 。</p><p>12-Factor，是由Heroku创始人Adam Wiggins首次提出并开源，并由众多经验丰富的开发者共同完善，这综合了他们关于SaaS应用几乎所有的经验和智慧，是开发此类应用的理想实践标准。</p><p>12-Factor 全称叫 The Twelve-Factor App，它定义了一个优雅的互联网应用在设计过程中，需要遵循的一些基本原则，和 Cloud-Native 有异曲同工之处。其中文翻译不少，我觉得“十二要素”或“十二原则”比较贴切，</p><img src="/2018/04/24/apps12factor/e7c173d8879951c7ae5ab61c49f1bde1.png" title="The Twelve-Factor App"><h2><span id="i-基准代码"> [I. 基准代码]</span></h2><p><strong>一份基准代码，多份部署</strong></p><p>每一个部署的应用都在版本控制代码库中被追踪。在多个部署环境中,会有多种部署实例,单个应用只有一份代码库,多份部署相当于运行了该应用的多个实例,比如开发环境一个实例,测试环境、生产环境都有一个实例。</p><p>实际上,在云计算架构中,所有的基础设施都是代码配置,即Infrastructure as Code(laC),整个应用通过配置文件就可以编排出来,而不再需要手工的干预,做到基础服务也是可以追踪的。</p><h2><span id="ii-依赖"> [II. 依赖]</span></h2><p><strong>显式声明依赖关系</strong></p><p>应用程序不会隐式依赖系统级的类库,通过依赖清单声明所有依赖项。通过依赖隔离，确保程序不会存在调用系统中未声明的依赖项,清单统一应用到生产和开发环境。<br>比如通过合适的工具(例如Maven, Bundler, NPM),应用可以很清晰地对部署环境,公开和隔绝依赖性,而不是模糊地对部署环境产生依赖性。</p><p>在容器应用中,所有应用的依赖和安装都是通过DockerFile来完成声明的,通过配置,能明确把依赖关系,包括版本都明确地图形化展示出来,不存在黑盒。</p><h2><span id="iii-配置"> [III. 配置]</span></h2><p><strong>在环境中存储配置</strong></p><p>环境变量是一种清楚、容易理解和标准化的配置方法,将应用的配置存储于环境变量中,保证配置排除在代码之外,或者其他可能在部署环境(例如研发、展示、生产)之间区别的任何代码,可以通过操作系统级的环境变量来注入。</p><p>实例根据不同的环境配置运行在不同的环境中,此外,实现配置即代码,在云环境中,无论是统一的配置中心还是分布式的配置中心都有好的实践方式,比如Docker的环境变量使用。</p><h2><span id="iv-后端服务"> [IV. 后端服务]</span></h2><p><strong>把后端服务当作附加资源</strong></p><p>不用区别对待本地或第三方服务,统一把依赖的后端作为一种服务来对待。<br>例如数据库或者消息代理,作为附加资源,同等地在各种环境中被消耗。比如在云架构的基础服务中,计算、网络、存储资源都可以看作是一种服务去对待使用即可,不用区分是远程还是本地的。</p><h2><span id="v-构建发布运行"> [V. 构建，发布，运行]</span></h2><p><strong>严格分离构建和运行</strong></p><p>应用严格区分构建、发布、运行这3个阶段。3个阶段是严格分开的,一个阶段对应做一件事情,每个阶段有很明确的实现功能。<br>云原生应用的构建流程可以把发布配置挪到开发阶段,包括实际的代码构建和运行应用所需的生产环境配置。在云原生应用中,基于容器的Build-Ship-Run和这3个阶段完全吻合,也是Docker对本原则的最佳实践。</p><h2><span id="vi-进程"> [VI. 进程]</span></h2><p><strong>以一个或多个无状态进程运行应用</strong></p><p>进程必须无状态且无共享,即云应用以一个或多个无状态不共享的程序运行。任何必要状态都被服务化到后端服务中(缓存、对象存储等)。</p><p>所有的应用在设计时就认为随时随地会失败,面向失败而设计,随时拉起或消失,特别是在弹性扩容的阶段。</p><h2><span id="vii-端口绑定"> [VII. 端口绑定]</span></h2><p><strong>通过端口绑定提供服务</strong></p><p>不依赖于任何网络服务器就可以创建一个面向网络的服务,每个应用的功能都很齐全,通过端口绑定对外提供所有服务,比如Web应用通过端口绑定(Port binding)来提供服务,并监听发送至该端口的请求(包括HTTP)。</p><p>在容器应用中,应用统一通过暴露端口来服务,尽量避免通过本地文件或进程来通信,每种服务通过服务发现而服务。</p><h2><span id="viii-并发"> [VIII. 并发]</span></h2><p><strong>通过进程模型进行扩展</strong></p><p>进程可以看作一等公民,并发性即可以依靠水平扩展应用程序来实现,通过进程模型进行扩展,并且具备无共享、水平分区的特性。<br>在互联网的服务中,业务的爆发性随时可能发生,因此不太可能通过硬件扩容来随时扩展。</p><img src="/2018/04/24/apps12factor/process-types.png" title="进程模型"><h2><span id="ix-易处理"> [IX. 易处理]</span></h2><p><strong>快速启动和优雅终止可最大化健壮性</strong><br>所有应用的架构设计都需要支持能随时销毁的特点,和状态的无关性保持一致,允许系统快速弹性扩展、改变部署及故障恢复等。</p><p>在云环境中,由于业务的高低峰值经常需要能实现快速灵活、弹性的伸缩应用,以及不可控的硬件因素等,应用可能随时会发生故障,因此应用在架构设计上需要尽可能无状态,应用能随时随地拉起,也能随时随地销毁,同时保证进程最小启动时间和架构的可弃性,也可以提供更敏捷的发布及扩展过程,</p><h2><span id="x-开发测试环境与线上环境等价"> [X. 开发测试环境与线上环境等价]</span></h2><p><strong>尽可能的保持开发，预发布，线上环境相同</strong></p><p>必须缩小本地与线上差异,确保环境的一致性,保持研发、测试和生产环境尽可能相似,这样可以提供应用的持续交付和部署服务,</p><p>在容器化应用中,通过文件构建的环境运行能做到版本化,因此保证各个不同环境的差异性,同时还能大大减少环境不同带来的排错等成本沟通问题。</p><h2><span id="xi-日志"> [XI. 日志]</span></h2><p><strong>把日志当作事件流</strong></p><p>每一个运行的进程都会直接标准输出(stdout)和错误输出(stderr)事件流,还可以将日志当作事件流作为数据源,通过集中服务,执行环境收集、聚合、索引和分析这些事件。</p><p>日志是系统运行状态的部分体现,无论在系统诊断、业务跟踪还是后续大数据服务中, Docker提供标准的日志服务,用户可以根据需求做自定义的插件开发来处理日志。</p><h2><span id="xii-管理进程"> [XII. 管理进程]</span></h2><p><strong>后台管理任务当作一次性进程运行</strong><br>管理或维护应用的运行状态是软件维护的基础部分,比如数据库迁移、健康检查、安,全巡检等,在与应用长期运行的程序相同环境中,作为一次性程序运行。</p><p>在应用架构模式中,比如Kuberetes里面的Pod资源或者docker exec,可以随着其他的应用程序一起发布或在出现异常诊断时能通过相关的程序去管理其状态。</p><p>参考链接：</p><ol><li><a href="http://dockone.io/article/2093" target="_blank" rel="noopener">http://dockone.io/article/2093</a></li><li><a href="https://github.com/bingohuang/12factor-gitbook" target="_blank" rel="noopener">https://github.com/bingohuang/12factor-gitbook</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;如今，软件通常会作为一种服务来交付，它们被称为网络应用程序，或软件即服务（SaaS）。12-Factor 为构建如下的 SaaS 应用提供了方法论：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用&lt;strong&gt;标准化&lt;/strong&gt;流程自动配置，从而使新的开发者花费最少的学习成本加入这个项目。&lt;/li&gt;
&lt;li&gt;和操作系统之间尽可能的&lt;strong&gt;划清界限&lt;/strong&gt;，在各个系统中提供&lt;strong&gt;最大的可移植性&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;适合&lt;strong&gt;部署&lt;/strong&gt;在现代的&lt;strong&gt;云计算平台&lt;/strong&gt;，从而在服务器和系统管理方面节省资源。&lt;/li&gt;
&lt;li&gt;将开发环境和生产环境的&lt;strong&gt;差异降至最低&lt;/strong&gt;，并使用&lt;strong&gt;持续交付&lt;/strong&gt;实施敏捷开发。&lt;/li&gt;
&lt;li&gt;可以在工具、架构和开发流程不发生明显变化的前提下实现&lt;strong&gt;扩展&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这套理论适用于任意语言和后端服务（数据库、消息队列、缓存等）开发的应用程序。&lt;/p&gt;
    
    </summary>
    
    
      <category term="架构" scheme="yunke.science/tags/%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>nginx 配置性能优化</title>
    <link href="yunke.science/2018/04/23/nginx-optimize/"/>
    <id>yunke.science/2018/04/23/nginx-optimize/</id>
    <published>2018-04-23T08:24:49.000Z</published>
    <updated>2018-04-23T08:26:33.000Z</updated>
    
    <content type="html"><![CDATA[<p>大多数的Nginx安装指南告诉你如下基础知识——通过apt-get安装，修改这里或那里的几行配置，好了，你已经有了一个Web服务器了。而且，在大多数情况下，一个常规安装的Nginx对你的网站来说已经能很好地工作了。然而，如果你真的想挤压出Nginx的性能，你必须更深入一些。</p><a id="more"></a><p><ul class="markdownIt-TOC"><li><a href="#worker_processes">worker_processes</a></li><li><a href="#worker_connections">worker_connections</a></li><li><a href="#buffers">Buffers</a></li><li><a href="#http-%E6%A8%A1%E5%9D%97">HTTP 模块</a></li><li><a href="#%E6%97%A5%E5%BF%97">日志</a></li><li><a href="#timeouts">Timeouts</a></li><li><a href="#%E8%BF%9E%E6%8E%A5%E6%95%B0%E9%99%90%E5%88%B6">连接数限制</a></li><li><a href="#gzip-%E5%8E%8B%E7%BC%A9">gzip 压缩</a></li><li><a href="#open_file_cache-%E5%92%8C-static_file_caching">open_file_cache 和 Static_File_Caching</a></li><li><a href="#%E4%B8%80%E4%B8%AA%E5%AE%8C%E6%95%B4%E7%9A%84%E9%85%8D%E7%BD%AE">一个完整的配置</a></li></ul></p><p>在本文中，我们将分享Nginx配置性能优化的方法，需要注意一点，这不是一个全面的微调指南。这是一个简单的预览——那些可以通过微调来提高性能设置的概述。</p><p><strong>对于Nginx的调优，可以大致从如下指令着手：</strong></p><ol><li>进程数 worker_processes</li><li>连接数 worker_connections</li><li>缓存大小 Buffers</li><li>超时时间 Timeouts</li><li>压缩传输 Gzip Compression</li><li>静态文件缓存 Static File Caching</li><li>日志文件 logging</li></ol><h2><span id="worker_processes"> worker_processes</span></h2><p>Nginx.conf文件中，Nginx中有少数的几个高级配置在模块部分之上。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">user www-data;  </span><br><span class="line">pid /var/run/nginx.pid;  </span><br><span class="line">worker_processes auto;  </span><br><span class="line">worker_rlimit_nofile 100000;</span><br></pre></td></tr></table></figure><p>user和pid应该按默认设置 - 我们不会更改这些内容，因为更改与否没有什么不同。</p><p>worker_processes 定义了nginx对外提供web服务时的worker进程数。最优值取决于许多因素，包括（但不限于）CPU核的数量、存储数据的硬盘数量及负载模式。不能确定的时候，将其设置为可用的CPU内核数将是一个好的开始（设置为“auto”将尝试自动检测它）。</p><p>worker_rlimit_nofile 更改worker进程的最大打开文件数限制。如果没设置的话，这个值为操作系统的限制。设置后你的操作系统和Nginx可以处理比“ulimit -a”更多的文件，所以把这个值设高，这样nginx就不会有“too many open files”问题了。</p><h2><span id="worker_connections"> worker_connections</span></h2><p>events模块中包含Nginx中所有处理连接的设置。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">events &#123;  </span><br><span class="line">worker_connections 2048;  </span><br><span class="line">multi_accept on;  </span><br><span class="line">use epoll;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>worker_connections 设置可由一个worker进程同时打开的最大连接数。如果设置了上面提到的worker_rlimit_nofile，我们可以将这个值设得很高。</p><p>记住，最大客户数也由系统的可用socket连接数限制（~ 64K），所以设置不切实际的高没什么好处。</p><p>multi_accept 告诉nginx收到一个新连接通知后接受尽可能多的连接。</p><p>use 设置用于复用客户端线程的轮询方法。如果你使用Linux 2.6+，你应该使用epoll。如果你使用*BSD，你应该使用kqueue。</p><p>（值得注意的是如果你不知道Nginx该使用哪种轮询方法的话，它会选择一个最适合你操作系统的）</p><h2><span id="buffers"> Buffers</span></h2><p>Buffers：另一个很重要的参数为buffer，如果buffer太小，Nginx会不停的写一些临时文件，这样会导致磁盘不停的去读写，现在我们先了解设置buffer的一些相关参数：</p><ul><li>client_body_buffer_size:允许客户端请求的最大单个文件字节数</li><li>client_header_buffer_size:用于设置客户端请求的Header头缓冲区大小，大部分情况1KB大小足够</li><li>client_max_body_size:设置客户端能够上传的文件大小，默认为1m</li><li>large_client_header_buffers:该指令用于设置客户端请求的Header头缓冲区大小</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">client_body_buffer_size 10K;</span><br><span class="line">client_header_buffer_size 1k;</span><br><span class="line">client_max_body_size 8m;</span><br><span class="line">large_client_header_buffers 2 1k;</span><br></pre></td></tr></table></figure><h2><span id="http-模块"> HTTP 模块</span></h2><p>HTTP模块控制着Nginx http处理的所有核心特性。因为这里只有很少的配置，所以我们只节选配置的一小部分。所有这些设置都应该在http模块中，甚至你不会特别的注意到这段设置。</p><pre><code>http {  server_tokens off;  sendfile on;  tcp_nopush on;  tcp_nodelay on;  ...  }  </code></pre><p>server_tokens  并不会让nginx执行的速度更快，但它可以关闭在错误页面中的nginx版本数字，这样对于安全性是有好处的。</p><p>sendfile 可以让sendfile()发挥作用。sendfile()可以在磁盘和TCP socket之间互相拷贝数据(或任意两个文件描述符)。Pre-sendfile是传送数据之前在用户空间申请数据缓冲区。之后用read()将数据从文件拷贝到这个缓冲区，write()将缓冲区数据写入网络。sendfile()是立即将数据从磁盘读到OS缓存。因为这种拷贝是在内核完成的，sendfile()要比组合read()和write()以及打开关闭丢弃缓冲更加有效(更多有关于sendfile)。</p><p>tcp_nopush 告诉nginx在一个数据包里发送所有头文件，而不一个接一个的发送。</p><p>tcp_nodelay 告诉nginx不要缓存数据，而是一段一段的发送–当需要及时发送数据时，就应该给应用设置这个属性，这样发送一小块数据信息时就不能立即得到返回值。</p><h2><span id="日志"> 日志</span></h2><p>access_log设置Nginx是否将存储访问日志。关闭这个选项可以让读取磁盘IO操作更快。<br>修改配置文件将该功能关闭，并记录错误的日志时间。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">access_log off;  </span><br><span class="line">error_log /var/log/nginx/error.log crit;</span><br></pre></td></tr></table></figure><h2><span id="timeouts"> Timeouts</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">keepalive_timeout 10;  </span><br><span class="line">client_header_timeout 10;  </span><br><span class="line">client_body_timeout 10;  </span><br><span class="line">reset_timedout_connection on;  </span><br><span class="line">send_timeout 10;</span><br></pre></td></tr></table></figure><p>keepalive_timeout  给客户端分配keep-alive链接超时时间。服务器将在这个超时时间过后关闭链接。我们将它设置低些可以让ngnix持续工作的时间更长。</p><p>client_header_timeout 和client_body_timeout 设置请求头和请求体(各自)的超时时间。我们也可以把这个设置低些。</p><p>reset_timeout_connection 告诉nginx关闭不响应的客户端连接。这将会释放那个客户端所占有的内存空间。</p><p>send_timeout 指定客户端的响应超时时间。这个设置不会用于整个转发器，而是在两次客户端读取操作之间。如果在这段时间内，客户端没有读取任何数据，nginx就会关闭连接。</p><h2><span id="连接数限制"> 连接数限制</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">limit_conn_zone $binary_remote_addr zone=addr:5m;  </span><br><span class="line">limit_conn addr 100;</span><br></pre></td></tr></table></figure><p>limit_conn_zone 设置用于保存各种key（比如当前连接数）的共享内存的参数。5m就是5兆字节，这个值应该被设置的足够大以存储（32K<em>5）32byte状态或者（16K</em>5）64byte状态。</p><p>limit_conn 为给定的key设置最大连接数。这里key是addr，我们设置的值是100，也就是说我们允许每一个IP地址最多同时打开有100个连接。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">include /etc/nginx/mime.types;  </span><br><span class="line">default_type text/html;  </span><br><span class="line">charset UTF-8;</span><br></pre></td></tr></table></figure><p>include 只是一个在当前文件中包含另一个文件内容的指令。这里我们使用它来加载稍后会用到的一系列的MIME类型。</p><p>default_type 设置文件使用的默认的MIME-type。</p><p>charset 设置我们的头文件中的默认的字符集</p><h2><span id="gzip-压缩"> gzip 压缩</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">gzip on;  </span><br><span class="line">gzip_disable &quot;msie6&quot;;  </span><br><span class="line"># gzip_static on;  </span><br><span class="line">gzip_proxied expired no-cache no-store private auth;  </span><br><span class="line">gzip_min_length 1000;  </span><br><span class="line">gzip_comp_level 4;  </span><br><span class="line">gzip_types text/plain text/css application/json application/x-javascript text/xml application/xmapplication/xml+rss text/javascript;</span><br></pre></td></tr></table></figure><p>开启Gzip，gzip可以帮助Nginx减少大量的网络传输工作，另外要注意gzip_comp_level的设置，太高的话，Nginx服务会浪费CPU的执行周期。</p><ul><li>gzip_disable 为指定的客户端禁用gzip功能。我们设置成IE6或者更低版本以使我们的方案能够广泛兼容。</li><li>gzip_static 告诉nginx在压缩资源之前，先查找是否有预先gzip处理过的资源。这要求你预先压缩你的文件（在这个例子中- 被注释掉了），从而允许你使用最高压缩比，这样nginx就不用再压缩这些文件了（想要更详尽的gzip_static的信息，请点- 击这里）。</li><li>gzip_proxied 允许或者禁止压缩基于请求和响应的响应流。我可以们设置为any，意味着将会压缩所有的请求。</li><li>gzip_min_length 设置对数据启用压缩的最少字节数。如果一个请求小于1000字节，我们最好不要压缩它，因为压缩这些小- 的数据会降低处理此请求的所有进程的速度。</li><li>gzip_comp_level 设置数据的压缩等级。这个等级可以是1-9之间的任意数值，9是最慢但是压缩比最大的。我们设置为4，这- 是一个比较折中的设置。</li><li>gzip_type 设置需要压缩的数据格式。上面例子中已经有一些了，你也可以再添加更多的格式。</li></ul><h2><span id="open_file_cache-和-static_file_caching"> open_file_cache 和 Static_File_Caching</span></h2><p>打开文件缓存：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># cache informations about file descriptors, frequently accessed files  </span><br><span class="line"># can boost performance, but you need to test those values  </span><br><span class="line">open_file_cache max=100000 inactive=20s;  </span><br><span class="line">open_file_cache_valid 30s;  </span><br><span class="line">open_file_cache_min_uses 2;  </span><br><span class="line">open_file_cache_errors on;  </span><br><span class="line">##  </span><br><span class="line"># Virtual Host Configs  </span><br><span class="line"># aka our settings for specific servers  </span><br><span class="line">##  </span><br><span class="line">include /etc/nginx/conf.d/*.conf;  </span><br><span class="line">include /etc/nginx/sites-enabled/*;</span><br></pre></td></tr></table></figure><ul><li>open_file_cache 打开缓存的同时也指定了缓存最大数目，以及缓存的时间。我们可以设置一个相对高的最大时间，这样我们可以在它们不活动超过20秒后清除掉。</li><li>open_file_cache_valid 在 open_file_cache 中指定检测正确信息的间隔时间。</li><li>open_file_cache_min_uses 定义了open_file_cache中指令参数不活动时间期间里最小的文件数。</li><li>open_file_cache_errors 指定了当搜索一个文件时是否缓存错误信息，也包括再次给配置中添加文件。我们也包括了服务器模块，这些是在不同文件中定义的。如果你的服务器模块不在这些位置，你就得修改这一行来指定正确的位置。</li></ul><p>静态文件缓存：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">location ~* .(jpg|jpeg|png|gif|ico|css|js)$ &#123;</span><br><span class="line">    expires 365d;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2><span id="一个完整的配置"> 一个完整的配置</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">user www-data;  </span><br><span class="line">pid /var/run/nginx.pid;  </span><br><span class="line">worker_processes auto;  </span><br><span class="line">worker_rlimit_nofile 100000;  </span><br><span class="line">events &#123;  </span><br><span class="line">worker_connections 2048;  </span><br><span class="line">multi_accept on;  </span><br><span class="line">use epoll;  </span><br><span class="line">&#125;  </span><br><span class="line">http &#123;  </span><br><span class="line">server_tokens off;  </span><br><span class="line">sendfile on;  </span><br><span class="line">tcp_nopush on;  </span><br><span class="line">tcp_nodelay on;  </span><br><span class="line">access_log off;  </span><br><span class="line">error_log /var/log/nginx/error.log crit;  </span><br><span class="line">keepalive_timeout 10;  </span><br><span class="line">client_header_timeout 10;  </span><br><span class="line">client_body_timeout 10;  </span><br><span class="line">reset_timedout_connection on;  </span><br><span class="line">send_timeout 10;  </span><br><span class="line">limit_conn_zone $binary_remote_addr zone=addr:5m;  </span><br><span class="line">limit_conn addr 100;  </span><br><span class="line">include /etc/nginx/mime.types;  </span><br><span class="line">default_type text/html;  </span><br><span class="line">charset UTF-8;  </span><br><span class="line">gzip on;  </span><br><span class="line">gzip_disable &quot;msie6&quot;;  </span><br><span class="line">gzip_proxied any;  </span><br><span class="line">gzip_min_length 1000;  </span><br><span class="line">gzip_comp_level 6;  </span><br><span class="line">gzip_types text/plain text/css application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript;  </span><br><span class="line">open_file_cache max=100000 inactive=20s;  </span><br><span class="line">open_file_cache_valid 30s;  </span><br><span class="line">open_file_cache_min_uses 2;  </span><br><span class="line">open_file_cache_errors on;  </span><br><span class="line">include /etc/nginx/conf.d/*.conf;  </span><br><span class="line">include /etc/nginx/sites-enabled/*;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>编辑完配置后，确认重启nginx使设置生效。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># nginx -s reload</span><br></pre></td></tr></table></figure><p>参考：</p><ol><li><a href="http://yuedu.163.com/news_reader/#/~/source?id=a4a21dba-8c0b-4404-b48f-53d526aa792b_1&amp;cid=004d54a727df4ab5a40b21a8c6481693_1" target="_blank" rel="noopener">Nginx配置性能优化的方法<br></a></li><li><a href="https://zhuanlan.zhihu.com/p/27288422" target="_blank" rel="noopener">Nginx性能优化</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;大多数的Nginx安装指南告诉你如下基础知识——通过apt-get安装，修改这里或那里的几行配置，好了，你已经有了一个Web服务器了。而且，在大多数情况下，一个常规安装的Nginx对你的网站来说已经能很好地工作了。然而，如果你真的想挤压出Nginx的性能，你必须更深入一些。&lt;/p&gt;
    
    </summary>
    
      <category term="nginx" scheme="yunke.science/categories/nginx/"/>
    
    
      <category term="nginx" scheme="yunke.science/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>zabbix 3.4 新特性：从属监控项</title>
    <link href="yunke.science/2018/04/22/zabbix-depend/"/>
    <id>yunke.science/2018/04/22/zabbix-depend/</id>
    <published>2018-04-22T11:33:31.000Z</published>
    <updated>2018-04-22T11:38:04.000Z</updated>
    
    <content type="html"><![CDATA[<p>zabbix 3.4 新特性：从属依赖监控项。<br>一个监控项一次收集多个指标的场景，或者同时收集相关指标，</p><a id="more"></a><p>例如：</p><ul><li>单个内核的CPU使用率</li><li>流入/流出/总的网络流量</li></ul><p>为了支持这项功能，Zabbix现在支持从属监控项目。从属监控项有一个主监控项，它在一个查询策略中收集所有的指标。从属监控项使用主监控项的数据来收集她们的数据，主监控项的新数据值自动填充从属监控项的值。</p><hr><p>Zabbix预处理选项可用于从主项目数据中提取依赖项目所需的部分。</p><p><strong>预处理由Zabbix 3.4中添加的预处理管理器进程管理，以及执行预处理步骤的进程</strong>。 来自不同数据收集器的所有值（有或没有预处理）都会在添加到历史记录缓存之前通过预处理管理器。<br>在数据收集器（轮询器，捕获器等）和预处理过程之间使用基于套接字的IPC通信。</p><p>只有Zabbix server执行预处理步骤并处理相关项目。</p><p>任何类型的项目，甚至是依赖项目，都可以设置为主项目。 可以使用其他级别的依赖项目来从现有依赖项目的值中提取较小的部分。</p><h3><span id="限制"> 限制</span></h3><ol><li>只允许相同的主机（模板/发现规则）依赖关系</li><li>一个主项目的相关项目的最大数量限制为999</li><li>最多允许3个相关性级别</li><li>依赖于模板的主项目的从属项目将不会导出到XML</li></ol><h3><span id="项目配置"> 项目配置</span></h3><p>依赖项取决于其依赖的主项目的数据。 这就是为什么主项目必须先配置（或存在）的原因：</p><ul><li>转到：配置→主机</li><li>点击主机所在的项目</li><li>点击创建项目</li><li>在表单中输入项目的参数</li></ul><img src="/2018/04/22/zabbix-depend/master_item.png" title="天青色等烟雨"><ul><li>点击添加保存主项目。</li><li>然后你可以配置一个依赖项目：</li></ul><ol><li>点击创建项目</li><li>Type 选择 Dependent item</li></ol><img src="/2018/04/22/zabbix-depend/dependent_item.png" title="天青色等烟雨"><p>需要依赖项目的特定信息的字段是：</p><table><thead><tr><th>选项</th><th>说明</th></tr></thead><tbody><tr><td>Type</td><td>选择 依赖项Dependent item.</td></tr><tr><td>Key</td><td>输入将用于识别item的key.</td></tr><tr><td>Master</td><td>选择主项目。 主项目值将用于填充相关项目值。</td></tr><tr><td>Type of information</td><td>存储的数据类型</td></tr></tbody></table><p>您可以使用项目值预处理来提取主项目值的必需部分。</p><img src="/2018/04/22/zabbix-depend/dependent_item_preprocessing.png" title="天青色等烟雨"><p>如果不进行预处理，相关项目值将与主项目值完全相同。</p><p>点击添加保存相关项目。</p><p>快速创建依赖项目的快捷方式是使用项目列表中的向导：</p><img src="/2018/04/22/zabbix-depend/dependent_item_wizard.png" title="天青色等烟雨"><h2><span id="显示"> 显示</span></h2><p>在项目列表中，依赖项目以其主项目名称作为前缀显示。</p><img src="/2018/04/22/zabbix-depend/dependent_items.png" title="天青色等烟雨"><p>如果主项目被删除，所有其依赖项目也被删除。</p><p>参考链接：<br><a href="https://www.zabbix.com/documentation/3.4/manual/config/items/itemtypes/dependent_items" target="_blank" rel="noopener">https://www.zabbix.com/documentation/3.4/manual/config/items/itemtypes/dependent_items</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;zabbix 3.4 新特性：从属依赖监控项。&lt;br&gt;
一个监控项一次收集多个指标的场景，或者同时收集相关指标，&lt;/p&gt;
    
    </summary>
    
      <category term="monitor" scheme="yunke.science/categories/monitor/"/>
    
    
      <category term="zabbix" scheme="yunke.science/tags/zabbix/"/>
    
  </entry>
  
  <entry>
    <title>使用kcptun建立UDP隧道传输数据</title>
    <link href="yunke.science/2018/04/22/kcptun4zabbix/"/>
    <id>yunke.science/2018/04/22/kcptun4zabbix/</id>
    <published>2018-04-22T08:07:20.000Z</published>
    <updated>2018-04-22T08:17:48.000Z</updated>
    
    <content type="html"><![CDATA[<p>Kcptun 是一个非常简单和快速的，基于 KCP 协议的 UDP 隧道，它可以将 TCP 流转换为 KCP+UDP 流。而 KCP 是一个快速可靠协议，能以比 TCP 浪费10%-20%的带宽的代价，换取平均延迟降低 30%-40%，且最大延迟降低三倍的传输效果。</p><a id="more"></a><p><ul class="markdownIt-TOC"><li><ul><li><a href="#kcptun-%E5%B7%A5%E4%BD%9C%E7%A4%BA%E6%84%8F%E5%9B%BE">Kcptun 工作示意图：</a></li><li><a href="#dockerfile">Dockerfile</a></li><li><a href="#docker-harbor-%E5%9C%B0%E5%9D%80">docker harbor 地址:</a></li><li><a href="#kcptun-server-install">kcptun server install</a></li><li><a href="#kcptun-client-install">kcptun client install</a></li><li><a href="#%E5%85%B6%E4%BB%96%E4%BD%BF%E7%94%A8%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%8F%82%E6%95%B0%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E">其他使用命令行参数使用说明：</a></li></ul></li></ul></p><p><a href="https://github.com/xtaci/kcptun" target="_blank" rel="noopener">kcptun github 地址</a></p><blockquote><p>Kcptun 是 KCP 协议的一个简单应用，可以用于任意 TCP 网络程序的传输承载，以提高网络流畅度，降低掉线情况。由于 Kcptun 使用 Go 语言编写，内存占用低（经测试，在64M内存服务器上稳定运行），而且适用于所有平台，甚至 Arm 平台。</p></blockquote><h3><span id="kcptun-工作示意图"> Kcptun 工作示意图：</span></h3><p><img src="https://blog.kuoruan.com/wp-content/uploads/2016/06/kcptun-550x159.png" alt="image"></p><p>在实际生产环境中，多台内网主机Zabbix client共用一个出口IP向监控服务器Zabbix server发送监控数据。由于，使用TCP 协议传输数据，端口独占，导致只有一个client发送数据成功。考虑使用 UDP 传输监控数据。<br>拓扑图如下：</p><img src="/2018/04/22/kcptun4zabbix/Snipaste_2018-04-22_16-12-38.png" title="天青色等烟雨"><h3><span id="dockerfile"> Dockerfile</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">FROM alpine</span><br><span class="line">MAINTAINER xmhtops @2017-12-05</span><br><span class="line"></span><br><span class="line"># ADD https://github.com/xtaci/kcptun/releases/download/v20171201/kcptun-linux-amd64-20171201.tar.gz /usr/sbin</span><br><span class="line">ADD kcptun-linux-amd64-20171201.tar.gz /usr/sbin</span><br><span class="line"></span><br><span class="line">CMD [ &apos;server_linux_amd64  --version&apos; ]</span><br></pre></td></tr></table></figure><h3><span id="docker-harbor-地址"> docker harbor 地址:</span></h3><p><a href="harbor.domain.cn/xmht/kcptun">harbor.domain.cn/xmht/kcptun</a></p><h3><span id="kcptun-server-install"> kcptun server install</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># cat docker-compose.yml</span><br><span class="line">version: &apos;2&apos;</span><br><span class="line">services:</span><br><span class="line">  kcptun:</span><br><span class="line">    image: harbor.domain.cn/xmht/kcptun</span><br><span class="line">    container_name: kcptun-server</span><br><span class="line">    ports:</span><br><span class="line">      - listenUDPport:listenUDPport/udp</span><br><span class="line">    volumes:</span><br><span class="line">      - /var/log/kcptun.log:/var/log/kcptun.log</span><br><span class="line">    restart: unless-stopped</span><br><span class="line">    command: server_linux_amd64 -t localIP:localport -l :listenUDPport -mode fast3 --key Passwd --log /var/log/kcptun.log --crypt aes-128</span><br></pre></td></tr></table></figure><p>启动参数说明，需要修改的地方：<br>server_linux_amd64 -t localIP:localport -l :listenUDPport -mode fast3 --key Passwd --log /var/log/kcptun.log --crypt aes-128</p><p>-t localIP:localport 服务端监听的网卡及端口<br>-l :listenUDPport kcptun服务端监听的UDP端口，把接收到的数据传输到localIP:localport<br>–key Passwd kcptun客户端与kcptun服务端的认证密码，必须一致</p><h3><span id="kcptun-client-install"> kcptun client install</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># cat docker-compose.yml</span><br><span class="line">version: &apos;2&apos;</span><br><span class="line">services:</span><br><span class="line">  kcptun:</span><br><span class="line">    image: harbor.domain.cn/xmht/kcptun</span><br><span class="line">    container_name: kcptun-client</span><br><span class="line">    ports:</span><br><span class="line">      - listenTCPport:listenTCPport/tcp</span><br><span class="line">    volumes:</span><br><span class="line">      - /var/log/kcptun.log:/var/log/kcptun.log</span><br><span class="line">    restart: unless-stopped</span><br><span class="line">    command: client_linux_amd64 -r &quot;kcptunserverIP:kcptunserverUDPport&quot; -l &quot;:listenTCPport&quot; -mode fast3 --key passwd --log /var/log/kcptun.log --crypt aes-128</span><br></pre></td></tr></table></figure><p>启动参数说明，需要修改的地方：<br>client_linux_amd64 -r “kcptunserverIP:kcptunserverUDPport” -l “:listenTCPport” -mode fast3 --key passwd --log /var/log/kcptun.log --crypt aes-128</p><p>-r “kcptunserverIP:kcptunserverUDPport”  kcptun服务端的IP和UDP端口<br>-l “:listenTCPport” kcptun客户端监听的TCP端口，把接收到的数据传输到kcptunserverIP:kcptunserverUDPport<br>–key Passwd kcptun客户端与kcptun服务端的认证密码，必须一致</p><h3><span id="其他使用命令行参数使用说明"> 其他使用命令行参数使用说明：</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">$ ./client_darwin_amd64 -h</span><br><span class="line">NAME:</span><br><span class="line">   kcptun - client(with SMUX)</span><br><span class="line"></span><br><span class="line">USAGE:</span><br><span class="line">   client_darwin_amd64 [global options] command [command options] [arguments...]</span><br><span class="line"></span><br><span class="line">VERSION:</span><br><span class="line">   20170120</span><br><span class="line"></span><br><span class="line">COMMANDS:</span><br><span class="line">     help, h  Shows a list of commands or help for one command</span><br><span class="line"></span><br><span class="line">GLOBAL OPTIONS:</span><br><span class="line">   --localaddr value, -l value      local listen address (default: &quot;:12948&quot;)</span><br><span class="line">   --remoteaddr value, -r value     kcp server address (default: &quot;vps:29900&quot;)</span><br><span class="line">   --key value                      pre-shared secret between client and server (default: &quot;it&apos;s a secrect&quot;) [$KCPTUN_KEY]</span><br><span class="line">   --crypt value                    aes, aes-128, aes-192, salsa20, blowfish, twofish, cast5, 3des, tea, xtea, xor, none (default: &quot;aes&quot;)</span><br><span class="line">   --mode value                     profiles: fast3, fast2, fast, normal (default: &quot;fast&quot;)</span><br><span class="line">   --conn value                     set num of UDP connections to server (default: 1)</span><br><span class="line">   --autoexpire value               set auto expiration time(in seconds) for a single UDP connection, 0 to disable (default: 0)</span><br><span class="line">   --mtu value                      set maximum transmission unit for UDP packets (default: 1350)</span><br><span class="line">   --sndwnd value                   set send window size(num of packets) (default: 128)</span><br><span class="line">   --rcvwnd value                   set receive window size(num of packets) (default: 512)</span><br><span class="line">   --datashard value, --ds value    set reed-solomon erasure coding - datashard (default: 10)</span><br><span class="line">   --parityshard value, --ps value  set reed-solomon erasure coding - parityshard (default: 3)</span><br><span class="line">   --dscp value                     set DSCP(6bit) (default: 0)</span><br><span class="line">   --nocomp                         disable compression</span><br><span class="line">   --snmplog value                  collect snmp to file, aware of timeformat in golang, like: ./snmp-20060102.log</span><br><span class="line">   --snmpperiod value               snmp collect period, in seconds (default: 60)</span><br><span class="line">   --log value                      specify a log file to output, default goes to stderr</span><br><span class="line">   -c value                         config from json file, which will override the command from shell</span><br><span class="line">   --help, -h                       show help</span><br><span class="line">   --version, -v                    print the version</span><br><span class="line"></span><br><span class="line">$ ./server_darwin_amd64 -h</span><br><span class="line">NAME:</span><br><span class="line">   kcptun - server(with SMUX)</span><br><span class="line"></span><br><span class="line">USAGE:</span><br><span class="line">   server_darwin_amd64 [global options] command [command options] [arguments...]</span><br><span class="line"></span><br><span class="line">VERSION:</span><br><span class="line">   20170120</span><br><span class="line"></span><br><span class="line">COMMANDS:</span><br><span class="line">     help, h  Shows a list of commands or help for one command</span><br><span class="line"></span><br><span class="line">GLOBAL OPTIONS:</span><br><span class="line">   --listen value, -l value         kcp server listen address (default: &quot;:29900&quot;)</span><br><span class="line">   --target value, -t value         target server address (default: &quot;127.0.0.1:12948&quot;)</span><br><span class="line">   --key value                      pre-shared secret between client and server (default: &quot;it&apos;s a secrect&quot;) [$KCPTUN_KEY]</span><br><span class="line">   --crypt value                    aes, aes-128, aes-192, salsa20, blowfish, twofish, cast5, 3des, tea, xtea, xor, none (default: &quot;aes&quot;)</span><br><span class="line">   --mode value                     profiles: fast3, fast2, fast, normal (default: &quot;fast&quot;)</span><br><span class="line">   --mtu value                      set maximum transmission unit for UDP packets (default: 1350)</span><br><span class="line">   --sndwnd value                   set send window size(num of packets) (default: 1024)</span><br><span class="line">   --rcvwnd value                   set receive window size(num of packets) (default: 1024)</span><br><span class="line">   --datashard value, --ds value    set reed-solomon erasure coding - datashard (default: 10)</span><br><span class="line">   --parityshard value, --ps value  set reed-solomon erasure coding - parityshard (default: 3)</span><br><span class="line">   --dscp value                     set DSCP(6bit) (default: 0)</span><br><span class="line">   --nocomp                         disable compression</span><br><span class="line">   --snmplog value                  collect snmp to file, aware of timeformat in golang, like: ./snmp-20060102.log</span><br><span class="line">   --snmpperiod value               snmp collect period, in seconds (default: 60)</span><br><span class="line">   --log value                      specify a log file to output, default goes to stderr</span><br><span class="line">   -c value                         config from json file, which will override the command from shell</span><br><span class="line">   --help, -h                       show help</span><br><span class="line">   --version, -v                    print the version</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Kcptun 是一个非常简单和快速的，基于 KCP 协议的 UDP 隧道，它可以将 TCP 流转换为 KCP+UDP 流。而 KCP 是一个快速可靠协议，能以比 TCP 浪费10%-20%的带宽的代价，换取平均延迟降低 30%-40%，且最大延迟降低三倍的传输效果。&lt;/p&gt;
    
    </summary>
    
      <category term="monitor" scheme="yunke.science/categories/monitor/"/>
    
    
      <category term="kcptun" scheme="yunke.science/tags/kcptun/"/>
    
      <category term="zabbix" scheme="yunke.science/tags/zabbix/"/>
    
  </entry>
  
  <entry>
    <title>zabbix 宏概念及使用</title>
    <link href="yunke.science/2018/04/20/zabbix-macros/"/>
    <id>yunke.science/2018/04/20/zabbix-macros/</id>
    <published>2018-04-20T07:53:49.000Z</published>
    <updated>2018-04-20T09:01:15.000Z</updated>
    
    <content type="html"><![CDATA[<p>Zabbix支持许多在多种情况下使用的宏。宏是一个变量，由如下特殊语法标识：<code>{MACRO}</code><br>根据在上下文中， 宏解析为一个特殊的值。<br>有效地使用宏可以节省时间，并使Zabbix变地更加高效。</p><a id="more"></a><p><ul class="markdownIt-TOC"><li><a href="#%E5%AE%8F%E5%87%BD%E6%95%B0">宏函数</a><ul><li><a href="#%E7%A4%BA%E4%BE%8B">示例</a></li></ul></li><li><a href="#%E7%94%A8%E6%88%B7%E5%AE%8F">用户宏</a><ul><li><a href="#%E7%A4%BA%E4%BE%8B-2">示例</a><ul><li><a href="#%E7%A4%BA%E4%BE%8B-1">示例 1</a></li><li><a href="#%E7%A4%BA%E4%BE%8B-2">示例 2</a></li><li><a href="#%E7%A4%BA%E4%BE%8B-3">示例 3</a></li><li><a href="#%E7%A4%BA%E4%BE%8B-4">示例 4</a></li><li><a href="#%E7%A4%BA%E4%BE%8B-5">示例 5</a></li></ul></li><li><a href="#%E5%9C%A8%E4%B8%8A%E4%B8%8B%E6%96%87%E4%B8%AD%E4%BD%BF%E7%94%A8%E7%94%A8%E6%88%B7%E5%AE%8F">在上下文中使用用户宏</a><ul><li><a href="#%E5%9C%A8%E7%94%A8%E6%88%B7%E5%AE%8F%E4%B8%8A%E4%B8%8B%E6%96%87%E4%B8%AD%E4%BD%BF%E7%94%A8lld%E5%AE%8F">在用户宏上下文中使用LLD宏</a></li></ul></li></ul></li><li><a href="#%E8%87%AA%E5%8A%A8%E5%8F%91%E7%8E%B0lld%E5%AE%8F">自动发现（LLD）宏</a></li></ul></p><p>Zabbix支持许多在多种情况下使用的宏。宏是一个变量，由如下特殊语法标识：</p><p><mark>{MACRO}</mark></p><p>根据在上下文中， 宏解析为一个特殊的值。</p><p>有效地使用宏可以节省时间，并使Zabbix变地更加高效。</p><p>在一个的典型用途中，宏可以用于模板中。因此，模板的触发器可能命名为“Processor load is too high on {<a href="http://HOST.NAME" target="_blank" rel="noopener">HOST.NAME</a>}”。当这个模板应用与主机（如 Zabbix Server ）时，并且当触发器展示在监控页面上时，触发器的名称将解析为“Processor load is too high on Zabbix server”。</p><p>宏可以在监控项键值参数中使用。<strong>宏只能用在监控项键值参数的一部分中，例如 item.key[server_{HOST.HOST}_local] 。</strong> 双引号参数不是必须的，因为Zabbix将处理任何模糊不清的特殊参数（如果这些参数存在于已解析的宏中）。</p><h2><span id="宏函数"> 宏函数</span></h2><p>宏函数能提供自定义宏值的功能。</p><p>有时候宏可能会解析为一个不一定易于使用的值。它可能很长，或包含你想提取的一个特殊感兴趣的子字符串。这在宏函数中是可以使用的。</p><p>宏函数的语法为：</p><img src="/2018/04/20/zabbix-macros/Snipaste_2018-04-20_16-27-29.png" title="天青色等烟雨"><p>其中：</p><ol><li><macro> - 这个参数为要定义的宏 （例如 {ITEM.VALUE}）；</macro></li><li><func> - 要应用的函数；</func></li><li><params> - 以逗号分隔的函数参数列表。如果他们以 (空格), &quot; 或者包含 ), ,这些符号开始，则参数必须要引用。</params></li></ol><p>例如：</p><img src="/2018/04/20/zabbix-macros/Snipaste_2018-04-20_16-31-40.png" title="天青色等烟雨"><p>受支持的宏函数</p><p><strong>regsub (<pattern>,<output>)  通过正则表达式匹配提取的子字符串（<mark>区分大小写</mark>）。</output></pattern></strong><br><strong>iregsub (<pattern>,<output>) 通过正则表达式匹配提取的子字符串（<mark>不区分大小写</mark>）。</output></pattern></strong></p><ul><li>pattern - 匹配的正则表达式</li><li>output - 输出的选项。 \1 - \9 支持使用占位符来捕获组。</li></ul><p><em>如果参数 pattern 是一个不正确的正则表达式，那么将返回 “UNKNOWN” 。</em></p><p>支持的宏：</p><ul><li>{ITEM.VALUE}</li><li>{ITEM.LASTVALUE}</li></ul><p>如果在受支持的位置使用函数，但是应用于不支持宏函数得宏， 那么宏的计算结果为 “UNKNOWN”。<br>如果在不支持宏函数的位置将宏函数应用于宏， 则忽略该函数。</p><h3><span id="示例"> 示例</span></h3><p>关于宏函数可用于自定义宏值的方法，在下面的示例中说明，其中包含的 “log line” 作为接收值：</p><img src="/2018/04/20/zabbix-macros/Snipaste_2018-04-20_16-20-13.png" title="天青色等烟雨"><h2><span id="用户宏"> 用户宏</span></h2><p>除了支持开箱即用的宏之外，Zabbix 还支持更灵活的用户宏。</p><p>用户宏可以在全局、模板和主机级别进行定义。这些宏具有一个特殊的语法：</p><p><mark>{$MACRO}</mark></p><p><strong>用户宏可被用于：</strong></p><ol><li>监控项名称；</li><li>监控项键值参数；</li><li>触发器名称和描述；</li><li>触发器表达式参数和常量(详细查阅下文的 <a href="https://www.zabbix.com/documentation/3.4/zh/manual/config/macros/usermacros#examples" target="_blank" rel="noopener">示例</a>)</li><li>许多其他位置 (详细查阅 <a href="https://www.zabbix.com/documentation/3.4/manual/appendix/macros/supported_by_location" target="_blank" rel="noopener">位置支持的宏</a>)</li></ol><p>宏名称中允许使用以下字符：A-Z , 0-9 , _ , . 。</p><p><strong>Zabbix 根据以下优先级解析宏：</strong></p><ol><li>主机级别的宏 (首先检查)；</li><li>为主机的第一级别模板定义的宏（即，直接链接到主机的模板），按照模板 ID 来排序；</li><li>为主机的第二级别模板定义的宏，按照模板 ID 来排序；</li><li>为主机的第三级别模板定义的宏，按照模板ID来排序，等；</li><li>全局宏 (最后检查)。</li></ol><p>换言之，如果一个主机不存在一个宏， Zabbix 将会尝试在级别递增的主机模板中找到它，如果仍然找不到，那么将会使用全局宏（如果全局宏存在的话）。</p><p>如果要定义用户宏，请转到Zabbix的前端页面的如下位置：<br>对于全局宏，请访问 管理 → 常规 → 右上角下拉菜单选择 “宏” ；<br>对于主机和模板级别的宏，请打开主机或模板属性并查看 宏 标签页面。</p><p><em>如果在模板的监控项或触发器使用用户宏，建议将该宏添加到模板，即使它被定义在全局级别上。这样的话，将模板导出至XML文件中，之后在其他系统中导入，那么在其他系统中使用也将会达到预期的使用效果。</em></p><p><strong>全局和主机宏的常用案例</strong></p><ul><li>利用具有主机特定属性的模板：密码、端口号、文件名称、正则表达式等；</li><li>运用全局宏进行全局的一键配置更改或微调。</li></ul><h3><span id="示例"> 示例</span></h3><h4><span id="示例-1"> 示例 1</span></h4><p>在 “Status of SSH daemon” 监控项键值中使用主机级别的宏：</p><p><code>net.tcp.service[ssh,,{$SSH_PORT}]</code></p><p>该监控项可以分配给多个主机，前提是在这些主机上定义了 {$SSH_PORT} 的值。</p><h4><span id="示例-2"> 示例 2</span></h4><p>在 “CPU load is too high” 触发器上使用主机级别的宏:</p><p><code>{ca_001:system.cpu.load[,avg1].last()}&gt;{$MAX_CPULOAD}</code></p><p>这样的触发器将会在模板上创建，而不会在单个主机中编辑。</p><p><em>如果要使用数值作为函数参数（例如，max(#3)），则在宏定义中要包含#（hash mark）例如：SOME_PERIOD ⇒ #3</em></p><h4><span id="示例-3"> 示例 3</span></h4><p>在“CPU load is too high”触发器中使用了两个宏：</p><p><code>{ca_001:system.cpu.load[,avg1].min({$CPULOAD_PERIOD})}&gt;{$MAX_CPULOAD}</code></p><p>请注意，宏可以用作触发器函数的参数，在这个示例中为 min() 。</p><p><em><strong>在触发器表达式中，如果引用参数或者常量，则用户宏将会解析</strong>。<mark>如果引用主机、监控项键值、函数、操作或其他触发器表达式的话，他们将不会解析</mark>。</em></p><h4><span id="示例-4"> 示例 4</span></h4><p>使agent不可用条件与项目更新时间间隔同步：</p><p>定义 <code>{$INTERVAL}</code> 宏并在项目更新间隔中使用它;<br>使用 <code>{$INTERVAL}</code> 作为agent不可用性触发器的参数：<br><code>{ca_001:agent.ping.nodata({$INTERVAL})}=1</code></p><h4><span id="示例-5"> 示例 5</span></h4><p>集中配置工作时间 $WORKING_HOURS ：</p><ol><li>创建一个全局宏{$WORKING_HOURS}，值为 <code>1-5,09:00-18:00;</code></li><li>进入菜单配置 Administration → General → Working time;</li><li>使用宏 User → Media → When active;</li><li>在工作时间使用它来设置更频繁的项目轮询：</li></ol><img src="/2018/04/20/zabbix-macros/usermacro_example5.png" title="天青色等烟雨"><ol><li>在时间段动作条件中使用它;</li><li>如果需要，在Administration → General → Macros 调整工作时间。</li></ol><h3><span id="在上下文中使用用户宏"> 在上下文中使用用户宏</span></h3><p>一个可选的上下文可以在用户宏中使用，允许用上下文特定的一个覆盖缺省值。</p><p>具有上下文的用户宏具有类似的语法：</p><p><code>{$MACRO:context}</code></p><p>宏上下文是一个简单的文本值。 宏上下文的常见用例是使用低级别发现宏值作为用户宏上下文。 例如，可以为安装的文件系统发现定义触发器原型，以根据安装点或文件系统类型使用不同的低空间限制。</p><p>在宏上下文中只支持低级别的发现宏。 任何其他的宏都被忽略并被视为纯文本。</p><p>从技术上讲，使用类似于项目关键参数的规则来指定宏上下文，除非宏上下文没有被分析为几个参数，如果有逗号<code>,</code>字符：</p><ul><li>宏上下文必须用引号<code>，</code>。 如果上下文中包含<code>}</code>或者以<code>&quot;</code>开始，需要使用<code>\</code>字符转义。 <code>\</code>字符本身不会被转义，这意味着不可能有以<code>\</code>字符结尾的引用上下文 - 宏<code>{$MACRO:&quot;a:\b\c\&quot;}</code> 是无效的。</li><li>上下文中的前置空格将被忽略，后端空格不会忽略。 例如<code>{$MACRO:A}</code>与 <code>{$MACRO: A}</code>相同，但不同于 <code>{$MACRO:A }</code>。</li><li>引号前和引号之后的所有空格都被忽略，但引号内的所有空格不会忽略。 宏 <code>{$MACRO:&quot;A&quot;}, {$MACRO: &quot;A&quot;}, {$MACRO:&quot;A&quot; } and {$MACRO: &quot;A&quot; }</code> 是相同的，但是宏 <code>{$MACRO:&quot;A&quot;} and {$MACRO:&quot; A &quot;}</code> 不是。</li></ul><p>以下宏都是等价的，因为它们具有相同的上下文：<code>{$MACRO:A}, {$MACRO: A} and {$MACRO:&quot;A&quot;}</code>。 这与项目键相反，其中key[a], key[ a] and key[“a”] 在语义上是相同的，但为了唯一性目的而不同。</p><p>当上下文宏被处理时，Zabbix用它的上下文查找宏。 如果具有此上下文的宏未由主机或链接模板定义，并且它不是定义为具有上下文的全局宏，则将搜索没有上下文的宏。</p><p>参阅<a href="https://www.zabbix.com/documentation/3.4/manual/discovery/low_level_discovery#using_lld_macros_in_user_macro_contexts" target="_blank" rel="noopener">磁盘空间触发器原型中的宏上下文使用示例</a>，并考虑限制条款。</p><h4><span id="在用户宏上下文中使用lld宏"> 在用户宏上下文中使用LLD宏</span></h4><p>带有上下文的用户宏可用于在触发器表达式中实现更灵活的阈值。 不同的阈值可以在用户宏等级上定义，然后根据发现的上下文在触发常量中使用。 当宏中使用的低级别发现宏解析为实际值时，会显示发现的上下文。</p><p>为了说明我们可以使用上述示例中的数据，并假定将发现以下文件系统：<code>/, /home, /tmp, /usr, /var</code>。</p><p>我们可以为主机定义一个自由磁盘空间触发器原型，其中阈值由具有上下文的用户宏表示：</p><img src="/2018/04/20/zabbix-macros/Snipaste_2018-04-20_16-39-55.png" title="天青色等烟雨"><p>然后添加用户宏上下文：</p><ul><li><code>{$LOW_SPACE_LIMIT} =&gt; 10</code></li><li><code>{$LOW_SPACE_LIMIT:/home} =&gt; 20</code></li><li><code>{$LOW_SPACE_LIMIT:/tmp} =&gt; 50</code></li></ul><p>现在，一旦文件系统被发现，如果/，/usr和/var文件系统的可用磁盘空间少于10％，/home文件系统少于20％的可用磁盘空间或/tmp文件系统少于50％的可用磁盘空间, 将触发报警。</p><h2><span id="自动发现lld宏"> 自动发现（LLD）宏</span></h2><p>有一种自动发现（LLD）函数中使用的宏类型为:</p><img src="/2018/04/20/zabbix-macros/Snipaste_2018-04-20_16-37-27.png" title="天青色等烟雨"><p>它是一个在LLD规则中使用的宏，并返回文件系统名称、网络接口和 SNMP OIDs。</p><p>这些宏可以用于创建监控项、触发器和图形原型。然后，当发现真实的文件系统、网络接口等，这些宏将被替换为真实的值，并且以这些值来创建真实的监控项、触发器和图形。</p><p>这些宏还用于在虚拟机自动发现中创建主机和主机组原型。</p><p>受支持的位置<br>LLD 宏可以用在：</p><ul><li>用于监控项原型中：</li><li><ul><li>names</li></ul></li><li><ul><li>key parameters</li></ul></li><li><ul><li>units</li></ul></li><li><ul><li>SNMP OIDs</li></ul></li><li><ul><li>IPMI sensor fields</li></ul></li><li><ul><li>calculated item formulas</li></ul></li><li><ul><li>SSH and Telnet scripts</li></ul></li><li><ul><li>database monitoring SQL queries</li></ul></li><li><ul><li>descriptions (从 2.2.0 开始支持)</li></ul></li><li>用于触发器原型中：</li><li><ul><li>names</li></ul></li><li><ul><li>expressions</li></ul></li><li><ul><li>URLs (从 3.0.0 开始支持)</li></ul></li><li><ul><li>descriptions (从 2.2.0 开始支持)</li></ul></li><li><ul><li>event tag names and values (从 3.2.0 开始支持)</li></ul></li><li>用于图形原型中：</li><li><ul><li>names</li></ul></li><li>用于主机原型中 (从 2.2.0 开始支持)：</li><li><ul><li>names</li></ul></li><li><ul><li>visible names</li></ul></li><li><ul><li>host group prototype names<br>(详细查阅 <a href="https://www.zabbix.com/documentation/3.4/manual/vm_monitoring/discovery_fields" target="_blank" rel="noopener">全部列表</a>)</li></ul></li></ul><p>在上述所有位置，LLD 宏都可以在用户宏上下文中使用。</p><p>一些自动发现（LLD）宏在 Zabbix 中是已经预先内置的，例如 (#FSNAME}、 (#FSTYPE}、(#IFNAME}、 (#SNMPINDEX}、 (#SNMPVALUE} 这些宏。然而，当你在创建自定义自动发现规则的时候，遵守这些宏名称不是强制性的。所以，你可以使用任何其他的 LLD 宏名称并引用该名称。</p><p>参考连接：</p><ol><li>官方文档中文<a href="https://www.zabbix.com/documentation/3.4/zh/manual/config/macros" target="_blank" rel="noopener"> 第九节 宏 </a></li><li>官方文档英文<a href="https://www.zabbix.com/documentation/3.4/manual/config/macros" target="_blank" rel="noopener">10 Macros</a></li><li>受支持的宏的<a href="https://www.zabbix.com/documentation/3.4/manual/appendix/macros/supported_by_location" target="_blank" rel="noopener">完整列表</a></li><li>受支持的<a href="https://www.zabbix.com/documentation/3.4/manual/appendix/macros/supported_by_location_user" target="_blank" rel="noopener">用户宏列表</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Zabbix支持许多在多种情况下使用的宏。宏是一个变量，由如下特殊语法标识：&lt;code&gt;{MACRO}&lt;/code&gt;&lt;br&gt;
根据在上下文中， 宏解析为一个特殊的值。&lt;br&gt;
有效地使用宏可以节省时间，并使Zabbix变地更加高效。&lt;/p&gt;
    
    </summary>
    
      <category term="monitor" scheme="yunke.science/categories/monitor/"/>
    
    
      <category term="zabbix" scheme="yunke.science/tags/zabbix/"/>
    
  </entry>
  
  <entry>
    <title>ip 子网划分的两个例子</title>
    <link href="yunke.science/2018/04/20/ip-netmaster/"/>
    <id>yunke.science/2018/04/20/ip-netmaster/</id>
    <published>2018-04-20T02:26:24.000Z</published>
    <updated>2018-04-20T02:29:02.000Z</updated>
    
    <content type="html"><![CDATA[<p>IP将IP地址分隔为网络和主机地址（&lt;网络&gt; &lt;主机&gt;）。 子网划分进一步将IP地址的主机部分划分为子网称为子网掩码，因为它用于通过对网络掩码执行按位与操作来识别IP地址的网络地址。</p><a id="more"></a><p><ul class="markdownIt-TOC"><li><a href="#%E4%BE%8B1%E6%9C%AC%E4%BE%8B%E9%80%9A%E8%BF%87%E5%AD%90%E7%BD%91%E6%95%B0%E6%9D%A5%E5%88%92%E5%88%86%E5%AD%90%E7%BD%91%E6%9C%AA%E8%80%83%E8%99%91%E4%B8%BB%E6%9C%BA%E6%95%B0">例1：本例通过子网数来划分子网，未考虑主机数。</a></li><li><a href="#%E4%BE%8B2%E6%9C%AC%E4%BE%8B%E9%80%9A%E8%BF%87%E8%AE%A1%E7%AE%97%E4%B8%BB%E6%9C%BA%E6%95%B0%E6%9D%A5%E5%88%92%E5%88%86%E5%AD%90%E7%BD%91">例2：本例通过计算主机数来划分子网。</a><ul><li><a href="#a-%E5%85%88%E6%A0%B9%E6%8D%AE%E5%A4%A7%E7%9A%84%E4%B8%BB%E6%9C%BA%E6%95%B0%E9%9C%80%E6%B1%82%E5%88%92%E5%88%86%E5%AD%90%E7%BD%91">A. 先根据大的主机数需求，划分子网</a></li><li><a href="#b-%E5%86%8D%E5%88%92%E5%88%862%E6%A5%BC%E4%BD%BF%E7%94%A8%E7%9A%84%E7%BD%91%E6%AE%B5">B. 再划分2楼使用的网段</a></li><li><a href="#c-%E6%9C%80%E5%90%8E%E5%88%92%E5%88%86%E8%B7%AF%E7%94%B1%E5%99%A8%E4%BA%92%E8%81%94%E4%BD%BF%E7%94%A8%E7%9A%84%E7%BD%91%E6%AE%B5">C. 最后划分路由器互联使用的网段</a></li><li><a href="#d-%E6%95%B4%E7%90%86%E6%9C%AC%E4%BE%8B%E7%9A%84%E8%A7%84%E5%88%92%E5%9C%B0%E5%9D%80">D. 整理本例的规划地址</a></li></ul></li><li><a href="#%E5%BF%AB%E9%80%9F%E5%88%92%E5%88%86%E5%AD%90%E7%BD%91%E7%A1%AE%E5%AE%9Aip">快速划分子网确定IP</a></li><li><a href="#%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5">参考链接：</a></li></ul></p><h2><span id="例1本例通过子网数来划分子网未考虑主机数"> 例1：本例通过子网数来划分子网，未考虑主机数。</span></h2><p>一家集团公司有12家子公司，每家子公司又有4个部门。上级给出一个172.16.0.0/16的网段，让给每家子公司以及子公司的部门分配网段。</p><p>思路：既然有12家子公司，那么就要划分12个子网段，但是每家子公司又有4个部门，因此又要在每家子公司所属的网段中划分4个子网分配给各部门。</p><p>步骤：</p><p>A. 先划分各子公司的所属网段。</p><p>有12家子公司，那么就有2的n次方≥12，n的最小值=4。因此，网络位需要向主机位借4位。那么就可以从172.16.0.0/16这个大网段中划出2的4次方=16个子网。</p><p>详细过程：</p><p>先将172.16.0.0/16用二进制表示</p><p>10101100.00010000.00000000.00000000/16</p><p>借4位后（可划分出16个子网）：</p><ol><li><mark>10101100.00010000.0000</mark>0000.00000000/20【172.16.0.0/20】</li><li><mark>10101100.00010000.0001</mark>0000.00000000/20【172.16.16.0/20】</li><li><mark>10101100.00010000.0010</mark>0000.00000000/20【172.16.32.0/20】</li><li><mark>10101100.00010000.0011</mark>0000.00000000/20【172.16.48.0/20】</li><li><mark>10101100.00010000.0100</mark>0000.00000000/20【172.16.64.0/20】</li><li><mark>10101100.00010000.0101</mark>0000.00000000/20【172.16.80.0/20】</li><li><mark>10101100.00010000.0110</mark>0000.00000000/20【172.16.96.0/20】</li><li><mark>10101100.00010000.0111</mark>0000.00000000/20【172.16.112.0/20】</li><li><mark>10101100.00010000.1000</mark>0000.00000000/20【172.16.128.0/20】</li><li><mark>10101100.00010000.1001</mark>0000.00000000/20【172.16.144.0/20】</li><li><mark>10101100.00010000.1010</mark>0000.00000000/20【172.16.160.0/20】</li><li><mark>10101100.00010000.1011</mark>0000.00000000/20【172.16.176.0/20】</li><li><mark>10101100.00010000.1100</mark>0000.00000000/20【172.16.192.0/20】</li><li><mark>10101100.00010000.1101</mark>0000.00000000/20【172.16.208.0/20】</li><li><mark>10101100.00010000.1110</mark>0000.00000000/20【172.16.224.0/20】</li><li><mark>10101100.00010000.1111</mark>0000.00000000/20【172.16.240.0/20】</li></ol><p>我们从这16个子网中选择12个即可，就将前12个分给下面的各子公司。每个子公司最多容纳主机数目为2的12次方-2=4094。</p><p>B. 再划分子公司各部门的所属网段</p><p>以甲公司获得172.16.0.0/20为例，其他子公司的部门网段划分同甲公司。</p><p>有4个部门，那么就有2的n次方≥4，n的最小值=2。因此，网络位需要向主机位借2位。那么就可以从172.16.0.0/20这个网段中再划出2的2次方=4个子网，正符合要求。</p><p>详细过程：<br>先将172.16.0.0/20用二进制表示<br><mark>10101100.00010000.0000</mark>0000.00000000/20<br>借2位后（可划分出4个子网）：</p><ol><li>10101100.00010000.0000<mark>00</mark>00.00000000/22【172.16.0.0/22】</li><li>10101100.00010000.0000<mark>01</mark>00.00000000/22【172.16.4.0/22】</li><li>10101100.00010000.0000<mark>10</mark>00.00000000/22【172.16.8.0/22】</li><li>10101100.00010000.0000<mark>11</mark>00.00000000/22【172.16.12.0/22】</li></ol><p>将这4个网段分给甲公司的4个部门即可。每个部门最多容纳主机数目为2的10次方-2=1024。</p><h2><span id="例2本例通过计算主机数来划分子网"> 例2：本例通过计算主机数来划分子网。</span></h2><p>某集团公司给下属子公司甲分配了一段IP地址192.168.5.0/24，现在甲公司有两层办公楼（1楼和2楼），统一从1楼的路由器上公网。1楼有100台电脑联网，2楼有53台电脑联网。如果你是该公司的网管，你该怎么去规划这个IP？</p><p>根据需求，画出下面这个简单的拓扑。将192.168.5.0/24划成3个网段，1楼一个网段，至少拥有101个可用IP地址；2楼一个网段，至少拥有54个可用IP地址；1楼和2楼的路由器互联用一个网段，需要2个IP地址。</p><p>思路:我们在划分子网时优先考虑最大主机数来划分。在本例中，我们就先使用最大主机数来划分子网。101个可用IP地址，那就要保证至少7位的主机位可用（2的m次方-2≥101，m的最小值=7）。如果保留7位主机位，那就只能划出两个网段，剩下的一个网段就划不出来了。但是我们剩下的一个网段只需要2个IP地址并且2楼的网段只需要54个可用IP，因此，我们可以从第一次划出的两个网段中选择一个网段来继续划分2楼的网段和路由器互联使用的网段。</p><p>步骤：</p><h3><span id="a-先根据大的主机数需求划分子网"> A. 先根据大的主机数需求，划分子网</span></h3><p>因为要保证1楼网段至少有101个可用IP地址，所以，主机位要保留至少7位。<br>先将192.168.5.0/24用二进制表示：<br><mark>11000000.10101000.00000101</mark>.00000000/24<br>主机位保留7位，即在现有基础上网络位向主机位借1位（可划分出2个子网）：</p><ol><li><mark>11000000.10101000.00000101.0</mark>0000000/25【192.168.5.0/25】</li><li><mark>11000000.10101000.00000101.1</mark>0000000/25【192.168.5.128/25】</li></ol><p>1楼网段从这两个子网段中选择一个即可，我们选择192.168.5.0/25。<br>2楼网段和路由器互联使用的网段从192.168.5.128/25中再次划分得到。</p><h3><span id="b-再划分2楼使用的网段"> B. 再划分2楼使用的网段</span></h3><p>2楼使用的网段从192.168.5.128/25这个子网段中再次划分子网获得。因为2楼至少要有54个可用IP地址，所以，主机位至少要保留6位（2的m次方-2≥54，m的最小值=6）。</p><p>先将192.168.5.128/25用二进制表示：<br>11000000.10101000.00000101.10000000/25<br>主机位保留6位，即在现有基础上网络位向主机位借1位（可划分出2个子网）：</p><ol><li>11000000.10101000.00000101.1<mark>0</mark>000000/26【192.168.5.128/26】</li><li>11000000.10101000.00000101.1<mark>1</mark>000000/26【192.168.5.192/26】</li></ol><p>2楼网段从这两个子网段中选择一个即可，我们选择192.168.5.128/26。<br>路由器互联使用的网段从192.168.5.192/26中再次划分得到。</p><h3><span id="c-最后划分路由器互联使用的网段"> C. 最后划分路由器互联使用的网段</span></h3><p>路由器互联使用的网段从192.168.5.192/26这个子网段中再次划分子网获得。因为只需要2个可用IP地址，所以，主机位只要保留2位即可（2的m次方-2≥2，m的最小值=2）。</p><p>先将192.168.5.192/26用二进制表示：<br>11000000.10101000.00000101.11000000/26<br>主机位保留2位，即在现有基础上网络位向主机位借4位（可划分出16个子网）：</p><ol><li>11000000.10101000.00000101.11<mark>0000</mark>00/30【192.168.5.192/30】</li><li>11000000.10101000.00000101.11<mark>0001</mark>00/30【192.168.5.196/30】</li><li>11000000.10101000.00000101.11<mark>0010</mark>00/30【192.168.5.200/30】<br>…………………………………</li><li>11000000.10101000.00000101.11<mark>1101</mark>00/30【192.168.5.244/30】</li><li>11000000.10101000.00000101.11<mark>1110</mark>00/30【192.168.5.248/30】</li><li>11000000.10101000.00000101.11<mark>1111</mark>00/30【192.168.5.252/30】<br>路由器互联网段我们从这16个子网中选择一个即可，我们就选择192.168.5.252/30。</li></ol><h3><span id="d-整理本例的规划地址"> D. 整理本例的规划地址</span></h3><p>1楼：<br>网络地址：【192.168.5.0/25】<br>主机IP地址：【192.168.5.1/25—192.168.5.126/25】<br>广播地址：【192.168.5.127/25】<br>2楼：<br>网络地址：【192.168.5.128/26】<br>主机IP地址：【192.168.5.129/26—192.168.5.190/26】<br>广播地址：【192.168.5.191/26】<br>路由器互联：<br>网络地址：【192.168.5.252/30】<br>两个IP地址：【192.168.5.253/30、192.168.5.254/30】<br>广播地址：【192.168.5.255/30】</p><h2><span id="快速划分子网确定ip"> 快速划分子网确定IP</span></h2><p>我们以例2为例：<br>题目需要我们将192.168.5.0/24这个网络地址划分成能容纳101/54/2个主机的子网。因此我们要先确定主机位，然后根据主机位决定网络位，最后确定详细的IP地址。</p><ol><li>确定主机位<br>将所需要的主机数自大而小的排列出来：101/54/2，然后根据网络拥有的IP数目确定每个子网的主机位：如果2的n次方-2≥该网段的IP数目，那么主机位就等于n。于是，得到：7/6/2。</li><li>根据主机位决定网络位<br>用32减去主机位剩下的数值就是网络位，得到：25/26/30。</li><li>确定详细的IP地址<br>在二进制中用网络位数值掩盖IP前面相应的位数，然后后面的为IP位。选取每个子网的第一个IP为网络地址，最后一个为广播地址，之间的为有效IP。得到：</li></ol><table><thead><tr><th>【网络地址】</th><th>【有效IP】</th><th>【广播地址】</th></tr></thead><tbody><tr><td>【192.168.5.0/25】</td><td>【192.168.5.1/25-192.168.5.126/25】</td><td>【192.168.5.127/25】</td></tr><tr><td>【192.168.5.128/26】</td><td>【192.168.5.129/26-192.168.5.190/26】</td><td>【192.168.5.191/26】</td></tr><tr><td>【192.168.5.192/30】</td><td>【192.168.5.193/30-192.168.5.194/30】</td><td>【192.168.5.195/30】</td></tr></tbody></table><p>用于分级网络的常用网络掩码的例子是8位（A类），16位（B类）和24位（C类），而无分类网络如下：</p><table><thead><tr><th>Class</th><th>Address</th><th># of Hosts</th><th>Netmask (Binary)</th><th>Netmask (Decimal)</th></tr></thead><tbody><tr><td>CIDR</td><td>/4</td><td>240,435,456</td><td>11110000 00000000 00000000 00000000</td><td>240.0.0.0</td></tr><tr><td>CIDR</td><td>/5</td><td>134,217,728</td><td>11111000 00000000 00000000 00000000</td><td>248.0.0.0</td></tr><tr><td>CIDR</td><td>/6</td><td>67,108,864</td><td>11111100 00000000 00000000 00000000</td><td>252.0.0.0</td></tr><tr><td>CIDR</td><td>/7</td><td>33,554,432</td><td>11111110 00000000 00000000 00000000</td><td>254.0.0.0</td></tr><tr><td>A</td><td>/8</td><td>16,777,216</td><td>11111111 00000000 00000000 00000000</td><td>255.0.0.0</td></tr><tr><td>CIDR</td><td>/9</td><td>8,388,608</td><td>11111111 10000000 00000000 00000000</td><td>255.128.0.0</td></tr><tr><td>CIDR</td><td>/10</td><td>4,194,304</td><td>11111111 11000000 00000000 00000000</td><td>255.192.0.0</td></tr><tr><td>CIDR</td><td>/11</td><td>2,097,152</td><td>11111111 11100000 00000000 00000000</td><td>255.224.0.0</td></tr><tr><td>CIDR</td><td>/12</td><td>1,048,576</td><td>11111111 11110000 00000000 00000000</td><td>255.240.0.0</td></tr><tr><td>CIDR</td><td>/13</td><td>524,288</td><td>11111111 11111000 00000000 00000000</td><td>255.248.0.0</td></tr><tr><td>CIDR</td><td>/14</td><td>262,144</td><td>11111111 11111100 00000000 00000000</td><td>255.252.0.0</td></tr><tr><td>CIDR</td><td>/15</td><td>131,072</td><td>11111111 11111110 00000000 00000000</td><td>255.254.0.0</td></tr><tr><td>B</td><td>/16</td><td>65,534</td><td>11111111 11111111 00000000 00000000</td><td>255.255.0.0</td></tr><tr><td>CIDR</td><td>/17</td><td>32,768</td><td>11111111 11111111 10000000 00000000</td><td>255.255.128.0</td></tr><tr><td>CIDR</td><td>/18</td><td>16,384</td><td>11111111 11111111 11000000 00000000</td><td>255.255.192.0</td></tr><tr><td>CIDR</td><td>/19</td><td>8,192</td><td>11111111 11111111 11100000 00000000</td><td>255.255.224.0</td></tr><tr><td>CIDR</td><td>/20</td><td>4,096</td><td>11111111 11111111 11110000 00000000</td><td>255.255.240.0</td></tr><tr><td>CIDR</td><td>/21</td><td>2,048</td><td>11111111 11111111 11111000 00000000</td><td>255.255.248.0</td></tr><tr><td>CIDR</td><td>/22</td><td>1,024</td><td>11111111 11111111 11111100 00000000</td><td>255.255.252.0</td></tr><tr><td>CIDR</td><td>/23</td><td>512</td><td>11111111 11111111 11111110 00000000</td><td>255.255.254.0</td></tr><tr><td>C</td><td>/24</td><td>256</td><td>11111111 11111111 11111111 00000000</td><td>255.255.255.0</td></tr><tr><td>CIDR</td><td>/25</td><td>128</td><td>11111111 11111111 11111111 10000000</td><td>255.255.255.128</td></tr><tr><td>CIDR</td><td>/26</td><td>64</td><td>11111111 11111111 11111111 11000000</td><td>255.255.255.192</td></tr><tr><td>CIDR</td><td>/27</td><td>32</td><td>11111111 11111111 11111111 11100000</td><td>255.255.255.224</td></tr><tr><td>CIDR</td><td>/28</td><td>16</td><td>11111111 11111111 11111111 11110000</td><td>255.255.255.240</td></tr><tr><td>CIDR</td><td>/29</td><td>8</td><td>11111111 11111111 11111111 11111000</td><td>255.255.255.248</td></tr><tr><td>CIDR</td><td>/30</td><td>4</td><td>11111111 11111111 11111111 11111100</td><td>255.255.255.252</td></tr></tbody></table><h2><span id="参考链接"> 参考链接：</span></h2><p><a href="http://blog.51cto.com/yuanbin/112029" target="_blank" rel="noopener">子网划分的两个例子</a><br><a href="https://www.iplocation.net/subnet-mask" target="_blank" rel="noopener">What is a Subnet Mask?</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;IP将IP地址分隔为网络和主机地址（&amp;lt;网络&amp;gt; &amp;lt;主机&amp;gt;）。 子网划分进一步将IP地址的主机部分划分为子网称为子网掩码，因为它用于通过对网络掩码执行按位与操作来识别IP地址的网络地址。&lt;/p&gt;
    
    </summary>
    
      <category term="网络" scheme="yunke.science/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="网络" scheme="yunke.science/tags/%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>凡是让人幸福的东西，往往又会成为他不幸的源泉。</title>
    <link href="yunke.science/2018/04/19/meiwen01/"/>
    <id>yunke.science/2018/04/19/meiwen01/</id>
    <published>2018-04-19T04:04:09.000Z</published>
    <updated>2018-04-19T04:06:58.000Z</updated>
    
    <content type="html"><![CDATA[<p>她那时候还太年轻，不知道所有命运赠送的礼物，早已在暗中标好了价格。</p><a id="more"></a><ol><li><p>她那时候还太年轻，不知道所有命运赠送的礼物，早已在暗中标好了价格。<br>——斯蒂芬·茨威格《断头王后》</p></li><li><p>凡是让人幸福的东西，往往又会成为他不幸的源泉。<br>——歌德《少年维特之烦恼》</p></li><li><p>那时候，你还很年轻，人人都说你美，现在，我是特为来告诉你，对我来说，我觉得现在你比年轻的时候更美，那时你是年轻女人，与你那时的面貌相比，我更爱你现在备受摧残的面容。<br>——玛格丽特·杜拉斯《情人》</p></li><li><p>当你老了，回顾一生，就会发觉：什么时候出国读书，什么时候决定做第一份职业、何时选定了对象而恋爱、什么时候结婚，其实都是命运的巨变。只是当时站在三岔路口，眼见风云千樯，你作出选择的那一日，在日记上，相当沉闷和平凡，当时还以为是生命中普通的一天。<br>——陶杰 《杀鹌鹑的少女》</p></li><li><p>为什么你认为美——世界上最宝贵的财富——会同沙滩上的石头一样，一个漫不经心的过路人随随便便就能捡起来？美是一种美妙、奇异的东西，艺术家只有经过灵魂的痛苦折磨才能从宇宙的混沌中塑造出来。在美被创造出以后，它也不是为了叫每个人都能认出来的。要想认识它，一个人必须重复艺术家经历过的一番冒险。他唱给你的是一个美的旋律，要是想在自己的心里重新听一遍，就必须有知识、有敏锐的感觉和想象力。<br>——毛姆《月亮和六便士》</p></li><li><p>一个人只拥有此生此世是不够的，他还应该拥有诗意的世界。<br>——王小波 《万寿寺》</p></li><li><p>那一天我二十一岁，在我一生的黄金时代，我有好多奢望。我想爱，想吃，还想在一瞬间变成天上半明半暗的云，后来我才知道，生活就是个缓慢受锤的过程，人一天天老下去，奢望也一天天消逝，最后变得像挨了锤的牛一样。可是我过二十一岁生日时没有预见到这一点。我觉得自己会永远生猛下去，什么也锤不了我。<br>——王小波《黄金时代》</p></li><li><p>我年纪还轻，阅历不深的时候，我父亲教导过我一句话，我至今还念念不忘。<br>“每逢你想要批评任何人的时候，”他对我说，“你就记住，这个世界上所有的人，并不是个个都有过你拥有的那些优越条件。”<br>—— 菲茨杰拉德 《了不起的盖茨比》</p></li><li><p>洛丽塔，我生命之光，我欲念之火。我的罪恶，我的灵魂。洛一丽一塔：舌尖向上，分三步，从上颚往下轻轻落在牙齿上。洛.丽.塔。<br>—— 弗拉基米尔·纳博科夫 《洛丽塔》</p></li><li><p>忠厚老实人的恶毒，像饭里的砂砾或者出骨鱼片里未净的刺，会给人一种不期待的伤痛。<br>——钱钟书《围城》</p></li><li><p>心脏是一座有两间卧室的房子，一间住着痛苦，另一间住着欢乐，人不能笑得太响。否则笑声会吵醒隔壁房间的痛苦。<br>—— 卡夫卡《箴言录》</p></li></ol><p>12.我们很少信任比我们好的人，这可太真实了。<br>我们宁肯避免与他们往来。<br>相反，最为经常的是我们对和我们相似，和我们有着共同弱点的人吐露心迹。<br>因此，我们并不希望改掉我们的弱点，也不希望变得更好，只是希望在我们的道路上受到怜悯和鼓励。<br>—— 加缪《堕落》</p><p>13.一个人只要学会了回忆，就再不会孤独，哪怕只在世上生活一日，你也能毫无困难地凭回忆在囚牢中独处百年。<br>—— 加缪《局外人》</p><ol start="14"><li><p>田野上万籁俱寂，直传到我的耳际。夜的气味土地的气味，海水的气味，使我两鬓生凉。这夏夜奇妙的安静像潮水一样浸透了我的全身。这时，黑夜将尽，汽笛鸣叫起来了，它宣告着世人将开始新的旅程，他们要去的天地从此与我无关痛痒。很久以来，我第一次想起了妈妈。<br>——加缪《局外人》</p></li><li><p>雨声潺潺，像住在溪边，宁愿天天下雨，以为你是因为下雨不来。<br>——张爱玲《小团圆》</p></li><li><p>冷风如刀，以大地为砧板，视众生为鱼肉。<br>　万里飞雪，将苍穹作洪炉，溶万物为白银。<br>　雪将住，风未定，一辆马车自北而来，滚动的车轮碾碎了地上的冰雪，却碾不碎天地间的寂寞。<br>——古龙《多情剑客无情剑》</p></li></ol><p>17.愿中国青年都摆脱冷气，只是向上走，不必听自暴自弃者流的话。能做事的做事，能发声的发声。有一分热，发一分光。就令萤火一般，也可以在黑暗里发一点光，不必等候炬火。此后如竟没有炬火，我便是唯一的光……<br>——鲁迅《热风》</p><ol start="18"><li><p>你站在桥上看风景，看风景人在楼上看你。明月装饰了你的窗子，你装饰了别人的梦。<br>——卞之琳《断章》</p></li><li><p>爱是一个人的事情，而爱情是两个人的事情。所以，我爱你，与你无关。<br>——茨威格《一个陌生女人的来信》</p></li><li><p>是谁来自山川湖海，却囿于昼夜、厨房与爱。<br>——万能青年旅店《揪心的玩笑与漫长的白日梦 》</p></li><li><p>生命中曾拥有过的所有灿烂，终究都需要用寂寞偿还。<br>——《她比烟花寂寞》影评</p></li><li><p>当现实折过来严丝合缝地贴在我们长期的梦想上时，它盖住了梦想，与它混为一体，如同两个同样的图形重叠起来合而为一一样。<br>—— 马塞尔·普鲁斯特 《追忆似水年华》</p></li><li><p>人最宝贵的是生命，生命属于人只有一次，人的一生应当这样度过：当他回首往事时，不会因虚度年华而悔恨，也不会因碌碌无为而羞耻。这样，临终前他就可以自豪地说：“我已经把自己整个生命和全部的精力都献给了世界上最壮丽的事业为人类的解放而奋斗。”<br>—— 尼古拉·奥斯特洛夫斯基 《钢铁是怎么炼成的》</p></li><li><p>我在荒岛上迎接黎明。太阳初升时，忽然有十万支金喇叭齐鸣。阳光穿过透明的空气，在喑蓝色的天空飞过。在黑暗尚未褪去的海面上燃烧着十万支蜡烛。我听见天地之间钟声响了，然后十万支金喇叭又一次齐鸣。我忽然泪下如雨，但是我心底在欢歌。有一柄有弹性的长剑从我胸中穿过，带来了剧痛似的巨大感。这是我一生最美好的时刻，我站在那一个门坎上，从此我将和永恒连结起。<br>——王小波《我在荒岛上迎接黎明》</p></li><li><p>因为我既不生活在过去，也不生活在未来，我只有现在，它才是我感兴趣的。如果你能永远停留在现在，那你将是最幸福的人。你会发现沙漠里有生命，发现天空中有星星，发现士兵们打仗是因为战争是人类生活的一部分。生活就是一个节日，是一场盛大的庆典，因为生活永远是，也仅仅是我们现在经历的这一刻。<br>—— 保罗·柯艾略 《牧羊少年奇幻之旅》</p></li><li><p>我知道你愚蠢、轻挑、头脑空虚，然而，我爱你。 我知道你的企图、思想、势利、庸俗，然而，我爱你。 我知道你是二流货色，然而，我爱你<br>——毛姆《面纱》</p></li></ol><p>27.大部分人在二三十岁上就死去了，因为过了这个年龄，他们只是自己的影子，此后的余生则是在模仿自己中度过。日复一日，更机械，更装腔作势地重复他们在有生之年的所作所为，所思所想，所爱所恨。<br>——罗曼•罗兰《约翰•克利斯朵夫》</p><ol start="28"><li><p>当一个人有所追寻，”悉达多道，“他只会看到他追寻之物。他之所以无所发现、无所获得，是因为他只专注于他所追寻之物，因为他执迷于自己的目标。<br>——黑塞《悉达多》</p></li><li><p>生命好在无意义，才容得下各自赋予意义。假如生命是有意义的，这个意义却不合我的志趣，那才尴尬狼狈。<br>——木心《素履之往》</p></li><li><p>我想让你见识一下什么是真正的勇敢，而不要错误地认为一个人手握枪支就是勇敢。勇敢是，当你还未开始就已知道自己会输，可你依然要去做，而且无论如何都要把它坚持到底。你很少能赢，但有时也会。<br>—— 哈珀·李《杀死一只知更鸟》</p></li><li><p>眼看他起朱楼，眼看他宴宾客，眼看他楼塌了！<br>—— 孔尚任《桃花扇》</p></li><li><p>莫听穿林打叶声，何妨吟啸且徐行。竹杖芒鞋轻胜马，谁怕？一蓑烟雨任平生。<br>——苏轼《定风波·莫听穿林打叶声》</p></li><li><p>落霞与孤鹜齐飞，秋水共长天一色。<br>——王勃《滕王阁序》</p></li><li><p>我见青山多妩媚，料青山见我应如是。<br>——辛弃疾《贺新郎》</p></li></ol><p>35.衰老是从眼睛开始的。<br>——雨果 《吕意·布拉斯》</p><ol start="36"><li>井蛙不可以语于海者，拘于虚也；夏虫不可以语于冰者，笃于时也<br>——《庄子·秋水》</li></ol><p>37.我天性不宜交际。在多数场合，我不是觉得对方乏味，就是害怕对方觉得我乏味。可是我既不愿忍受对方的乏味，也不愿费劲使自己显得有趣，那都太累了。我独处时最轻松，因为我不觉得自己乏味，即使乏味，也自己承受，不累及他人，无需感到不安。<br>——周国平《人与永恒》</p><p>38.你没有如期归来，而这正是离别的意义。<br>——北岛《白日梦》</p><ol start="39"><li>草在结它的种子，风在摇它的叶子。我们站着，不说话，就十分美好。<br>——顾城《门前》</li></ol><p>40.从童年起，我便独自一人<br>照顾着<br>历代的星辰<br>——白鹤林《孤独》</p><ol start="41"><li><p>从前的日色变得慢 ，车，马，邮件都慢 ，一生只够爱一个人。<br>——木心《从前慢》</p></li><li><p>凌晨四点醒来，发现海棠花未眠<br>——川端康成《花未眠》</p></li><li><p>望着窗外，只要想起一生中后悔的事 ，梅花便落满了南山。<br>——张枣《镜中》</p></li></ol><p>44.世间情动,不过盛夏白瓷梅子汤,碎冰碰壁当啷响。<br>——《穆玄英挂帅》</p><p>45.蒹葭苍苍，白露为霜。所谓伊人，在水一方。<br>——《诗经》</p><ol start="46"><li><p>满天星光，满屋月亮，人生何如，为什么这么悲凉。 若赶上一个下雨的夜，就特别凄凉，寡妇可以落泪，鳏夫就要起来彷徨。<br>——萧红《呼兰河传》</p></li><li><p>白马带著她一步步的回到中原。白马已经老了，只能慢慢的走，但终是能回到中原的。江南有杨柳、桃花，有燕子、金鱼……汉人中有的是英俊勇武的少年，倜傥潇洒的少年……但这个美丽的姑娘就像古高昌国人那样固执：“那都是很好很好的，可是我偏偏不喜欢。”<br>——金庸《白马啸西风》</p></li></ol><p>48.世界沉默了，为了这些伤心的名字，为了这些伤心的名字后面那千百年寂寞的时光。<br>——何夕《伤心者》</p><p>49.给岁月以文明，而不是给文明以岁月。<br>——刘慈欣《三体2：黑暗森林》</p><ol start="50"><li><p>那一年我们踏雪回家，走到白雾深处，我看着她也怦然心动。那时候四面一片混沌，也不知天地在哪里，我看见她艰难地走过没膝的深雪，很想把她抱起来。她的小脸冻得通红，呵出的白气像喷泉一样。那时候天地茫茫，世界上好像再没有别的人。我想保护她，得到她，把她据为己有。<br>——王小波 《三十而立》</p></li><li><p>一天晚上，美棠突然说她想吃杏花楼的马蹄小蛋糕。家附近没有杏花楼，但较远的一个小区里有一家，骑自行车单程需约二十分钟。当我骑车赶到店里已经很晚，幸好还能买到马蹄蛋糕。可等我终于把蛋糕送到她枕边，她又不吃了。我那时年已八十六岁，儿女们得知此事无不责怪我不该夜里骑车出去，我也明知此时美棠说话已经胡涂，可我总是不能习惯，她嘱我做的事我竟不能依她。<br>——饶平如《我俩的故事 平如美棠》</p></li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">作者：单曲循环</span><br><span class="line">链接：https://www.zhihu.com/question/33449950/answer/176788398</span><br><span class="line">来源：知乎</span><br><span class="line">著作权归作者所有，转载请联系作者获得授权。</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;她那时候还太年轻，不知道所有命运赠送的礼物，早已在暗中标好了价格。&lt;/p&gt;
    
    </summary>
    
      <category term="美文" scheme="yunke.science/categories/%E7%BE%8E%E6%96%87/"/>
    
    
      <category term="美文" scheme="yunke.science/tags/%E7%BE%8E%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>THEY&#39;RE MADE OUT OF MEAT (他们是肉造的！)</title>
    <link href="yunke.science/2018/04/19/MADEOFMEAT/"/>
    <id>yunke.science/2018/04/19/MADEOFMEAT/</id>
    <published>2018-04-19T02:09:06.000Z</published>
    <updated>2018-04-19T02:20:58.000Z</updated>
    
    <content type="html"><![CDATA[<p>如果有一天，外星人真的和地球人有了亲密接触，那情形也许并不像人们幻想了几十年的壮丽和辉煌，而是有点囧，有点雷……</p><a id="more"></a><p>作者：［美］Terry Bisson（著名科幻小说家、雨果奖得主）译者：王月</p><hr><img src="/2018/04/19/MADEOFMEAT/0.jpg" title="天青色等烟雨"><p>“他们是肉造的。”</p><p>“肉？”</p><p>“对，是肉，他们是肉造的。”</p><p>“肉？”</p><p>“这点确凿无疑，我们从这个星球上的各个地方挑选了几个，把他们带到我们的侦查舰上，对他们做了彻底的检测——他们完完全全是肉造。”</p><p>“这怎么可能？那无线电信号是怎么回事？那些发往星空的信息是怎么回事？”</p><p>“他们使用无线电交谈，但信号却不是他们发出来的。这些信号都是机器发出来的。”</p><p>“那么，谁造的机器？他们才是我们真正想要接触的。”</p><p>“就是他们制造了机器。这正是我要告诉你的：肉制造了机器。”</p><p>“这太搞笑了。肉怎么可能制造机器呢？你要我相信一坨肉有意识？”</p><p>“我不是要你相信，我是告诉你，这些生物是那个区域里惟一有意识的种族，而他们是肉造的。”</p><p>“或许他们跟俄浮雷星人差不多，他们是那种要经历“肉形态”阶段的碳基智慧生物。”</p><p>“不，不是，他们生下来是坨肉，死的时候还是坨肉。我们研究过他们生命的整个时间跨度，他们的生命不是很长，你知道这些肉的生命时间跨度有多长吗？”</p><p>“饶了我吧。嗯，或许他们只是部分是肉。你清楚的，像威迪星人那样，肉质的头里面装的是个电子脑。”</p><p>“没有这回事，我们也那样设想过，因为他们的确有个肉质的头，像威迪星人那样的。但，我告诉过你，我们对他们做了彻底检测，他们完完全全、彻彻底底是坨肉。”</p><p>“没有大脑？”</p><p>“不是，他们也有一个大脑，但那只是个肉造的大脑！我不是跟你说过嘛。”</p><p>“那么……他们怎么思考？”</p><p>“你怎么还不明白啊？你硬是要跟我对着干，我不是告诉过你吗？大脑是可以思考的。肉可以思考。”</p><p>“能思考的肉！你让我相信世上有能思考的肉！”</p><p>“是的，能思考的肉！有意识的肉！有爱有恨的肉，会做梦的肉。所有的事实就是，他们是坨肉。你清楚这点了吗？还是要我再跟你讲一遍？”</p><p>“我的神呐，你是认真的了。他们是肉造的。”</p><p>“谢天谢地，你终于想通了。他们的确是肉造的，并且已经花了他们上百年的时间试图联系上我们。”</p><img src="/2018/04/19/MADEOFMEAT/1.jpg" title="天青色等烟雨"><p>“我的神呐，那么，这些肉造的脑子是怎么想的？”</p><p>“首先，他们想跟我们谈谈，然后我猜他们是想探索宇宙，接触其他的有自我意识的生物，交换思想和信息。这些都很寻常啊。”</p><p>“我们应该跟这些肉谈谈。”</p><p>“我赞成。他们通过无线电发出的信息都是些‘喂，那儿有人吗？有人在家吗？’诸如此类的话。”</p><p>“他们的确能交谈。那么，他们也能运用字词、思想，以及概念吧？”</p><p>“哦，是这样的，不过这些都是通过它们身上的肉来进行的。”</p><p>“我记得你告诉过我他们是使用无线电的。”</p><p>“他们的确使用无线电，但是，你认为他们用无线电是在讲什么？肉发出的声音。就是那种肉相互拍打时发出的声音，他们通过肉的相互拍打声来交谈的。他们甚至能通过他们的肉喷气来唱歌呢。“</p><p>“我的神呐，唱歌的肉。够了。那么，你有什么建议？”</p><p>“要正式书面的，还是私底下的建议？”</p><p>“你两个都说说。”</p><p>“书面上来讲，我们必须接触、欢迎和记录宇宙中这个象限里任何有意识的种族和智慧生物，不带任何偏见、恐惧或是个人喜好。私底下来讲，我建议我们抹掉这个记录，然后把整件事情都忘掉。”</p><p>“我正等着你这话呢！”</p><p>“这似乎有些难听，但凡事都有个限度。我们真的愿意与那一坨坨的肉接触吗？</p><p>“我百分之百的赞同你。想象一下，你能对肉说些什么呢？‘嗨，肉，最近怎样啊？’这能有用吗？我们在这里有多少行星要处理？”</p><p>“只有这一个。他们能通过一个特殊的肉质容器来航行到其他行星上去，但他们却不能在行星上定居。而且，作为肉，他们只能通过Ｃ空间来航行，这将他们限制在光速以内。而且也使得他们与其他智慧生物接触的可能性小，说实话，是无穷小。”</p><p>“那么，我们只要假装宇宙之中没有他们就可以了。”</p><p>“正是这样。”</p><p>“这有点残忍，但你自己也说了，有谁想见到那一坨坨的肉呢？那被你劫上侦查舰的那些肉，还有被你彻底检测过的那些肉怎么办呢？你确信他们不会记得这一切？”</p><p>“如果他们记得，他们也会被视为疯子的。我们进入他们的脑袋，抚平那些肉，所以对他们来说我们只是他们的一个梦。”</p><p>“肉的一个梦！我们将会是肉的一个梦，真是个奇怪而又恰当的说法。”</p><p>“然后我们把这里的整个区域标记为无生命区。”</p><p>“很好，我双手加双脚地赞同。事情终于结了。还有其他的吗？银河那一边还有其他有趣的事情吗？”</p><p>“是的，Ｇ４４５区域里９等恒星上的氢核集簇智慧体相当害羞，但是也很可爱。他们在两个银河自转年之前就与我们有过接触，他们想再次示好。”（注：银河自转一周约２．５亿年时间）</p><p>“他们总是会找上门来的。”</p><p>“为什么不呢？如果有谁在宇宙中是独自一个，那将是多么难以忍受，那种孤独感是多么难以言喻……”</p><p>作者语：<em>I’m honored that this often shows up on the internet. Here’s the correct version, as published in Omni, 1990.</em></p><p>作品源链接：<a href="http://www.terrybisson.com/page6/page6.html" target="_blank" rel="noopener">http://www.terrybisson.com/page6/page6.html</a></p><img src="/2018/04/19/MADEOFMEAT/2.jpg" title="天青色等烟雨">]]></content>
    
    <summary type="html">
    
      &lt;p&gt;如果有一天，外星人真的和地球人有了亲密接触，那情形也许并不像人们幻想了几十年的壮丽和辉煌，而是有点囧，有点雷……&lt;/p&gt;
    
    </summary>
    
      <category term="fiction" scheme="yunke.science/categories/fiction/"/>
    
    
      <category term="fiction" scheme="yunke.science/tags/fiction/"/>
    
  </entry>
  
</feed>
