<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>天青色等烟雨  而我在等你</title>
  
  <subtitle>文不在多、有换则新、人不在挤、有来就行</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="yunke.science/"/>
  <updated>2018-04-15T04:20:45.680Z</updated>
  <id>yunke.science/</id>
  
  <author>
    <name>Young</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>使用k8s容器钩子确保服务安全退出</title>
    <link href="yunke.science/2018/04/15/k8s-hook/"/>
    <id>yunke.science/2018/04/15/k8s-hook/</id>
    <published>2018-04-15T04:16:36.000Z</published>
    <updated>2018-04-15T04:20:45.680Z</updated>
    
    <content type="html"><![CDATA[<p>Kubernetes为容器提供了生命周期钩子。<br>钩子能使容器感知其生命周期内的事件，并且当相应的生命周期钩子被调用时运行指定的代码。</p><a id="more"></a><p><ul class="markdownIt-TOC"><li><a href="#%E5%AE%B9%E5%99%A8%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%9A%84%E9%92%A9%E5%AD%90">容器生命周期的钩子</a><ul><li><a href="#poststart">PostStart</a></li><li><a href="#prestop">PreStop</a></li></ul></li><li><a href="#%E9%92%A9%E5%AD%90%E5%A4%84%E7%90%86%E7%A8%8B%E5%BA%8F%E7%9A%84%E5%AE%9E%E7%8E%B0">钩子处理程序的实现</a></li><li><a href="#%E5%AE%9A%E4%B9%89%E9%A2%84%E5%90%AF%E5%8A%A8%E5%92%8C%E9%A2%84%E7%BB%93%E6%9D%9F%E4%BA%8B%E4%BB%B6%E6%93%8D%E4%BD%9C">定义预启动和预结束事件操作</a></li><li><a href="#%E4%BD%BF%E7%94%A8-prestop-hook-%E4%BF%9D%E8%AF%81%E6%9C%8D%E5%8A%A1%E5%AE%89%E5%85%A8%E9%80%80%E5%87%BA">使用 prestop hook 保证服务安全退出</a></li><li><a href="#%E5%8F%82%E8%80%83%E8%BF%9E%E6%8E%A5">参考连接</a></li></ul></p><h2><span id="容器生命周期的钩子"> 容器生命周期的钩子</span></h2><p>Kubernetes为容器提供了生命周期钩子。<br>钩子能使容器感知其生命周期内的事件，并且当相应的生命周期钩子被调用时运行指定的代码。</p><p>容器钩子分为两类触发点：容器创建后PostStart和容器终止前PreStop。</p><h3><span id="poststart"> PostStart</span></h3><p>这个钩子在容器创建后立即执行。<br>但是，并不能保证钩子将在容器ENTRYPOINT之前运行。<br>没有参数传递给处理程序。</p><p>容器ENTRYPOINT和钩子执行是异步操作。<br>如果钩子花费太长时间以至于容器不能运行或者挂起， 容器将不能达到running状态</p><h3><span id="prestop"> PreStop</span></h3><p>这个钩子在容器终止之前立即被调用。<br>它是阻塞的，意味着它是同步的， 所以它必须在删除容器的调用发出之前完成</p><p>如果钩子在执行期间挂起， Pod阶段将停留在running状态并且永不会达到failed状态。</p><p><strong>如果PostStart或者PreStop钩子失败， 容器将会被kill。<br>用户应该使他们的钩子处理程序尽可能的轻量。</strong></p><h2><span id="钩子处理程序的实现"> 钩子处理程序的实现</span></h2><p>容器可以通过实现和注册该钩子的处理程序来访问钩子。<br>可以为容器实现两种类型的钩子处理程序：</p><ul><li>Exec - 在容器的cgroups和命名空间内执行一个特定的命令，<a href="http://xn--pre-stop-jo1ot97l.sh" target="_blank" rel="noopener">比如pre-stop.sh</a>。<br>该命令消耗的资源被计入容器。</li><li>HTTP - 对容器上的特定的端点执行HTTP请求。</li></ul><p>在Pod的事件中没有钩子处理程序的日志。 如果一个处理程序因为某些原因运行失败，它广播一个事件。<br>对于PostStart, 这<strong>是FailedPostStartHook</strong>事件， 对于PreStop, 这是<strong>FailedPreStopHook</strong>事件。<br>你可以通过运行kubectl describe pod &lt;pod_name&gt;来查看这些事件。</p><h2><span id="定义预启动和预结束事件操作"> 定义预启动和预结束事件操作</span></h2><p>下面将会创建含有一个容器的Pod，我们将会给这个容器设置预启动和预结束操作。<br><a href="https://raw.githubusercontent.com/kubernetes/website/master/docs/tasks/configure-pod-container/lifecycle-events.yaml" target="_blank" rel="noopener">https://raw.githubusercontent.com/kubernetes/website/master/docs/tasks/configure-pod-container/lifecycle-events.yaml</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: lifecycle-demo</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: lifecycle-demo-container</span><br><span class="line">    image: nginx</span><br><span class="line">    lifecycle:</span><br><span class="line">      postStart:</span><br><span class="line">        exec:</span><br><span class="line">          command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo Hello from the postStart handler &gt; /usr/share/message&quot;]</span><br><span class="line">      preStop:</span><br><span class="line">        exec:</span><br><span class="line">          command: [&quot;/usr/sbin/nginx&quot;,&quot;-s&quot;,&quot;quit&quot;]</span><br></pre></td></tr></table></figure><h2><span id="使用-prestop-hook-保证服务安全退出"> 使用 prestop hook 保证服务安全退出</span></h2><p>在实际生产环境中使用spring框架，由于服务更新过程中，服务容器被直接终止，部分请求仍然被分发到终止的容器，导致出现500错误，这部分错误的请求数据占比较少，也可以忽略。<br>考虑添加优雅的终止方式，将错误请求降到最低，直至没有错误出现。</p><p>这里介绍 spring cloud 的服务发现组件：<br>Eureka 是一个基于 REST 的服务，作为服务注册中心，用于定位服务来进行中间层服务器的负载均衡和故障转移。<br>各服务启动时,会向Eureka Server注册自己的信息(IP,端口,服务信息等),Eureka Server会存储这些信息.<br>微服务启动后,会周期性(默认30秒)的向Eureka Server发送心跳以续约自己的”租期”，并可以从eureka中获取其他微服务的地址信息，执行相关的逻辑。<br><img src="http://www.ityouknow.com/assets/images/2017/springcloud/eureka-architecture-overview.png" alt="image"></p><p>考虑现在eureka server 修改注册实例的状态，暂停服务( InstanceStatus.OUT_OF_SERVICE )，保留一段时间后，再删除服务。</p><p>禁用某个服务：<br>curl -X PUT “<a href="http://admin:admin@192.168.101.100:8761/eureka/apps/%7BappName%7D/%7BinstanceId%7D/status?value=OUT_OF_SERVICE" target="_blank" rel="noopener">http://admin:admin@192.168.101.100:8761/eureka/apps/{appName}/{instanceId}/status?value=OUT_OF_SERVICE</a>”</p><p>说明：admin:admin是eureka的登录名和密码，如果没有，直接去掉前面这段；<br>instanceId是上面打开的链接显示的服务列表中的<instanceid>标签内容,如：myapp:192.168.1.100:8080</instanceid></p><p>在k8s 中的具体操作：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: NAME-service-deployment</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: NAME-service</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: NAME-service</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: NAME-service</span><br><span class="line">        lifecycle:</span><br><span class="line">          preStop:</span><br><span class="line">            exec:</span><br><span class="line">              command:</span><br><span class="line">                - &quot;/bin/sh&quot;</span><br><span class="line">                - &quot;-c&quot;</span><br><span class="line">                - &quot; \</span><br><span class="line">                  APPLICATION=NAME-service; \</span><br><span class="line">                  APPLICATION_PORT=8016; \</span><br><span class="line">                  curl -s -X PUT http://eureka01-server.domain.com/eureka/apps/$&#123;APPLICATION&#125;/$(hostname):$&#123;APPLICATION&#125;:$&#123;APPLICATION_PORT&#125;/status?value=OUT_OF_SERVICE; \</span><br><span class="line">                  sleep 30; \</span><br><span class="line">                  &quot;</span><br></pre></td></tr></table></figure><p>删除了无用的信息，重点关注 lifecycle<br>首先定义了服务名和端口的环境变量，把这部分单独作为变量，便于不同的服务进行修改。<br>使用 curl PUT 到eureka 配置状态为 OUT_OF_SERVICE。<br>配置一个sleep时间，作为服务停止缓冲时间。</p><h2><span id="参考连接"> 参考连接</span></h2><ol><li><a href="https://k8smeetup.github.io/docs/concepts/containers/container-lifecycle-hooks/" target="_blank" rel="noopener">容器生命周期的钩子</a></li><li><a href="https://k8smeetup.github.io/docs/concepts/workloads/pods/pod/#pods-%E7%9A%84%E7%BB%88%E6%AD%A2" target="_blank" rel="noopener">Pods 的终止</a></li><li><a href="https://k8smeetup.github.io/docs/tasks/configure-pod-container/attach-handler-lifecycle-event/" target="_blank" rel="noopener">给容器生命周期设置操作事件</a></li><li><a href="https://blog.csdn.net/wangdw1984/article/details/78459782" target="_blank" rel="noopener">eureka服务禁用</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Kubernetes为容器提供了生命周期钩子。&lt;br&gt;
钩子能使容器感知其生命周期内的事件，并且当相应的生命周期钩子被调用时运行指定的代码。&lt;/p&gt;
    
    </summary>
    
      <category term="Kubernetes" scheme="yunke.science/categories/Kubernetes/"/>
    
    
      <category term="Kubernetes" scheme="yunke.science/tags/Kubernetes/"/>
    
      <category term="docker" scheme="yunke.science/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>Docker 基本概念</title>
    <link href="yunke.science/2018/04/14/docker-notions/"/>
    <id>yunke.science/2018/04/14/docker-notions/</id>
    <published>2018-04-14T13:36:01.000Z</published>
    <updated>2018-04-15T02:20:21.292Z</updated>
    
    <content type="html"><![CDATA[<p>A container image is a lightweight, stand-alone, executable package of a piece of software that includes everything needed to run it: code, runtime, system tools, system libraries, settings.<br>Available for both Linux and Windows based apps, containerized software will always run the same, regardless of the environment.<br>Containers isolate software from its surroundings, for example differences between development and staging environments and help reduce conflicts between teams running different software on the same infrastructure.</p><p><ul class="markdownIt-TOC"><li><a href="#%E4%BB%80%E4%B9%88%E6%98%AF-docker">什么是 Docker</a></li><li><a href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E4%BD%BF%E7%94%A8-docker">为什么要使用 Docker？</a></li><li><a href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5">基本概念</a><ul><li><a href="#%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A8">分层存储</a></li></ul></li><li><a href="#%E9%AB%98%E7%BA%A7%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE">高级网络配置</a></li><li><a href="#%E5%AE%89%E5%85%A8%E7%9B%B8%E5%85%B3">安全相关</a></li><li><a href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8pod">为什么使用pod</a><ul><li><a href="#%E7%AE%A1%E7%90%86%E9%9C%80%E6%B1%82">管理需求</a></li><li><a href="#%E8%B5%84%E6%BA%90%E5%85%B1%E4%BA%AB%E5%92%8C%E9%80%9A%E4%BF%A1">资源共享和通信</a></li></ul></li><li><a href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E5%9C%A8%E4%B8%80%E4%B8%AA%E5%AE%B9%E5%99%A8%E4%B8%AD%E8%BF%90%E8%A1%8C%E5%A4%9A%E4%B8%AA%E7%A8%8B%E5%BA%8F">为什么不在一个容器中运行多个程序？</a></li><li><a href="#pods-%E7%9A%84%E7%BB%88%E6%AD%A2%E8%BF%87%E7%A8%8B">Pods 的终止过程</a><ul><li><a href="#%E5%BC%BA%E5%88%B6%E5%88%A0%E9%99%A4-pods">强制删除 pods</a></li></ul></li><li><a href="#pod-%E5%AE%B9%E5%99%A8%E7%9A%84%E7%89%B9%E6%9D%83%E6%A8%A1%E5%BC%8F">Pod 容器的特权模式</a></li><li><a href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99">参考资料</a></li></ul></p><h2><span id="什么是-docker"> 什么是 Docker</span></h2><p>Docker 使用 Google 公司推出的 Go 语言 进行开发实现，基于 Linux 内核的 cgroup，namespace，以及 AUFS 类的 Union FS 等技术，对进程进行封装隔离，属于 操作系统层面的虚拟化技术。由于隔离的进程独立于宿主和其它的隔离的进程，因此也称其为容器。最初实现是基于 LXC，从 0.7 版本以后开始去除 LXC，转而使用自行开发的 libcontainer，从 1.11 开始，则进一步演进为使用 runC 和 containerd。</p><p>传统虚拟机技术是虚拟出一套硬件后，在其上运行一个完整操作系统，在该系统上再运行所需应用进程；而容器内的应用进程直接运行于宿主的内核，容器内没有自己的内核，而且也没有进行硬件虚拟。因此容器要比传统虚拟机更为轻便。</p><h2><span id="为什么要使用-docker"> 为什么要使用 Docker？</span></h2><ol><li>更高效的资源利用率</li><li>更快速的启动时间</li><li>一致的运行环境</li><li>不同服务资源隔离</li><li>持续交付和部署</li><li>更轻松的迁移</li><li>更轻松的维护和扩展</li></ol><h2><span id="基本概念"> 基本概念</span></h2><ul><li>镜像（Image）</li><li>容器（Container）</li><li>仓库（Repository）</li></ul><h3><span id="分层存储"> 分层存储</span></h3><p>因为镜像包含操作系统完整的 root 文件系统，其体积往往是庞大的，因此在 Docker 设计时，就充分利用 Union FS 的技术，将其设计为分层存储的架构。所以严格来说，镜像并非是像一个 ISO 那样的打包文件，镜像只是一个虚拟的概念，其实际体现并非由一个文件组成，而是由一组文件系统组成，或者说，由多层文件系统联合组成。</p><p>镜像构建时，会一层层构建，前一层是后一层的基础。每一层构建完就不会再发生改变，后一层上的任何改变只发生在自己这一层。比如，删除前一层文件的操作，实际不是真的删除前一层的文件，而是仅在当前层标记为该文件已删除。在最终容器运行的时候，虽然不会看到这个文件，但是实际上该文件会一直跟随镜像。因此，在构建镜像的时候，需要额外小心，每一层尽量只包含该层需要添加的东西，任何额外的东西应该在该层构建结束前清理掉。</p><p>分层存储的特征还使得镜像的复用、定制变的更为容易。甚至可以用之前构建好的镜像作为基础层，然后进一步添加新的层，以定制自己所需的内容，构建新的镜像。</p><h2><span id="高级网络配置"> 高级网络配置</span></h2><p>当 Docker 启动时，会自动在主机上创建一个 docker0 虚拟网桥，实际上是 Linux 的一个 bridge，可以理解为一个软件交换机。它会在挂载到它的网口之间进行转发。</p><p>同时，Docker 随机分配一个本地未占用的私有网段（在 RFC1918 中定义）中的一个地址给 docker0 接口。比如典型的 172.17.42.1，掩码为 255.255.0.0。此后启动的容器内的网口也会自动分配一个同一网段（172.17.0.0/16）的地址。</p><p>当创建一个 Docker 容器的时候，同时会创建了一对 veth pair 接口（当数据包发送到一个接口时，另外一个接口也可以收到相同的数据包）。这对接口一端在容器内，即 eth0；另一端在本地并被挂载到 docker0 网桥，名称以 veth 开头（例如 vethAQI2QT）。通过这种方式，主机可以跟容器通信，容器之间也可以相互通信。Docker 就创建了在主机和所有容器之间一个虚拟共享网络。</p><h2><span id="安全相关"> 安全相关</span></h2><p>对于DDOS攻击的防护<br>关闭不必要的服务和端口；限制同一时间内的打开的syn半连接数目；缩短syn半连接的超时时间；及时安装系统补丁；禁止对主机非开放服务的访问；启用防火墙防DDOS属性。</p><h2><span id="为什么使用pod"> 为什么使用pod</span></h2><h3><span id="管理需求"> 管理需求</span></h3><p>Pod 是这样一个模式的抽象：<strong>互相协作的多个进程共同形成一个完整的服务。通过提供对应用的更高层次的抽象，pod简化了应用部署和管理。</strong><br>pod是部署、水平扩展以及复制的基本单元。容器的协同工作（协同调度)，共享生命周期(比如说：终止), 复制协调，资源共享以及依赖管理都自动在 pod 内部进行处理。</p><h3><span id="资源共享和通信"> 资源共享和通信</span></h3><p>Pod 内部实现了数据共享和相互通信。</p><p><strong>在 pod 里的所有应用使用同一个网络空间(相同的 IP 和端口)， 彼此之间可以通过 localhost 相互通信。</strong><br>因此在同一个 pod 里的应用必须相互之间协调好端口的使用。每一个 pod 都拥有一个平面网络空间的 IP 地址，使用这个地址可以与网络中其他物理机器和 pods 进行通信。</p><p>除了定义运行在pod中的应用容器，<strong>pod还可以指定一系列共享存储卷。有了卷，数据就不会在容器重启后丢失，数据还可以在pod内的容器之间共享。</strong></p><h2><span id="为什么不在一个容器中运行多个程序"> 为什么不在一个容器中运行多个程序？</span></h2><ol><li><p>透明度。让 pod 里的容器可见于框架，框架则可以很容易的给这些容器提供服务，比如说：进程管理，资源监控。 这种机制给用户带来了很大的便利。</p></li><li><p>解耦软件依赖。每一个独立的容器都可以单独管理版本，也可以单独重构和重新部署。 Kubernetes 甚至有一天可以实现为单独容器的在线升级。</p></li><li><p>易用性。用户们不需要运行自己的进程管理，也不需要担心信号和退出处理等等。</p></li><li><p>效率。由于基础设施承担了更多的职责，容器从而变得更加轻量级。</p></li></ol><p>为什么不支持基于亲和性的容器协同调度？</p><p>这个方法可以提供协同寻址，但是不能提供大多数 pods 优势，比如说资源共享， IPC, 生命周期共享以及最简化的管理。</p><h2><span id="pods-的终止过程"> Pods 的终止过程</span></h2><p>由于 pods 是一个运行在集群中的进程，所以很重要的一点是，当它们不再被需要时如何优雅地终止 Pod (而不是粗暴的使用 KILL 命令杀死它们以至于没有做清理工作)。用户需要能够发起一个删除 Pod 的请求，知晓 Pod 何时终止，同时应该也能够确认这个删除事件是否已经完成。</p><p><strong>当用户提出删除一个 pod 的请求时，系统会先发送 TERM 信号给每个容器的主进程，如果在预设的宽限期之后这些进程没有自主终止运行，系统会发送 KILL 信号给这些进程，接着 pod 将被从 API server 中删除。</strong></p><p><em>如果 Kubelet 或者 container manager 在等待结束进程时重新启动，终止操作将在宽限期内反复重试。</em></p><p>示例流程：</p><ul><li><ol><li>用户发送一个删除 Pod 的命令， 并使用默认的宽限期（30s)： terminationGracePeriodSeconds: 30。</li></ol></li><li><ol start="2"><li>API server中的pod状态设为dead，时间设置为宽限期</li></ol></li><li><ol start="3"><li>使用客户端的命令，显示出的Pod的状态为 ”terminating”。</li></ol></li><li><ol start="4"><li>（与第3步同时发生）Kubelet 发现某一个 Pod 由于时间超过第2步的设置而被标志成 terminating 状态时， Kubelet 将启动一个kill进程。<br>a. 如果 pod 已经被定义成一个 preStop hook，这会在 pod 内部进行调用。如果宽限期已经过期但 preStop - hook 依然还在运行，将调用第2步并在原来的宽限期上加一个小的时间窗口（2 秒钟）。<br>b. 把 Pod 里的进程发送到 TERM 信号。</li></ol></li><li><ol start="5"><li>（与第3步同时发生），Pod 被从终端的服务列表里移除，同时也不再被 replication controllers 看做时一组运行中的 - pods. 在负载均衡（比如说 service proxy）会将它们从轮做中移除前， Pods - 这种慢关闭的方式可以继续为流量提供服务。</li></ol></li><li><ol start="6"><li>当宽期限过期时， 任何还在 Pod 里运行的进程都会被 SIGKILL 杀掉。</li></ol></li><li><ol start="7"><li>Kubelet 通过在 API server 把宽期限设置成0(立刻删除)的方式完成删除 Pod的过程。 这时 Pod 在 API - 里消失，也不再能被用户看到。</li></ol></li></ul><p>默认所有的宽期限都在30秒内。kubectl delete 命令支持 --grace-period=<seconds> - 选项，这个选项允许用户用他们自己指定的值覆盖默认值。值’0‘代表 强制删除 pod. 在 kubectl 1.5 - 及以上的版本里，执行强制删除时必须同时指定 --force ， --grace-period=0。</seconds></p><h3><span id="强制删除-pods"> 强制删除 pods</span></h3><p>强制删除一个 pod 是从集群状态还有 etcd 里立刻删除这个 pod. 当 Pod 被强制删除时， api 服务器不会等待来自 Pod 所在节点上的 kubelet 的确认信息：pod 已经被终止。在 API 里 pod 会被立刻删除，这样新的 pod 就能被创建并且使用完全一样的名字。在节点上， pods 被设置成立刻终止后，在强行杀掉前还会有一个很小的宽限期。</p><h2><span id="pod-容器的特权模式"> Pod 容器的特权模式</span></h2><p>从 Kubernetes v1.1 开始， pod 的容器都可以启动特权模式，只需要将 container spec 的 SecurityContext 指定为 privileged 标志。这对于那些想使用网络栈操作以及访问系统设备等 Linux 能力的容器来说，是个非常有用的功能。 容器里的进程获得了与容器外进程几乎完全相同的权限。有了特权模式，编写网络和卷插件变得更加容易，因为它们可以作为独立的 Pod 运行，而无需编译到 kubelet 中去。</p><p>如果 master 运行的 Kubernetes 版本是 v1.1 或者更高，但是节点上运行的版本低于 v1.1，api-server 虽然会接受新的特权 pod ，但这些 pod 却无法正常运行起来。 它们将一直处于 pending 状态。 当用户调用 kubectl describe pod FooPodName 查看 pod 一直处于 pending 状态的原因时，在 describe command 的输出事件表里会有类似下面的信息： Error validating pod “FooPodName”.“FooPodNamespace” from api, ignoring: spec.containers[0].securityContext.privileged: forbidden ‘&lt;*&gt;(0xc2089d3248)true’</p><p>如果 master 运行的 Kubernetes 版本低于 v1.1，则不能创建特权Pod。在这种情况如果用户尝试去创建一个包含特权容器的 pod ，那么将会返回类似下面的错误信息： The Pod “FooPodName” is invalid. spec.containers[0].securityContext.privileged: forbidden ‘&lt;*&gt;(0xc20b222db0)true’</p><h2><span id="参考资料"> 参考资料</span></h2><ol><li><a href="https://yeasy.gitbooks.io/docker_practice/content/introduction/why.html" target="_blank" rel="noopener">Docker —— 从入门到实践<br></a></li><li><a href="https://k8smeetup.github.io/docs/concepts/workloads/pods/pod/" target="_blank" rel="noopener">kubernetes pods</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;A container image is a lightweight, stand-alone, executable package of a piece of software that includes everything needed to run it: cod
      
    
    </summary>
    
      <category term="docker" scheme="yunke.science/categories/docker/"/>
    
    
      <category term="docker" scheme="yunke.science/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>Tini - 一个小而有效的容器初始化命令</title>
    <link href="yunke.science/2018/04/09/Tini-command/"/>
    <id>yunke.science/2018/04/09/Tini-command/</id>
    <published>2018-04-09T07:24:24.000Z</published>
    <updated>2018-04-14T13:45:47.564Z</updated>
    
    <content type="html"><![CDATA[<p>Tini是你能想到的最简单的init。<br>Tini所做的一切都是衍生出一个单独的子进程(Tini是在一个容器中运行的)，等待它退出所有的时候，然后杀死僵尸进程和执行信号转发。<br>github地址： <a href="https://github.com/krallin/tini" target="_blank" rel="noopener">https://github.com/krallin/tini</a></p><h2><span id="tini优势"> Tini优势</span></h2><ul><li>它可以防止意外造成僵尸进程的软件，僵尸进程可以（随着时间的推移）让整个系统崩溃，并使其无法使用。</li><li>它确保默认的信号处理程序适用于您在Docker镜像中运行的软件。 例如，对于Tini，即使您没有为其显式安装信号处理程序，SIGTERM 也会正确终止您的过程。</li><li>它完全透明！ 没有Tini工作的Docker图像将与Tini无任何变化一起工作。</li></ul><h2><span id="使用-tini"> 使用 Tini</span></h2><p>注意：如果您使用的是Docker 1.13或更高版本，则Tini会包含在Docker中。 这包括所有版本的Docker CE。 要启用Tini，只需将 --init 标志传递给docker run即可。</p><p>注意：Tini有预先构建的Docker镜像。 如果您当前使用的是Ubuntu或CentOS映像作为您的基础，则可以将其中一个用作插入式替换。</p><p>注意：有Alpine Linux和NixOS的Tini软件包。 请参阅下面的安装说明。</p><p>将Tini添加到您的容器中，并使其可执行。 然后，只需调用Tini并将您的程序及其参数作为参数传递给Tini。</p><p>在Docker中，您将需要使用入口点，因此您不必记住手动调用Tini：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># Add Tini</span><br><span class="line">ENV TINI_VERSION v0.17.0</span><br><span class="line">ADD https://github.com/krallin/tini/releases/download/$&#123;TINI_VERSION&#125;/tini /tini</span><br><span class="line">RUN chmod +x /tini</span><br><span class="line">ENTRYPOINT [&quot;/tini&quot;, &quot;--&quot;]</span><br><span class="line"></span><br><span class="line"># Run your program under Tini</span><br><span class="line">CMD [&quot;/your/program&quot;, &quot;-and&quot;, &quot;-its&quot;, &quot;arguments&quot;]</span><br><span class="line"># or docker run your-image /your/program ...</span><br></pre></td></tr></table></figure><p>jenkins/entrypoint.sh 示例</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#! /bin/bash</span><br><span class="line">set -e</span><br><span class="line">chown -R 1000 &quot;$JENKINS_HOME&quot;</span><br><span class="line">exec gosu jenkins /bin/tini -- /usr/local/bin/jenkins.sh</span><br></pre></td></tr></table></figure><p>请注意，您可以在某些情况下可能不需要 – ，但始终将其包括在内以保证安全。 如果看到类似tini的错误消息：无效选项 - ‘c’，则需要添加 – 。</p><p>Tini本身的参数应该像-v一样在下面的例子中传递：/tini -v – /your/program</p><p>注：上面链接的二进制文件是一个64位动态链接二进制文件。</p><p>Tini也可以与容器中现有的/docker-entrypoint.sh一起使用！</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ENTRYPOINT [&quot;/tini&quot;, &quot;--&quot;, &quot;/docker-entrypoint.sh&quot;]</span><br></pre></td></tr></table></figure><h2><span id="alpine-linux-包管理"> Alpine Linux 包管理</span></h2><p>在Alpine Linux上，您可以使用以下命令来安装Tini：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">RUN apk add --no-cache tini</span><br><span class="line"># Tini is now available at /sbin/tini</span><br><span class="line">ENTRYPOINT [&quot;/sbin/tini&quot;, &quot;--&quot;]</span><br></pre></td></tr></table></figure><p>静态链接版本<br>Tini只有很少的依赖关系（它只依赖于libc），但是如果你的容器无法启动，你可能需要考虑使用静态构建的版本：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ADD https://github.com/krallin/tini/releases/download/$&#123;TINI_VERSION&#125;/tini-static /tini</span><br></pre></td></tr></table></figure><h2><span id="其他选项"> 其他选项</span></h2><h3><span id="详细输出"> 详细输出</span></h3><p>-v 参数可用于额外的详细输出（最多可传递3次，例如-vvv）。</p><h3><span id="subreaping-次级启动"> Subreaping 次级启动</span></h3><p>默认情况下，Tini需要以PID 1运行，以便它可以检测僵尸进程（作为PID 1运行，僵尸会重新添加到Tini中）。</p><p>如果由于某种原因，您无法将Tini作为PID 1运行，您应该将Tini注册为进程子区域转换器（仅在Linux&gt; = 3.4中），方法如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tini -s -- ...</span><br></pre></td></tr></table></figure><p>注意：如果Tini检测到它不是作为PID 1运行并且未注册为次级别，则会发出警告。</p><h3><span id="重新映射退出代码"> 重新映射退出代码</span></h3><p>Tini在退出时会重复使用子进程的退出代码，但偶尔这可能不是您想要的（例如，如果您的子进程在收到SIGTERM后返回143退出）。   值得注意的是，这可能是Java应用程序的一个问题。</p><p>在这种情况下，您可以使用-e标志将任意退出代码重新映射为0.如果需要，您可以多次传递该标志。</p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tini -e 143 - ...</span><br></pre></td></tr></table></figure><h3><span id="进程组查杀"> 进程组查杀</span></h3><p>默认情况下，Tini只会杀死其直接的子进程。 如果向该进程发送信号没有达到预期的效果，这可能是不方便的。 例如，如果你这样做</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run krallin/ubuntu-tini sh -c &apos;sleep 10&apos;</span><br></pre></td></tr></table></figure><p>和ctrl-C它没有任何反应：SIGINT被发送到’sh’进程，但是当shell等待’sleep’完成时，它不会对它做出反应。</p><p>使用-g选项，Tini杀死子进程组，以便组中的每个进程都获得信号。 这更接近于当您在终端中执行ctrl-C等时发生的情况：信号被发送到前台进程组。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Tini是你能想到的最简单的init。&lt;br&gt;
Tini所做的一切都是衍生出一个单独的子进程(Tini是在一个容器中运行的)，等待它退出所有的时候，然后杀死僵尸进程和执行信号转发。&lt;br&gt;
github地址： &lt;a href=&quot;https://github.com/kral
      
    
    </summary>
    
      <category term="docker" scheme="yunke.science/categories/docker/"/>
    
    
      <category term="docker" scheme="yunke.science/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>gosu or sudo</title>
    <link href="yunke.science/2018/04/09/gosu-or-sudo/"/>
    <id>yunke.science/2018/04/09/gosu-or-sudo/</id>
    <published>2018-04-09T02:45:55.000Z</published>
    <updated>2018-04-09T02:48:30.612Z</updated>
    
    <content type="html"><![CDATA[<p>gosu官方介绍为一个简单的基于go的工具，集成setuid+setgid+setgroups+exec.<br>github地址：<a href="https://github.com/tianon/gosu" target="_blank" rel="noopener">https://github.com/tianon/gosu</a><br>参考： <a href="https://segmentfault.com/a/1190000004527476" target="_blank" rel="noopener">https://segmentfault.com/a/1190000004527476</a></p><p><ul class="markdownIt-TOC"><li><a href="#%E7%AE%80%E4%BB%8B">简介</a></li><li><a href="#%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B">使用示例</a></li><li><a href="#%E6%99%AE%E9%80%9A%E5%AE%89%E8%A3%85">普通安装</a></li><li><a href="#%E5%9C%A8dockerfile-%E4%B8%AD%E5%AE%89%E8%A3%85">在Dockerfile 中安装</a><ul><li><a href="#from-alpine-33"><code>FROM alpine</code> (3.3+)</a></li><li><a href="#from-centos"><code>FROM centos</code></a></li></ul></li><li><a href="#%E5%85%B6%E4%BB%96%E5%8F%AF%E9%80%89%E7%9A%84%E6%96%B9%E6%A1%88">其他可选的方案</a><ul><li><a href="#su-exec"><code>su-exec</code></a></li><li><a href="#chroot"><code>chroot</code></a></li><li><a href="#others">Others</a></li></ul></li></ul></p><h2><span id="简介"> 简介</span></h2><p>这是一个简单的工具，它诞生于一个简单的事实，即su和sudo具有非常奇怪且常常令人讨厌的TTY和信号转发行为。   它们在设置和使用方面也有些复杂（特别是在sudo的情况下），它允许过大的权限，但你需要的只是“<strong>作为这个特定的用户运行这个特定的应用程序并退出</strong>”。</p><p>gosu工作的核心是直接从Docker/libcontainer本身开始在容器中启动应用程序(实际上，是直接从libcontainer的代码库中使用/etc/passwd处理代码)。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ gosu</span><br><span class="line">Usage: ./gosu user-spec command [args]</span><br><span class="line">   ie: ./gosu tianon bash</span><br><span class="line">       ./gosu nobody:root bash -c &apos;whoami &amp;&amp; id&apos;</span><br><span class="line">       ./gosu 1000:1 id</span><br><span class="line"></span><br><span class="line">./gosu version: 1.1 (go1.3.1 on linux/amd64; gc)</span><br></pre></td></tr></table></figure><p>一旦用户/组被指定，我们就切换到那个用户，然后我们执行指定的进程， <strong>而gosu本身不再是驻留的，也不再参与到流程生命周期中</strong> 。这样就避免了信号传递和TTY的所有问题，并将它们推到调用gosu的过程中，以及它们所属的gosu调用的过程。</p><p><strong>gosu的核心用例是在容器启动时从根目录下到非特权用户(通常是在ENTRYPOINT中)。</strong></p><h2><span id="使用示例"> 使用示例</span></h2><p>Dockerfile 最佳实践中示例 <a href="https://docs.docker.com/engine/reference/builder/#exec-form-entrypoint-example" target="_blank" rel="noopener">Best practices for writing Dockerfiles</a> ，<br>Postgres image使用以下脚本作为其入口点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env bash</span><br><span class="line">set -e</span><br><span class="line"></span><br><span class="line">if [ &quot;$1&quot; = &apos;postgres&apos; ]; then</span><br><span class="line">    chown -R postgres &quot;$PGDATA&quot;</span><br><span class="line"></span><br><span class="line">    if [ -z &quot;$(ls -A &quot;$PGDATA&quot;)&quot; ]; then</span><br><span class="line">        gosu postgres initdb</span><br><span class="line">    fi</span><br><span class="line"></span><br><span class="line">    exec gosu postgres &quot;$@&quot;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">exec &quot;$@&quot;</span><br></pre></td></tr></table></figure><p>上面的脚本中，docker run指定的命令会以postgres用户的身份执行。</p><p>所谓的ENTRYPOINT，正如其名，就是该镜像的根命令。默认的ENTRYPOINT为/bin/sh -c，通过docker run或CMD指定的命令会作为ENTRYPOINT的参数执行。举个例子，docker run ubuntu:latest ls就是执行/bin/sh -c ls。有些时候我们需要指定ENTRYPOINT的值，比如换成自己的包装脚本。</p><p>默认docker中的命令都是以root身份启动的（因为默认只有root用户）。不过你也可以通过USER指令设置当前使用的用户。某些时候，你可能需要在docker build中使用多个用户，比如上面例子中，安装依赖需要root，运行程序时使用的是postgres。这时候就需要动态指定一个用户身份。</p><p>docker文档中建议，如果需要动态指定一个用户身份，需要使用gosu而非平常的sudo。</p><p>然而文档中并没有解释为什么。gosu的项目主页中也只提到gosu避免了strange and often annoying TTY and signal-forwarding behavior。（然后顺便黑了下sudo太过于复杂）。不过gosu的测试用例透露了些蛛丝马迹，可以看出它认为sudo至少有两点不好：</p><p>sudo会作为被授权的命令的父进程一直存在，直到该命令退出。</p><p>sudo模式下的HOME环境变量仍是用sudo者原来的值。</p><h2><span id="普通安装"> 普通安装</span></h2><p>High-level steps:</p><ul><li>download gosu-$(dpkg --print-architecture | awk -F- ‘{ print $NF }’) as gosu</li><li>download gosu-$(dpkg --print-architecture | awk -F- ‘{ print $NF }’).asc as gosu.asc</li><li>fetch my public key (to verify your download): gpg --keyserver <a href="http://ha.pool.sks-keyservers.net" target="_blank" rel="noopener">ha.pool.sks-keyservers.net</a> --recv-keys B42F6819007F00F88E364FD4036A9C25BF357DD4</li><li>gpg --batch --verify gosu.asc gosu</li><li>chmod +x gosu</li></ul><h2><span id="在dockerfile-中安装"> 在Dockerfile 中安装</span></h2><p><a href="https://github.com/tianon/gosu/blob/master/INSTALL.md" target="_blank" rel="noopener">https://github.com/tianon/gosu/blob/master/INSTALL.md</a></p><h3><span id="from-alpine-33"> <code>FROM alpine</code> (3.3+)</span></h3><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ENV</span> GOSU_VERSION <span class="number">1.10</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">set</span> -ex; \</span></span><br><span class="line"><span class="bash">\</span></span><br><span class="line"><span class="bash">apk add --no-cache --virtual .gosu-deps \</span></span><br><span class="line"><span class="bash">dpkg \</span></span><br><span class="line"><span class="bash">gnupg \</span></span><br><span class="line"><span class="bash">openssl \</span></span><br><span class="line"><span class="bash">; \</span></span><br><span class="line"><span class="bash">\</span></span><br><span class="line"><span class="bash">dpkgArch=<span class="string">"<span class="variable">$(dpkg --print-architecture | awk -F- '&#123; print $NF &#125;')</span>"</span>; \</span></span><br><span class="line"><span class="bash">wget -O /usr/<span class="built_in">local</span>/bin/gosu <span class="string">"https://github.com/tianon/gosu/releases/download/<span class="variable">$GOSU_VERSION</span>/gosu-<span class="variable">$dpkgArch</span>"</span>; \</span></span><br><span class="line"><span class="bash">wget -O /usr/<span class="built_in">local</span>/bin/gosu.asc <span class="string">"https://github.com/tianon/gosu/releases/download/<span class="variable">$GOSU_VERSION</span>/gosu-<span class="variable">$dpkgArch</span>.asc"</span>; \</span></span><br><span class="line"><span class="bash">\</span></span><br><span class="line"><span class="bash"><span class="comment"># verify the signature</span></span></span><br><span class="line"><span class="bash"><span class="built_in">export</span> GNUPGHOME=<span class="string">"<span class="variable">$(mktemp -d)</span>"</span>; \</span></span><br><span class="line"><span class="bash">gpg --keyserver ha.pool.sks-keyservers.net --recv-keys B42F6819007F00F88E364FD4036A9C25BF357DD4; \</span></span><br><span class="line"><span class="bash">gpg --batch --verify /usr/<span class="built_in">local</span>/bin/gosu.asc /usr/<span class="built_in">local</span>/bin/gosu; \</span></span><br><span class="line"><span class="bash">rm -r <span class="string">"<span class="variable">$GNUPGHOME</span>"</span> /usr/<span class="built_in">local</span>/bin/gosu.asc; \</span></span><br><span class="line"><span class="bash">\</span></span><br><span class="line"><span class="bash">chmod +x /usr/<span class="built_in">local</span>/bin/gosu; \</span></span><br><span class="line"><span class="bash"><span class="comment"># verify that the binary works</span></span></span><br><span class="line"><span class="bash">gosu nobody <span class="literal">true</span>; \</span></span><br><span class="line"><span class="bash">\</span></span><br><span class="line"><span class="bash">apk del .gosu-deps</span></span><br></pre></td></tr></table></figure><p>When using Alpine, it’s probably also worth checking out <a href="https://github.com/ncopa/su-exec" target="_blank" rel="noopener"><code>su-exec</code></a> (<code>apk add --no-cache su-exec</code>), which since version 0.2 is fully <code>gosu</code>-compatible in a fraction of the file size.</p><h3><span id="from-centos"> <code>FROM centos</code></span></h3><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ENV</span> GOSU_VERSION <span class="number">1.10</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">set</span> -ex; \</span></span><br><span class="line"><span class="bash">\</span></span><br><span class="line"><span class="bash">yum -y install epel-release; \</span></span><br><span class="line"><span class="bash">yum -y install wget dpkg; \</span></span><br><span class="line"><span class="bash">\</span></span><br><span class="line"><span class="bash">dpkgArch=<span class="string">"<span class="variable">$(dpkg --print-architecture | awk -F- '&#123; print $NF &#125;')</span>"</span>; \</span></span><br><span class="line"><span class="bash">wget -O /usr/bin/gosu <span class="string">"https://github.com/tianon/gosu/releases/download/<span class="variable">$GOSU_VERSION</span>/gosu-<span class="variable">$dpkgArch</span>"</span>; \</span></span><br><span class="line"><span class="bash">wget -O /tmp/gosu.asc <span class="string">"https://github.com/tianon/gosu/releases/download/<span class="variable">$GOSU_VERSION</span>/gosu-<span class="variable">$dpkgArch</span>.asc"</span>; \</span></span><br><span class="line"><span class="bash">\</span></span><br><span class="line"><span class="bash"><span class="comment"># verify the signature</span></span></span><br><span class="line"><span class="bash"><span class="built_in">export</span> GNUPGHOME=<span class="string">"<span class="variable">$(mktemp -d)</span>"</span>; \</span></span><br><span class="line"><span class="bash">gpg --keyserver ha.pool.sks-keyservers.net --recv-keys B42F6819007F00F88E364FD4036A9C25BF357DD4; \</span></span><br><span class="line"><span class="bash">gpg --batch --verify /tmp/gosu.asc /usr/bin/gosu; \</span></span><br><span class="line"><span class="bash">rm -r <span class="string">"<span class="variable">$GNUPGHOME</span>"</span> /tmp/gosu.asc; \</span></span><br><span class="line"><span class="bash">\</span></span><br><span class="line"><span class="bash">chmod +x /usr/bin/gosu; \</span></span><br><span class="line"><span class="bash"><span class="comment"># verify that the binary works</span></span></span><br><span class="line"><span class="bash">gosu nobody <span class="literal">true</span>; \</span></span><br><span class="line"><span class="bash">\</span></span><br><span class="line"><span class="bash">yum -y remove wget dpkg; \</span></span><br><span class="line"><span class="bash">yum clean all</span></span><br></pre></td></tr></table></figure><h2><span id="其他可选的方案"> 其他可选的方案</span></h2><h3><span id="su-exec"> <code>su-exec</code></span></h3><p>As mentioned in <code>INSTALL.md</code>, <a href="https://github.com/ncopa/su-exec" target="_blank" rel="noopener"><code>su-exec</code></a> is a very minimal re-write of <code>gosu</code> in C, making for a much smaller binary, and is available in the <code>main</code> Alpine package repository.</p><h3><span id="chroot"> <code>chroot</code></span></h3><p>With the <code>--userspec</code> flag, <code>chroot</code> can provide similar benefits/behavior:</p><figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> docker run -it --rm ubuntu:trusty chroot --userspec=nobody / ps aux</span></span><br><span class="line">USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND</span><br><span class="line">nobody       1  5.0  0.0   7136   756 ?        Rs+  17:04   0:00 ps aux</span><br></pre></td></tr></table></figure><h3><span id="others"> Others</span></h3><p>I’m not terribly familiar with them, but a few other alternatives I’m aware of include:</p><ul><li><code>chpst</code> (part of <code>runit</code>)</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;gosu官方介绍为一个简单的基于go的工具，集成setuid+setgid+setgroups+exec.&lt;br&gt;
github地址：&lt;a href=&quot;https://github.com/tianon/gosu&quot; target=&quot;_blank&quot; rel=&quot;noopener
      
    
    </summary>
    
      <category term="docker" scheme="yunke.science/categories/docker/"/>
    
    
      <category term="linux" scheme="yunke.science/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>kubelet 功能介绍</title>
    <link href="yunke.science/2018/03/30/kubelet-Synopsis/"/>
    <id>yunke.science/2018/03/30/kubelet-Synopsis/</id>
    <published>2018-03-30T09:11:36.000Z</published>
    <updated>2018-04-09T02:50:14.913Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>kubelet 是运行在每个节点上的主要的“节点代理”，它按照 PodSpec 中的描述工作。<br>kubelet 通过各种机制（主要通过 apiserver ）获取一组 PodSpec 并保证在这些 PodSpec 中描述的容器健康运行。</p></blockquote><p><ul class="markdownIt-TOC"><li><a href="#%E6%A6%82%E8%A6%81">概要</a></li><li><a href="#kubelet-%E4%B8%BB%E8%A6%81%E5%8A%9F%E8%83%BD">kubelet 主要功能</a><ul><li><a href="#pod-%E7%AE%A1%E7%90%86">pod 管理</a></li><li><a href="#%E5%AE%B9%E5%99%A8%E5%81%A5%E5%BA%B7%E6%A3%80%E6%9F%A5">容器健康检查</a></li><li><a href="#%E5%AE%B9%E5%99%A8%E7%9B%91%E6%8E%A7">容器监控</a></li></ul></li></ul></p><h2><span id="概要"> 概要</span></h2><p>kubelet 是运行在每个节点上的主要的“节点代理”，它按照 PodSpec 中的描述工作。PodSpec 是用来描述一个 pod 的 YAML 或者 JSON 对象。kubelet 通过各种机制（主要通过 apiserver ）获取一组 PodSpec 并保证在这些 PodSpec 中描述的容器健康运行。kubelet 不管理不是由 Kubernetes 创建的容器。</p><p>除了来自 apiserver 的 PodSpec ，还有 3 种方式可以将容器清单提供给 kubelet 。</p><p>文件：在命令行指定的一个路径，在这个路径下的文件将被周期性的监视更新，默认监视周期是 20 秒并可以通过参数配置。</p><p>HTTP端点：在命令行指定的一个HTTP端点，该端点每 20 秒被检查一次并且可以通过参数配置检查周期。</p><p>HTTP服务：kubelet 还可以监听 HTTP 服务并响应一个简单的 API 来创建一个新的清单。</p><h2><span id="kubelet-主要功能"> kubelet 主要功能</span></h2><h3><span id="pod-管理"> pod 管理</span></h3><p>在 kubernetes 的设计中，最基本的管理单位是 pod，而不是 container。pod 是 kubernetes 在容器上的一层封装，由一组运行在同一主机的一个或者多个容器组成。如果把容器比喻成传统机器上的一个进程（它可以执行任务，对外提供某种功能），那么 pod 可以类比为传统的主机：它包含了多个容器，为它们提供共享的一些资源。</p><p>之所以费功夫提供这一层封装，主要是因为容器推荐的用法是里面只运行一个进程，而一般情况下某个应用都由多个组件构成的。</p><p>pod 中所有的容器最大的特性也是最大的好处就是共享了很多资源，比如网络空间。pod 下所有容器共享网络和端口空间，也就是它们之间可以通过 localhost 访问和通信，对外的通信方式也是一样的，省去了很多容器通信的麻烦。</p><p>除了网络之外，定义在 pod 里的 volume 也可以 mount 到多个容器里，以实现共享的目的。</p><p>最后，定义在 pod 的资源限制（比如 CPU 和 Memory） 也是所有容器共享的。</p><h3><span id="容器健康检查"> 容器健康检查</span></h3><p>建了容器之后，kubelet 还要查看容器是否正常运行，如果容器运行出错，就要根据设置的重启策略进行处理。检查容器是否健康主要有两种方式：在容器中执行命令和通过 HTTP 访问预定义的 endpoint。</p><h3><span id="容器监控"> 容器监控</span></h3><p>kubelet 还有一个重要的责任，就是监控所在节点的资源使用情况，并定时向 master 报告。知道整个集群所有节点的资源情况，对于 pod 的调度和正常运行至关重要。</p><p>kubelet 使用 cAdvisor 进行资源使用率的监控。cAdvisor 是 google 开源的分析容器资源使用和性能特性的工具，在 kubernetes 项目中被集成到 kubelet 里，无需额外配置。默认情况下，你可以在 http://&lt;host_ip&gt;:4194 地址看到 cAdvisor 的管理界面。</p><p>除了系统使用的 CPU，Memory，存储和网络之外，cAdvisor 还记录了每个容器使用的上述资源情况。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;kubelet 是运行在每个节点上的主要的“节点代理”，它按照 PodSpec 中的描述工作。&lt;br&gt;
kubelet 通过各种机制（主要通过 apiserver ）获取一组 PodSpec 并保证在这些 PodSpec 中描述的容器健康运行。&lt;/
      
    
    </summary>
    
    
      <category term="kubernetes" scheme="yunke.science/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Quickstart for Calico on Kubernetes</title>
    <link href="yunke.science/2018/03/30/Calico4k8s/"/>
    <id>yunke.science/2018/03/30/Calico4k8s/</id>
    <published>2018-03-30T03:06:46.000Z</published>
    <updated>2018-03-30T09:13:07.622Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>This quickstart gets you a single-host Kubernetes cluster with Calico in approximately 15 minutes. You can use this cluster for testing and development.</p></blockquote><p><ul class="markdownIt-TOC"><li><ul><li><a href="#requirements">Requirements</a></li><li><a href="#before-you-begin">Before you begin</a></li><li><a href="#create-a-single-host-kubernetes-cluster">Create a single-host Kubernetes cluster</a></li><li><a href="#next-steps">Next steps</a></li></ul></li></ul></p><p>To deploy a cluster suitable for production, refer to <a href="https://docs.projectcalico.org/v3.0/getting-started/kubernetes/" target="_blank" rel="noopener">Installation</a>.</p><h3><span id="requirements"> Requirements</span></h3><ul><li>AMD64 processor</li><li>2CPU</li><li>2GB RAM</li><li>10GB free disk space</li><li>RedHat Enterprise Linux 7.x+, CentOS 7.x+, Ubuntu 16.04+, or Debian 8.x+</li></ul><h3><span id="before-you-begin"> Before you begin</span></h3><p><a href="https://kubernetes.io/docs/setup/independent/install-kubeadm/" target="_blank" rel="noopener">Follow the Kubernetes instructions to install kubeadm</a>.</p><blockquote><p><strong>Note</strong>:  After installing kubeadm, do not power down or restart the host. Instead, continue directly to the next section to create your cluster.</p></blockquote><h3><span id="create-a-single-host-kubernetes-cluster"> Create a single-host Kubernetes cluster</span></h3><ol><li><p>As a regular user with sudo privileges, open a terminal on the host that<br>you installed kubeadm on.</p></li><li><p>Initialize the master using the following command.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo kubeadm init --pod-network-cidr=192.168.0.0/16</span><br></pre></td></tr></table></figure></li><li><p>Execute the following commands to configure kubectl (also returned by<br><code>kubeadm init</code>).</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p $HOME/.kube</span><br><span class="line">sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br></pre></td></tr></table></figure></li><li><p>Install Calico and a single node etcd with the following command.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f \</span><br><span class="line">https://docs.projectcalico.org/v3.0/getting-started/kubernetes/installation/hosted/kubeadm/1.7/calico.yaml</span><br></pre></td></tr></table></figure><blockquote><p><strong>Note</strong>: You can also<br><a href="https://docs.projectcalico.org/v3.0/getting-started/kubernetes/installation/hosted/kubeadm/1.7/calico.yaml" target="_blank" rel="noopener">view the YAML in a new tab</a>.</p></blockquote><p>You should see the following output.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">configmap &quot;calico-config&quot; created</span><br><span class="line">daemonset &quot;calico-etcd&quot; created</span><br><span class="line">service &quot;calico-etcd&quot; created</span><br><span class="line">daemonset &quot;calico-etcd&quot; created</span><br><span class="line">deployment &quot;calico-kube-controllers&quot; created</span><br><span class="line">clusterrolebinding &quot;calico-cni-plugin&quot; created</span><br><span class="line">clusterrole &quot;calico-cni-plugin&quot; created</span><br><span class="line">serviceaccount &quot;calico-cni-plugin&quot; created</span><br><span class="line">clusterrolebinding &quot;calico-kube-controllers&quot; created</span><br><span class="line">clusterrole &quot;calico-kube-controllers&quot; created</span><br><span class="line">serviceaccount &quot;calico-kube-controllers&quot; created</span><br></pre></td></tr></table></figure></li><li><p>Confirm that all of the pods are running with the following command.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">watch kubectl get pods --all-namespaces</span><br></pre></td></tr></table></figure><p>Wait until each pod has the <code>STATUS</code> of <code>Running</code>.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">NAMESPACE    NAME                                       READY  STATUS   RESTARTS  AGE</span><br><span class="line">kube-system  calico-etcd-x2482                          1/1    Running  0         2m</span><br><span class="line">kube-system  calico-kube-controllers-6ff88bf6d4-tgtzb   1/1    Running  0         2m</span><br><span class="line">kube-system  calico-etcd-24h85                          2/2    Running  0         2m</span><br><span class="line">kube-system  etcd-jbaker-virtualbox                     1/1    Running  0         6m</span><br><span class="line">kube-system  kube-apiserver-jbaker-virtualbox           1/1    Running  0         6m</span><br><span class="line">kube-system  kube-controller-manager-jbaker-virtualbox  1/1    Running  0         6m</span><br><span class="line">kube-system  kube-dns-545bc4bfd4-67qqp                  3/3    Running  0         5m</span><br><span class="line">kube-system  kube-proxy-8fzp2                           1/1    Running  0         5m</span><br><span class="line">kube-system  kube-scheduler-jbaker-virtualbox           1/1    Running  0         5m</span><br></pre></td></tr></table></figure></li><li><p>Press CTRL+C to exit <code>watch</code>.</p></li><li><p>Remove the taints on the master so that you can schedule pods<br>on it.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl taint nodes --all node-role.kubernetes.io/master-</span><br></pre></td></tr></table></figure><p>It should return the following.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">node &quot;&lt;your-hostname&gt;&quot; untainted</span><br></pre></td></tr></table></figure></li><li><p>Confirm that you now have a node in your cluster with the<br>following command.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get nodes -o wide</span><br></pre></td></tr></table></figure><p>It should return something like the following.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">NAME             STATUS  ROLES   AGE  VERSION  EXTERNAL-IP  OS-IMAGE            KERNEL-VERSION     CONTAINER-RUNTIME</span><br><span class="line">&lt;your-hostname&gt;  Ready   master  1h   v1.8.x   &lt;none&gt;       Ubuntu 16.04.3 LTS  4.10.0-28-generic  docker://1.12.6</span><br></pre></td></tr></table></figure></li></ol><p>Congratulations! You now have a single-host Kubernetes cluster</p><h3><span id="next-steps"> Next steps</span></h3><p><strong><a href="https://docs.projectcalico.org/v3.0/getting-started/kubernetes/tutorials/simple-policy" target="_blank" rel="noopener">Secure a simple application using the Kubernetes <code>NetworkPolicy</code> API</a></strong></p><p><strong><a href="https://docs.projectcalico.org/v3.0/getting-started/kubernetes/tutorials/advanced-policy" target="_blank" rel="noopener">Control ingress and egress traffic using the Kubernetes <code>NetworkPolicy</code> API</a></strong></p><p><strong><a href="https://docs.projectcalico.org/v3.0/getting-started/kubernetes/tutorials/stars-policy/" target="_blank" rel="noopener">Create a user interface that shows blocked and allowed connections in real time</a></strong></p><p><strong><a href="https://docs.projectcalico.org/v3.0/usage/calicoctl/install" target="_blank" rel="noopener">Install and configure calicoctl</a></strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;This quickstart gets you a single-host Kubernetes cluster with Calico in approximately 15 minutes. You can use this cluster 
      
    
    </summary>
    
    
      <category term="Kubernetes" scheme="yunke.science/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes HA 1.9 高可用集群kubeadm部署</title>
    <link href="yunke.science/2018/03/28/K8s19-cluster/"/>
    <id>yunke.science/2018/03/28/K8s19-cluster/</id>
    <published>2018-03-28T09:01:13.000Z</published>
    <updated>2018-03-28T09:11:42.378Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Kubeadm是为提供kubeadm init 和 kubeadm join而创建的工具，它是创建Kubernetes集群的最佳实践“快速路径”。<br>Kubeadm执行必要的操作以启动并运行最小的可用群集。 按照设计，它只关心引导，而不关心配置机器。 同样，安装各种不错的插件，如Kubernetes Dashboard，监控解决方案和云特定的插件，都不在范围之内。<br>相反，我们希望在kubeadm的基础上构建更高级别和更多定制的工具，理想情况下，使用kubeadm作为所有部署的基础，可以更轻松地创建一致的集群。</p></blockquote><p><ul class="markdownIt-TOC"><li><a href="#k8s-19-%E7%AE%80%E4%BB%8B">k8s 1.9 简介</a></li><li><a href="#kubernetes-%E6%A0%B8%E5%BF%83%E6%9E%B6%E6%9E%84">Kubernetes 核心架构</a></li><li><a href="#%E9%83%A8%E7%BD%B2%E7%8E%AF%E5%A2%83">部署环境：</a></li><li><a href="#%E5%88%9D%E5%A7%8B%E5%8C%96">初始化</a><ul><li><a href="#%E8%AE%BE%E7%BD%AE%E4%B8%BB%E6%9C%BA%E5%90%8D">设置主机名</a></li><li><a href="#%E5%81%9C%E6%AD%A2%E9%98%B2%E7%81%AB%E5%A2%99">停止防火墙</a></li><li><a href="#%E5%85%B3%E9%97%ADswap">关闭Swap</a></li><li><a href="#selinux">Selinux</a></li><li><a href="#%E9%85%8D%E7%BD%AE-dns">配置 dns</a></li><li><a href="#%E4%BF%AE%E6%94%B9%E5%86%85%E6%A0%B8%E5%8F%82%E6%95%B0">修改内核参数</a></li></ul></li><li><a href="#%E9%85%8D%E7%BD%AEkeepalived">配置keepalived</a></li><li><a href="#etcd-https-%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2">Etcd https 集群部署</a><ul><li><a href="#etcd-%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87">etcd 环境准备</a></li><li><a href="#etcd-https-%E8%AF%81%E4%B9%A6%E5%88%9B%E5%BB%BA">Etcd https 证书创建</a><ul><li><a href="#%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85">软件安装</a></li><li><a href="#%E7%94%9F%E6%88%90etcd%E7%9A%84tls-%E7%A7%98%E9%92%A5%E5%92%8C%E8%AF%81%E4%B9%A6">生成ETCD的TLS 秘钥和证书</a></li></ul></li><li><a href="#%E4%B8%8B%E8%BD%BD%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E8%A3%85%E6%96%87%E4%BB%B6">下载二进制安装文件</a></li><li><a href="#%E5%88%9B%E5%BB%BA-etcd-%E7%9A%84-systemd-unit-%E6%96%87%E4%BB%B6">创建 etcd 的 systemd unit 文件</a></li><li><a href="#%E5%90%AF%E5%8A%A8-etcd-%E6%9C%8D%E5%8A%A1">启动 etcd 服务</a></li><li><a href="#%E9%AA%8C%E8%AF%81%E6%9C%8D%E5%8A%A1">验证服务</a></li></ul></li><li><a href="#k8s-%E5%AE%89%E8%A3%85">k8s 安装</a><ul><li><a href="#%E6%8F%90%E5%8F%96k8s-rpm-%E5%8C%85">提取k8s rpm 包</a></li><li><a href="#%E5%90%AF%E5%8A%A8k8s">启动k8s</a></li><li><a href="#%E4%B8%8B%E8%BD%BD%E9%95%9C%E5%83%8F">下载镜像</a></li></ul></li><li><a href="#kubeadm-init-%E5%88%9D%E5%A7%8B%E5%8C%96">Kubeadm Init 初始化</a></li><li><a href="#%E5%AE%89%E8%A3%85%E7%BD%91%E7%BB%9C%E7%BB%84%E4%BB%B6-podnetwork">安装网络组件 podnetwork</a></li><li><a href="#%E9%83%A8%E7%BD%B2%E5%85%B6%E4%BB%96master-%E8%8A%82%E7%82%B9">部署其他Master 节点</a></li><li><a href="#%E9%83%A8%E7%BD%B2%E6%9C%8D%E5%8A%A1">部署服务</a></li><li><a href="#%E9%AA%8C%E8%AF%81master-apiserver-%E9%AB%98%E5%8F%AF%E7%94%A8">验证master apiserver 高可用</a></li><li><a href="#%E4%BD%BF%E7%94%A8-kube-router-ipvs-%E6%9B%BF%E4%BB%A3-kube-proxy">使用 kube-router IPVS 替代 kube-proxy</a><ul><li><a href="#%E9%AA%8C%E8%AF%81-lvs-%E6%98%AF%E5%90%A6%E7%94%9F%E6%95%88">验证 lvs 是否生效</a></li></ul></li><li><a href="#%E6%B7%BB%E5%8A%A0-workload-%E8%8A%82%E7%82%B9">添加 workload 节点</a></li><li><a href="#kubernetes-dashboard-%E5%AE%89%E8%A3%85">kubernetes dashboard 安装</a><ul><li><a href="#kubernetes-dashboard-%E4%BB%8B%E7%BB%8D">kubernetes dashboard 介绍</a><ul><li><a href="#%E6%9C%80%E5%B0%8F%E6%9D%83%E9%99%90%E5%8E%9F%E5%88%99">最小权限原则</a></li><li><a href="#%E8%AE%A4%E8%AF%81%E6%96%B9%E5%BC%8F">认证方式</a><ul><li><a href="#authorization-header-%E8%AE%A4%E8%AF%81%E6%96%B9%E5%BC%8F%E4%BB%8B%E7%BB%8D">Authorization header 认证方式介绍</a></li></ul></li><li><a href="#kubernetes-dashboard-%E5%AE%89%E8%A3%85%E6%96%B9%E5%BC%8F">kubernetes dashboard 安装方式</a></li></ul></li><li><a href="#kubernetes-dashboard-%E9%83%A8%E7%BD%B2">kubernetes dashboard 部署</a></li></ul></li><li><a href="#%E7%9B%91%E6%8E%A7%E6%8F%92%E4%BB%B6-heapster-%E5%AE%89%E8%A3%85">监控插件 heapster 安装</a><ul><li><a href="#%E5%9C%A8-kubernetes-%E4%B8%AD%E9%83%A8%E7%BD%B2heapster">在 Kubernetes 中部署heapster</a></li><li><a href="#%E7%8B%AC%E7%AB%8B%E9%83%A8%E7%BD%B2-heapster">独立部署 heapster</a></li></ul></li><li><a href="#%E4%BD%BF%E7%94%A8tr%C3%A6fik%E4%BD%9C%E4%B8%BAkubernetes%E9%9B%86%E7%BE%A4%E7%9A%84ingress%E6%8E%A7%E5%88%B6%E5%99%A8">使用Træfik作为Kubernetes集群的Ingress控制器</a><ul><li><a href="#rbac-%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6%E9%85%8D%E7%BD%AE">RBAC 访问控制配置</a></li><li><a href="#daemonset%E9%83%A8%E7%BD%B2tr%C3%A6fik">DaemonSet部署Træfik</a></li><li><a href="#%E5%90%91%E7%BE%A4%E9%9B%86%E6%8F%90%E4%BA%A4-%E4%B8%80%E4%B8%AA-ingress">向群集提交 一个 ingress</a></li><li><a href="#%E6%B7%BB%E5%8A%A0%E8%AE%A4%E8%AF%81">添加认证</a></li></ul></li><li><a href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99">参考资料</a></li></ul></p><h2><span id="k8s-19-简介"> k8s 1.9 简介</span></h2><ul><li>kubernetes1.9版本发布2017年12月15日，每三个月一个迭代， Workloads API成为稳定版本，这消除了很多潜在用户对于该功能稳定性的担忧。还有一个重大更新，就是测试支持了Windows了，这打开了在kubernetes中运行Windows工作负载的大门。</li><li>CoreDNS alpha可以使用标准工具来安装CoreDNS</li><li>kube-proxy的IPVS模式进入beta版，为大型集群提供更好的可扩展性和性能。</li><li>kube-router的网络插件支持，更方便进行路由控制，发布，和安全策略管理</li></ul><h2><span id="kubernetes-核心架构"> Kubernetes 核心架构</span></h2><p>k8s 高可用2个核心 <mark>apiserver master</mark> and <mark>etcd</mark></p><p><mark>apiserver master</mark>：（需高可用）集群核心，集群API接口、集群各个组件通信的中枢；集群安全控制；</p><p><mark>etcd</mark> ：（需高可用）集群的数据中心，用于存放集群的配置以及状态信息，非常重要，如果数据丢失那么集群将无法恢复；因此高可用集群部署首先就是etcd是高可用集群；</p><p>kube-scheduler：调度器 （内部自选举）集群Pod的调度中心；默认kubeadm安装情况下–leader-elect参数已经设置为true，保证master集群中只有一个kube-scheduler处于活跃状态；</p><p>kube-controller-manager： 控制器 （内部自选举）集群状态管理器，当集群状态与期望不同时，kcm会努力让集群恢复期望状态，比如：当一个pod死掉，kcm会努力新建一个pod来恢复对应replicas set期望的状态；默认kubeadm安装情况下–leader-elect参数已经设置为true，保证master集群中只有一个kube-controller-manager处于活跃状态；</p><p>kubelet: agent node注册apiserver</p><p>kube-proxy: 每个node上一个，负责service vip到endpoint pod的流量转发，老版本主要通过设置iptables规则实现，新版1.9基于kube-proxy-lvs 实现</p><p>集群HA方案，我们力求简单，使用keepalive 监听一个vip来实现，（当节点不可以后，会有vip漂移的切换时长，取决于我们设置timeout切换时长，测试会有10s空档期，如果对高可用更高要求 可以用lvs或者nginx做 4层lb负载 更佳完美，我们力求简单够用，可接受10s的api不可用）</p><h2><span id="部署环境"> 部署环境：</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker Server Version: 1.12.6</span><br><span class="line">CentOS Linux  3.10.0-327.el7.x86_64</span><br><span class="line">kubeadm version GitVersion:&quot;v1.9.6&quot;</span><br><span class="line">Kubernetes version v1.9.6</span><br></pre></td></tr></table></figure><table><thead><tr><th>主机名</th><th>IP</th></tr></thead><tbody><tr><td>docker01</td><td>192.168.0.65</td></tr><tr><td>docker02</td><td>192.168.0.67</td></tr><tr><td>docker03</td><td>192.168.0.31</td></tr></tbody></table><h2><span id="初始化"> 初始化</span></h2><h3><span id="设置主机名"> 设置主机名</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hostnamectl  set-hostname docker01</span><br><span class="line">hostnamectl  set-hostname docker02</span><br><span class="line">hostnamectl  set-hostname docker03</span><br></pre></td></tr></table></figure><h3><span id="停止防火墙"> 停止防火墙</span></h3><p>systemctl disable firewalld &amp;&amp; systemctl stop firewalld &amp;&amp; systemctl status firewalld</p><h3><span id="关闭swap"> 关闭Swap</span></h3><blockquote><p>swapoff -a<br>sed  ‘s/.<em>swap.</em>/#&amp;/’ /etc/fstab</p></blockquote><h3><span id="selinux"> Selinux</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[ -f /etc/selinux/config ] &amp;&amp; sed -i &apos;s/^SELINUX=.*/SELINUX=disabled/g&apos; /etc/selinux/config</span><br><span class="line">[ -f /etc/sysconfig/selinux ] &amp;&amp; sed -i &apos;s/^SELINUX=.*/SELINUX=disabled/g&apos; /etc/sysconfig/selinux</span><br><span class="line">[ -x /usr/sbin/setenforce ] &amp;&amp; /usr/sbin/setenforce 0</span><br></pre></td></tr></table></figure><h3><span id="配置-dns"> 配置 dns</span></h3><blockquote><p>echo nameserver 114.114.114.114&gt;&gt;/etc/resolv.conf</p></blockquote><h3><span id="修改内核参数"> 修改内核参数</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt;  /etc/sysctl.d/k8s.conf</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">vm.swappiness=0</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">sysctl -p /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo 1 &gt; /proc/sys/net/bridge/bridge-nf-call-iptables</span><br><span class="line">echo 1 &gt; /proc/sys/net/bridge/bridge-nf-call-ip6tables</span><br></pre></td></tr></table></figure><h2><span id="配置keepalived"> 配置keepalived</span></h2><ul><li>VIP Master 通过控制VIP 来HA高可用</li><li>到目前为止,三个master节点 相互独立运行,互不干扰. kube-apiserver作为核心入口, 可以使用keepalived 实现高可用,</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y keepalived</span><br></pre></td></tr></table></figure><p>配置keepalived.conf</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;/etc/keepalived/keepalived.conf  &lt;&lt;EOL</span><br><span class="line">global_defs &#123;</span><br><span class="line">   router_id LVS_k8s</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_script CheckK8sMaster &#123;</span><br><span class="line">    script &quot;curl -k https://192.168.0.32:6443&quot;</span><br><span class="line">    interval 3</span><br><span class="line">    timeout 9</span><br><span class="line">    fall 2</span><br><span class="line">    rise 2</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state MASTER</span><br><span class="line">    priority 100</span><br><span class="line">    interface em1</span><br><span class="line">    virtual_router_id 61</span><br><span class="line">    advert_int 1</span><br><span class="line">    # 多播源地址，默认为绑定的网卡IP</span><br><span class="line">    # mcast_src_ip 10.129.6.211</span><br><span class="line">    # 非抢占模式</span><br><span class="line">    nopreempt</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass ndikfXSx6uKpgU8D9NV7</span><br><span class="line">    &#125;</span><br><span class="line">    # 单播方式，其他节点的地址</span><br><span class="line">    # unicast_peer &#123;</span><br><span class="line">    #     #注释掉本地IP</span><br><span class="line">    #     #10.129.6.211</span><br><span class="line">    #     10.129.6.212</span><br><span class="line">    #     10.129.6.213</span><br><span class="line">    # &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        192.168.0.32/24</span><br><span class="line">    &#125;</span><br><span class="line">    # track_script &#123;</span><br><span class="line">    #     CheckK8sMaster</span><br><span class="line">    # &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">EOL</span><br></pre></td></tr></table></figure><p>启动</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">systemctl enable keepalived &amp;&amp; systemctl restart keepalived</span><br><span class="line"></span><br><span class="line">错误： Unable to load ipset library - libipset.so.3: cannot open shared object file: No such file or directory</span><br><span class="line">安装软件包： yum install libnl3-devel ipset-devel -y</span><br></pre></td></tr></table></figure><p>配置其他主机，修改state 为BACKUP 和 priority 优先级<br>priority 越大，优先级越高</p><p>在 master 上停止 keepalived.service ，测试 VIP 是否切换到其他主机。</p><h2><span id="etcd-https-集群部署"> Etcd https 集群部署</span></h2><h3><span id="etcd-环境准备"> etcd 环境准备</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#机器名称</span><br><span class="line">docker01：192.168.0.65</span><br><span class="line">docker02：192.168.0.67</span><br><span class="line">docker03：192.168.0.31</span><br><span class="line"></span><br><span class="line">#部署环境变量. 每台主机上都要添加，添加到 /etc/profile</span><br><span class="line">export NODE_NAME=docker01 #当前部署的机器名称(随便定义，只要能区分不同机器即可)</span><br><span class="line">export NODE_IP=192.168.0.65 # 当前部署的机器 IP</span><br><span class="line">export NODE_IPS=&quot;192.168.0.65 192.168.0.67 192.168.0.31&quot; # etcd 集群所有机器 IP</span><br><span class="line"># etcd 集群间通信的IP和端口</span><br><span class="line">export ETCD_NODES=docker01=https://192.168.0.65:2380,docker02=https://192.168.0.67:2380,docker03=https://192.168.0.31:2380</span><br></pre></td></tr></table></figure><h3><span id="etcd-https-证书创建"> Etcd https 证书创建</span></h3><h4><span id="软件安装"> 软件安装</span></h4><ul><li>安装cfssl， CloudFlare 的 PKI 工具集 cfssl 来生成 Certificate Authority (CA) 证书和秘钥文件</li><li>如果不希望将cfssl工具安装到部署主机上，可以在其他的主机上进行该步骤，生成以后将证书拷贝到部署etcd的主机上即可。本教程就是采取这种方法，在一台测试机上执行下面操作。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64</span><br><span class="line">chmod +x cfssl_linux-amd64</span><br><span class="line">mv cfssl_linux-amd64 /usr/local/bin/cfssl</span><br><span class="line"></span><br><span class="line">wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64</span><br><span class="line">chmod +x cfssljson_linux-amd64</span><br><span class="line">mv cfssljson_linux-amd64 /usr/local/bin/cfssljson</span><br><span class="line"></span><br><span class="line">wget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64</span><br><span class="line">chmod +x cfssl-certinfo_linux-amd64</span><br><span class="line">mv cfssl-certinfo_linux-amd64 /usr/local/bin/cfssl-certinfo</span><br></pre></td></tr></table></figure><h4><span id="生成etcd的tls-秘钥和证书"> 生成ETCD的TLS 秘钥和证书</span></h4><ul><li>为了保证通信安全，客户端(如 etcdctl) 与 etcd 集群、etcd 集群之间的通信需要使用 TLS 加密，本节创建 etcd TLS 加密所需的证书和私钥。</li></ul><p>创建 CA 配置文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;  ca-config.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">&quot;signing&quot;: &#123;</span><br><span class="line">&quot;default&quot;: &#123;</span><br><span class="line">  &quot;expiry&quot;: &quot;87600h&quot;</span><br><span class="line">&#125;,</span><br><span class="line">&quot;profiles&quot;: &#123;</span><br><span class="line">  &quot;kubernetes&quot;: &#123;</span><br><span class="line">    &quot;usages&quot;: [</span><br><span class="line">        &quot;signing&quot;,</span><br><span class="line">        &quot;key encipherment&quot;,</span><br><span class="line">        &quot;server auth&quot;,</span><br><span class="line">        &quot;client auth&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;expiry&quot;: &quot;87600h&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p><mark>ca-config.json</mark>：可以定义多个 profiles，分别指定不同的过期时间、使用场景等参数；后续在签名证书时使用某个 profile；<br><mark>signing</mark>：表示该证书可用于签名其它证书；生成的 ca.pem 证书中 CA=TRUE；<br><mark>server auth</mark>：表示 client 可以用该 CA 对 server 提供的证书进行验证；<br><mark>client auth</mark>：表示 server 可以用该 CA 对 client 提供的证书进行验证；</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;  ca-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">&quot;CN&quot;: &quot;kubernetes&quot;,</span><br><span class="line">&quot;key&quot;: &#123;</span><br><span class="line">&quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">&quot;size&quot;: 2048</span><br><span class="line">&#125;,</span><br><span class="line">&quot;names&quot;: [</span><br><span class="line">&#123;</span><br><span class="line">  &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">  &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class="line">  &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class="line">  &quot;O&quot;: &quot;k8s&quot;,</span><br><span class="line">  &quot;OU&quot;: &quot;System&quot;</span><br><span class="line">&#125;</span><br><span class="line">]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><ul><li><p>“CN”：Common Name，kube-apiserver 从证书中提取该字段作为请求的用户名 (User Name)；浏览器使用该字段验证网站是否合法；</p></li><li><p>“O”：Organization，kube-apiserver 从证书中提取该字段作为请求用户所属的组 (Group)；</p></li><li><p><mark>生成 CA 证书和私钥</mark>：<br><strong># cfssl gencert -initca ca-csr.json | cfssljson -bare ca</strong></p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ls ca*  </span><br><span class="line">-rw-r--r-- 1 root root  232 Mar 24 18:31 ca-config.json</span><br><span class="line">-rw-r--r-- 1 root root 1001 Mar 24 18:32 ca.csr</span><br><span class="line">-rw-r--r-- 1 root root  162 Mar 24 18:31 ca-csr.json</span><br><span class="line">-rw------- 1 root root 1675 Mar 24 18:32 ca-key.pem</span><br><span class="line">-rw-r--r-- 1 root root 1359 Mar 24 18:32 ca.pem</span><br></pre></td></tr></table></figure><ul><li><mark>创建 etcd 证书签名请求：</mark></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; etcd-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;etcd&quot;,</span><br><span class="line">  &quot;hosts&quot;: [</span><br><span class="line">    &quot;127.0.0.1&quot;,</span><br><span class="line">    &quot;192.168.0.65&quot;,</span><br><span class="line">    &quot;192.168.0.67&quot;,</span><br><span class="line">    &quot;192.168.0.31&quot;,</span><br><span class="line">    &quot;192.168.0.32&quot;</span><br><span class="line">  ],</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;k8s&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;System&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><ul><li>hosts 字段指定授权使用该证书的 etcd 节点 IP；</li><li>每个节点IP 都要在里面 或者 每个机器申请一个对应IP的证书</li></ul><p>生成 etcd 证书和私钥：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">cfssl gencert -ca=ca.pem \</span><br><span class="line">  -ca-key=ca-key.pem \</span><br><span class="line">  -config=ca-config.json \</span><br><span class="line">  -profile=kubernetes etcd-csr.json | cfssljson -bare etcd</span><br><span class="line"></span><br><span class="line"># ls -lt etcd*</span><br><span class="line">-rw-r--r-- 1 root root 1070 Mar 24 18:38 etcd.csr</span><br><span class="line">-rw-r--r-- 1 root root  316 Mar 24 18:37 etcd-csr.json</span><br><span class="line">-rw------- 1 root root 1675 Mar 24 18:38 etcd-key.pem</span><br><span class="line">-rw-r--r-- 1 root root 1444 Mar 24 18:38 etcd.pem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">mkdir -p /etc/etcd/ssl</span><br><span class="line">cp etcd.pem etcd-key.pem  ca.pem /etc/etcd/ssl/</span><br><span class="line"></span><br><span class="line">打包并传输到其他主机上</span><br><span class="line">tar zcvf  etcd_ssl.tar.gz /etc/etcd/ssl/</span><br><span class="line"></span><br><span class="line">#其他主机上解压</span><br><span class="line">rm -rf /etc/etcd/ssl/*</span><br><span class="line">tar xf etcd_ssl.tar.gz -C /</span><br><span class="line">ls /etc/etcd/ssl/</span><br></pre></td></tr></table></figure><h3><span id="下载二进制安装文件"> 下载二进制安装文件</span></h3><p>到 <a href="https://github.com/coreos/etcd/releases" target="_blank" rel="noopener">https://github.com/coreos/etcd/releases</a> 页面下载最新版本的二进制文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget https://github.com/coreos/etcd/releases/download/v3.3.2/etcd-v3.3.2-linux-amd64.tar.gz</span><br><span class="line">tar xf etcd-v3.3.2-linux-amd64.tar.gz</span><br><span class="line">mv etcd-v3.3.2-linux-amd64/etcd* /usr/local/bin/</span><br></pre></td></tr></table></figure><h3><span id="创建-etcd-的-systemd-unit-文件"> 创建 etcd 的 systemd unit 文件</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /var/lib/etcd</span><br><span class="line"></span><br><span class="line">创建文件之前，一定要先设置环境变量。并加载环境变量</span><br><span class="line"></span><br><span class="line">cat &gt; etcd.service &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Etcd Server</span><br><span class="line">After=network.target</span><br><span class="line">After=network-online.target</span><br><span class="line">Wants=network-online.target</span><br><span class="line">Documentation=https://github.com/coreos</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">WorkingDirectory=/var/lib/etcd/</span><br><span class="line">ExecStart=/usr/local/bin/etcd \\</span><br><span class="line">  --name=$&#123;NODE_NAME&#125; \\</span><br><span class="line">  --cert-file=/etc/etcd/ssl/etcd.pem \\</span><br><span class="line">  --key-file=/etc/etcd/ssl/etcd-key.pem \\</span><br><span class="line">  --peer-cert-file=/etc/etcd/ssl/etcd.pem \\</span><br><span class="line">  --peer-key-file=/etc/etcd/ssl/etcd-key.pem \\</span><br><span class="line">  --trusted-ca-file=/etc/etcd/ssl/ca.pem \\</span><br><span class="line">  --peer-trusted-ca-file=/etc/etcd/ssl/ca.pem \\</span><br><span class="line">  --initial-advertise-peer-urls=https://$&#123;NODE_IP&#125;:2380 \\</span><br><span class="line">  --listen-peer-urls=https://$&#123;NODE_IP&#125;:2380 \\</span><br><span class="line">  --listen-client-urls=https://$&#123;NODE_IP&#125;:2379,http://127.0.0.1:2379 \\</span><br><span class="line">  --advertise-client-urls=https://$&#123;NODE_IP&#125;:2379 \\</span><br><span class="line">  --initial-cluster-token=etcd-cluster-0 \\</span><br><span class="line">  --initial-cluster=$&#123;ETCD_NODES&#125; \\</span><br><span class="line">  --initial-cluster-state=new \\</span><br><span class="line">  --data-dir=/var/lib/etcd</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">mv etcd.service /etc/systemd/system/</span><br></pre></td></tr></table></figure><ul><li>指定 etcd 的工作目录和数据目录为 /var/lib/etcd，需在启动服务前创建这个目录；</li><li>为了保证通信安全，需要指定 etcd 的公私钥(cert-file和key-file)、Peers 通信的公私钥和 CA 证书(peer-cert-file、peer-key-file、peer-trusted-ca-file)、客户端的CA证书（trusted-ca-file）；</li><li>–initial-cluster-state 值为 new 时，–name 的参数值必须位于 –initial-cluster 列表中；</li></ul><h3><span id="启动-etcd-服务"> 启动 etcd 服务</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable etcd</span><br><span class="line">systemctl start etcd</span><br><span class="line">systemctl status etcd</span><br></pre></td></tr></table></figure><h3><span id="验证服务"> 验证服务</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">etcdctl \</span><br><span class="line">  --endpoints=https://$&#123;NODE_IP&#125;:2379  \</span><br><span class="line">  --ca-file=/etc/etcd/ssl/ca.pem \</span><br><span class="line">  --cert-file=/etc/etcd/ssl/etcd.pem \</span><br><span class="line">  --key-file=/etc/etcd/ssl/etcd-key.pem \</span><br><span class="line">  cluster-health</span><br></pre></td></tr></table></figure><p>结果验证</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">member 5610ea0b10a20992 is healthy: got healthy result from https://192.168.0.67:2379</span><br><span class="line">member 6f78cb98381e75db is healthy: got healthy result from https://192.168.0.65:2379</span><br><span class="line">member cef55d543e12e2d1 is healthy: got healthy result from https://192.168.0.31:2379</span><br><span class="line">cluster is healthy</span><br></pre></td></tr></table></figure><p>如果失败，需要删除目录，重新配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop etcd</span><br><span class="line">rm -Rf /var/lib/etcd</span><br><span class="line">rm -Rf /var/lib/etcd-cluster</span><br><span class="line">mkdir -p /var/lib/etcd</span><br><span class="line">systemctl start etcd</span><br></pre></td></tr></table></figure><h2><span id="k8s-安装"> k8s 安装</span></h2><h3><span id="提取k8s-rpm-包"> 提取k8s rpm 包</span></h3><ul><li>离线导入下rpm 仓库</li><li>安装官方YUM 仓库</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=http://yum.kubernetes.io/repos/kubernetes-el7-x86_64</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">repo_gpgcheck=0</span><br><span class="line">gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg</span><br><span class="line">       https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">离线下载rpm包</span><br><span class="line">mkdir k8srpm &amp;&amp; cd k8srpm</span><br><span class="line">yum install -y yum-utils</span><br><span class="line">yumdownloader kubelet kubeadm kubectl kubernetes-cni</span><br><span class="line"></span><br><span class="line"># du -sh *</span><br><span class="line">8.9M    c9a30a9b3cd4f8b83a3ffcbfe5a23b32c0c78ec90a8e67505ba4ae31ed1d7a69-kubectl-1.9.6-0.x86_64.rpm</span><br><span class="line">17M     f56f3294d633ecfa7f2aac506f7267c00547d4c529b134bc4698a563402897c3-kubeadm-1.9.6-0.x86_64.rpm</span><br><span class="line">8.6M    fe33057ffe95bfae65e2f269e1b05e99308853176e24a4d027bc082b471a07c0-kubernetes-cni-0.6.0-0.x86_64.rpm</span><br><span class="line">17M     fff4e7133c41ce6aaca95adb598f47967d180c4c5e8e6c67d8bfe58345bfde27-kubelet-1.9.6-0.x86_64.rpm</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">打包发送到三台主机，yum离线安装</span><br><span class="line">yum install  k8srpm/*.rpm -y</span><br></pre></td></tr></table></figure><h3><span id="启动k8s"> 启动k8s</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">修改KUBELET_CGROUP_ARGS=--cgroup-driver 与docker Cgroup Driver 相同</span><br><span class="line">cat /etc/systemd/system/kubelet.service.d/10-kubeadm.conf | grep cgroup-driver=</span><br><span class="line">docker info | grep &apos;Cgroup Driver&apos;</span><br><span class="line">比较以上两个的值。修改 /etc/systemd/system/kubelet.service.d/10-kubeadm.conf</span><br><span class="line">#Environment=&quot;KUBELET_CGROUP_ARGS=--cgroup-driver=systemd&quot;</span><br><span class="line">Environment=&quot;KUBELET_CGROUP_ARGS=--cgroup-driver=cgroupfs&quot;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable kubelet</span><br></pre></td></tr></table></figure><h3><span id="下载镜像"> 下载镜像</span></h3><blockquote><p>在其他主机上下载gcr.io镜像，上传到私有镜像仓库。<br>以后就可以通过拉取私有镜像仓库中的镜像，使用tag 重命名即可。</p></blockquote><p>以下是 本文使用到的镜像</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">docker pull gcr.io/google_containers/kube-apiserver-amd64:v1.9.6</span><br><span class="line">docker pull gcr.io/google_containers/kube-controller-manager-amd64:v1.9.6</span><br><span class="line">docker pull gcr.io/google_containers/kube-scheduler-amd64:v1.9.6</span><br><span class="line">docker pull gcr.io/google_containers/kube-proxy-amd64:v1.9.6</span><br><span class="line">docker pull gcr.io/google_containers/pause-amd64:3.0</span><br><span class="line">docker pull coredns/coredns:1.0.1</span><br><span class="line">docker pull cloudnativelabs/kube-router:latest</span><br><span class="line">docker pull cloudnativelabs/whats-my-ip:latest</span><br><span class="line">docker pull busybox:latest</span><br><span class="line">k8s.gcr.io/kubernetes-dashboard-amd64:v1.8.3</span><br><span class="line">k8s.gcr.io/heapster-amd64:v1.4.2</span><br><span class="line">traefik:v1.5.4-alpine</span><br></pre></td></tr></table></figure><h2><span id="kubeadm-init-初始化"> Kubeadm Init 初始化</span></h2><blockquote><p>我们使用config 模板方式来初始化集群，便于我们指定etcd 集群<br>private.domain 使我们的 测试镜像仓库 可以改成自己或者手动导入每个机器镜像</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt; config.yaml </span><br><span class="line">apiVersion: kubeadm.k8s.io/v1alpha1</span><br><span class="line">kind: MasterConfiguration</span><br><span class="line">etcd:</span><br><span class="line">  endpoints:</span><br><span class="line">  - https://192.168.0.31:2379</span><br><span class="line">  - https://192.168.0.65:2379</span><br><span class="line">  - https://192.168.0.67:2379</span><br><span class="line">  caFile: /etc/etcd/ssl/ca.pem </span><br><span class="line">  certFile: /etc/etcd/ssl/etcd.pem </span><br><span class="line">  keyFile: /etc/etcd/ssl/etcd-key.pem</span><br><span class="line">  dataDir: /var/lib/etcd</span><br><span class="line">networking:</span><br><span class="line">  podSubnet: 10.42.0.0/16</span><br><span class="line">kubernetesVersion: 1.9.6</span><br><span class="line">api:</span><br><span class="line">  advertiseAddress: &quot;192.168.0.32&quot;</span><br><span class="line">token: &quot;b99a00.a144ef80536d4344&quot;</span><br><span class="line">tokenTTL: &quot;0s&quot;</span><br><span class="line">apiServerCertSANs:</span><br><span class="line">- docker01</span><br><span class="line">- docker02</span><br><span class="line">- docker03</span><br><span class="line">- 192.168.0.31</span><br><span class="line">- 192.168.0.32</span><br><span class="line">- 192.168.0.65</span><br><span class="line">- 192.168.0.67</span><br><span class="line">featureGates:</span><br><span class="line">  CoreDNS: true</span><br><span class="line"># imageRepository: &quot;devhub.beisencorp.com/google_containers&quot;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>初始化集群</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm init --config config.yaml</span><br></pre></td></tr></table></figure><p>执行结果（翻译后的操作）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">说明Kubernetes版本，启用认证[Node RBAC]，</span><br><span class="line">验证docker服务是否开机启动，启动kubelet服务。</span><br><span class="line">生成ca证书和密钥。 </span><br><span class="line">生成的apiserver证书和密钥。apiserver服务证书签署DNS名称。</span><br><span class="line">生成了apiserver-kubelet-client证书和密钥。</span><br><span class="line">生成sa密钥和公钥。</span><br><span class="line">生成的前置代理 ca 证书和密钥。</span><br><span class="line">生成了前端代理 client 证书和密钥。</span><br><span class="line">生成配置文件：&quot;admin.conf&quot;，&quot;kubelet.conf&quot;，&quot;controller-manager.conf&quot;，&quot;scheduler.conf&quot;</span><br><span class="line">生成 组件 kube-apiserver、kube-controller-manager、kube-scheduler三个组建 yaml文件，在/etc/kubernetes/manifests/。</span><br><span class="line">kubelet 启动以上三个组件，组件启动成功。(三个image必须可以下载或者已经下载成功)</span><br><span class="line">在“kube-system”名称空间中存储ConfigMap“kubeadm-config”中使用的配置。</span><br><span class="line">将标记节点docker01作为master，添加标签和taint点。为mater docker01 添加标签node-role.kubernetes.io/master=&quot;&quot;。</span><br><span class="line">输出token。</span><br><span class="line">配置的RBAC规则，允许节点引导token在节点上发布CSRs以获得长期证书凭证。允许csrapprover控制器自动地从一个节点引导令牌中批准csr。允许集群中所有节点客户端证书的证书循环。</span><br><span class="line">在“kube-public”名称空间中创建“cluster-info”ConfigMap。</span><br><span class="line">应用 CoreDNS 和 kube-proxy。</span><br><span class="line">Kubernetes master 初始化完成。</span><br><span class="line"></span><br><span class="line">以下配置集群，方便使用 kubectl 部署操作。</span><br><span class="line">  mkdir -p $HOME/.kube</span><br><span class="line">  sudo cp -fi /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">现在可以通过在每个节点上运行以下操作来连接任意数量的计算机。</span><br><span class="line">as root:</span><br><span class="line"></span><br><span class="line">  kubeadm join --token b99a00.a144ef80536d4344 192.168.0.32:6443 --discovery-token-ca-cert-hash sha256:5a754d4f646da0519301a482534db6147debfbf718202e0d85155da933e46a21</span><br></pre></td></tr></table></figure><p>按照上面执行以下内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p $HOME/.kube</span><br><span class="line">sudo cp -fi /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br></pre></td></tr></table></figure><p>获取状态信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[root@docker01 ~]# kubectl get node</span><br><span class="line">NAME       STATUS     ROLES     AGE       VERSION</span><br><span class="line">docker01   NotReady   master    12h       v1.9.6</span><br><span class="line">[root@docker01 ~]# kubectl get cs  </span><br><span class="line">NAME                 STATUS    MESSAGE             ERROR</span><br><span class="line">controller-manager   Healthy   ok                  </span><br><span class="line">scheduler            Healthy   ok                  </span><br><span class="line">etcd-1               Healthy   &#123;&quot;health&quot;:&quot;true&quot;&#125;   </span><br><span class="line">etcd-0               Healthy   &#123;&quot;health&quot;:&quot;true&quot;&#125;   </span><br><span class="line">etcd-2               Healthy   &#123;&quot;health&quot;:&quot;true&quot;&#125;  </span><br><span class="line">[root@docker01 ~]# kubectl get pod --all-namespaces -o wide</span><br><span class="line">NAMESPACE     NAME                               READY     STATUS    RESTARTS   AGE       IP             NODE</span><br><span class="line">kube-system   coredns-65dcdb4cf-x9qdm            0/1       Pending   0          2m        &lt;none&gt;         &lt;none&gt;</span><br><span class="line">kube-system   kube-apiserver-docker01            1/1       Running   0          1m        192.168.0.65   docker01</span><br><span class="line">kube-system   kube-controller-manager-docker01   1/1       Running   0          1m        192.168.0.65   docker01</span><br><span class="line">kube-system   kube-proxy-d4frm                   1/1       Running   0          2m        192.168.0.65   docker01</span><br><span class="line">kube-system   kube-scheduler-docker01            1/1       Running   0          1m        192.168.0.65   docker01</span><br><span class="line"></span><br><span class="line">由于未安装网络模块，coredns 处于 Pending 状态，这是正常的。</span><br></pre></td></tr></table></figure><p>集群初始化如果遇到问题，可以使用下面的命令进行清理：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm reset</span><br></pre></td></tr></table></figure><h2><span id="安装网络组件-podnetwork"> 安装网络组件 podnetwork</span></h2><blockquote><p><a href="https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/#pod-network" target="_blank" rel="noopener">https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/#pod-network</a><br>安装网络插件以后，docker01 status变为Ready。coredns STATUS 变为 Running</p></blockquote><ul><li>kube-router提供pod网络和网络策略<br>KUBECONFIG=/etc/kubernetes/admin.conf kubectl apply -f <a href="https://raw.githubusercontent.com/cloudnativelabs/kube-router/master/daemonset/kubeadm-kuberouter.yaml" target="_blank" rel="noopener">https://raw.githubusercontent.com/cloudnativelabs/kube-router/master/daemonset/kubeadm-kuberouter.yaml</a></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">- 如果要使用 lvs 替代Iptables，执行以下操作。kube-router提供service prox,pod网络和网络策略    </span><br><span class="line">KUBECONFIG=/etc/kubernetes/admin.conf kubectl apply -f https://raw.githubusercontent.com/cloudnativelabs/kube-router/master/daemonset/kubeadm-kuberouter-all-features.yaml</span><br><span class="line">&gt; 现在，因为kube-router也提供服务代理。 运行以下命令删除kube-proxy并清除它可能完成的任何iptables配置。</span><br><span class="line"></span><br><span class="line">KUBECONFIG=/etc/kubernetes/admin.conf kubectl -n kube-system delete ds kube-proxy  </span><br><span class="line">docker run --privileged --net=host gcr.io/google_containers/kube-proxy-amd64:v1.7.3 kube-proxy --cleanup-iptables</span><br></pre></td></tr></table></figure><p>再次查看状态</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># kubectl get pod --all-namespaces -o wide</span><br><span class="line">NAMESPACE     NAME                               READY     STATUS    RESTARTS   AGE       IP             NODE</span><br><span class="line">kube-system   coredns-65dcdb4cf-x9qdm            1/1       Running   0          9m        10.42.0.2      docker01</span><br><span class="line">kube-system   kube-apiserver-docker01            1/1       Running   0          8m        192.168.0.65   docker01</span><br><span class="line">kube-system   kube-controller-manager-docker01   1/1       Running   0          8m        192.168.0.65   docker01</span><br><span class="line">kube-system   kube-proxy-d4frm                   1/1       Running   0          9m        192.168.0.65   docker01</span><br><span class="line">kube-system   kube-router-ck8vt                  1/1       Running   0          3m        192.168.0.65   docker01</span><br><span class="line">kube-system   kube-scheduler-docker01            1/1       Running   0          8m        192.168.0.65   docker01</span><br></pre></td></tr></table></figure><h2><span id="部署其他master-节点"> 部署其他Master 节点</span></h2><p>拷贝 pki证书到其他主机<br>tar zcvf pki.tar.gz /etc/kubernetes/pki/<br>打包pki.tar.gz传输到其他主机，解压 tar xf pki.tar.gz -C /</p><p>拷贝初始化配置config.yaml<br>修改 /etc/systemd/system/kubelet.service.d/10-kubeadm.conf<br>拉取 <a href="http://gcr.io" target="_blank" rel="noopener">gcr.io</a> 镜像</p><p>执行操作：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm init --config config.yaml</span><br></pre></td></tr></table></figure><p>查看所有服务的状态：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># kubectl get pod --all-namespaces -o wide</span><br><span class="line">NAMESPACE     NAME                               READY     STATUS    RESTARTS   AGE       IP             NODE</span><br><span class="line">kube-system   coredns-65dcdb4cf-5fwqh            1/1       Running   0          4m        10.42.1.2      docker03</span><br><span class="line">kube-system   kube-apiserver-docker01            1/1       Running   0          3m        192.168.0.65   docker01</span><br><span class="line">kube-system   kube-apiserver-docker02            1/1       Running   0          3m        192.168.0.67   docker02</span><br><span class="line">kube-system   kube-apiserver-docker03            1/1       Running   0          3m        192.168.0.31   docker03</span><br><span class="line">kube-system   kube-controller-manager-docker01   1/1       Running   0          3m        192.168.0.65   docker01</span><br><span class="line">kube-system   kube-controller-manager-docker02   1/1       Running   0          3m        192.168.0.67   docker02</span><br><span class="line">kube-system   kube-controller-manager-docker03   1/1       Running   0          3m        192.168.0.31   docker03</span><br><span class="line">kube-system   kube-proxy-4gwpv                   1/1       Running   0          3m        192.168.0.67   docker02</span><br><span class="line">kube-system   kube-proxy-4sjd6                   1/1       Running   0          4m        192.168.0.31   docker03</span><br><span class="line">kube-system   kube-proxy-rhf4p                   1/1       Running   0          4m        192.168.0.65   docker01</span><br><span class="line">kube-system   kube-router-8wk4r                  1/1       Running   0          1m        192.168.0.31   docker03</span><br><span class="line">kube-system   kube-router-qt6hk                  1/1       Running   0          1m        192.168.0.65   docker01</span><br><span class="line">kube-system   kube-router-r65f9                  1/1       Running   0          1m        192.168.0.67   docker02</span><br><span class="line">kube-system   kube-scheduler-docker01            1/1       Running   0          3m        192.168.0.65   docker01</span><br><span class="line">kube-system   kube-scheduler-docker02            1/1       Running   0          3m        192.168.0.67   docker02</span><br><span class="line">kube-system   kube-scheduler-docker03            1/1       Running   0          3m        192.168.0.31   docker03</span><br></pre></td></tr></table></figure><h2><span id="部署服务"> 部署服务</span></h2><p>默认情况下，为了保证master的安全，master是不会被调度到app的。你可以取消这个限制</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># kubectl taint nodes --all node-role.kubernetes.io/master-</span><br><span class="line">node &quot;docker01&quot; untainted</span><br><span class="line">node &quot;docker02&quot; untainted</span><br><span class="line">node &quot;docker03&quot; untainted</span><br></pre></td></tr></table></figure><p>部署三个副本</p><blockquote><p>cloudnativelabs/whats-my-ip 是一个每次请求，返回当前主机的主机名和IP的服务</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl run myip --image=cloudnativelabs/whats-my-ip --replicas=3 --port=8080</span><br></pre></td></tr></table></figure><p>创建一个服务，类型为NodePort</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl expose deployment myip --port=8080 --target-port=8080 --type=NodePort</span><br></pre></td></tr></table></figure><p>查看服务状态</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@docker01 k8srpm]# kubectl get pod -o wide</span><br><span class="line">NAME                    READY     STATUS    RESTARTS   AGE       IP          NODE</span><br><span class="line">myip-859c596bbf-228z2   1/1       Running   0          2m        10.42.1.3   docker03</span><br><span class="line">myip-859c596bbf-4jdvg   1/1       Running   0          2m        10.42.0.3   docker01</span><br><span class="line">myip-859c596bbf-vnt82   1/1       Running   0          2m        10.42.2.2   docker02</span><br><span class="line">[root@docker01 k8srpm]# kubectl get svc -o wide</span><br><span class="line">NAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE       SELECTOR</span><br><span class="line">kubernetes   ClusterIP   10.96.0.1      &lt;none&gt;        443/TCP          15m       &lt;none&gt;</span><br><span class="line">myip         NodePort    10.111.69.75   &lt;none&gt;        8080:31526/TCP   1m        run=myip</span><br></pre></td></tr></table></figure><p>请求服务：</p><blockquote><p>可以看到默认使用的是round-robin算法</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 请求 service:port</span><br><span class="line">[root@docker01 ~]# curl 10.111.69.75:8080</span><br><span class="line">HOSTNAME:myip-859c596bbf-vnt82 IP:10.42.2.2</span><br><span class="line">[root@docker01 ~]# curl 10.111.69.75:8080</span><br><span class="line">HOSTNAME:myip-859c596bbf-4jdvg IP:10.42.0.3</span><br><span class="line">[root@docker01 ~]# curl 10.111.69.75:8080</span><br><span class="line">HOSTNAME:myip-859c596bbf-228z2 IP:10.42.1.3</span><br><span class="line"></span><br><span class="line"># 请求 nodeIP:NodePort</span><br><span class="line">[root@docker01 ~]# curl 192.168.0.65:31526</span><br><span class="line">HOSTNAME:myip-859c596bbf-vnt82 IP:10.42.2.2</span><br><span class="line">[root@docker01 ~]# curl 192.168.0.67:31526</span><br><span class="line">HOSTNAME:myip-859c596bbf-vnt82 IP:10.42.2.2</span><br><span class="line">[root@docker01 ~]# curl 192.168.0.31:31526</span><br><span class="line">HOSTNAME:myip-859c596bbf-vnt82 IP:10.42.2.2</span><br></pre></td></tr></table></figure><h2><span id="验证master-apiserver-高可用"> 验证master apiserver 高可用</span></h2><p>停止 docker01 主机 上的 keepalived 服务，<br>观察当Master01主节点 keepalived 关闭后，备节点VIP状态  BACKUP  切换到 MASTER<br>验证 apiserver 的高可用。</p><p>停止 docker01 主机，验证高可用.</p><h2><span id="使用-kube-router-ipvs-替代-kube-proxy"> 使用 kube-router IPVS 替代 kube-proxy</span></h2><p>删除当前的 kuberouter<br>kubectl delete -f <a href="https://raw.githubusercontent.com/cloudnativelabs/kube-router/master/daemonset/kubeadm-kuberouter.yaml" target="_blank" rel="noopener">https://raw.githubusercontent.com/cloudnativelabs/kube-router/master/daemonset/kubeadm-kuberouter.yaml</a></p><ul><li>如果要使用 lvs 替代Iptables，执行以下操作。kube-router提供service prox,pod网络和网络策略<br>KUBECONFIG=/etc/kubernetes/admin.conf kubectl apply -f <a href="https://raw.githubusercontent.com/cloudnativelabs/kube-router/master/daemonset/kubeadm-kuberouter-all-features.yaml" target="_blank" rel="noopener">https://raw.githubusercontent.com/cloudnativelabs/kube-router/master/daemonset/kubeadm-kuberouter-all-features.yaml</a></li></ul><blockquote><p>现在，因为kube-router也提供服务代理。 运行以下命令删除kube-proxy并清除它可能完成的任何iptables配置。</p></blockquote><p>KUBECONFIG=/etc/kubernetes/admin.conf kubectl -n kube-system delete ds kube-proxy<br>docker run --privileged --net=host <a href="http://gcr.io/google_containers/kube-proxy-amd64:v1.9.6" target="_blank" rel="noopener">gcr.io/google_containers/kube-proxy-amd64:v1.9.6</a> kube-proxy --cleanup</p><h3><span id="验证-lvs-是否生效"> 验证 lvs 是否生效</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">[root@docker03 k8srpm]# kubectl get svc</span><br><span class="line">NAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">kubernetes   ClusterIP   10.96.0.1      &lt;none&gt;        443/TCP          33m</span><br><span class="line">myip         NodePort    10.111.69.75   &lt;none&gt;        8080:31526/TCP   19m</span><br><span class="line">[root@docker03 k8srpm]# ipvsadm        </span><br><span class="line">IP Virtual Server version 1.2.1 (size=4096)</span><br><span class="line">Prot LocalAddress:Port Scheduler Flags</span><br><span class="line">  -&gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn</span><br><span class="line">TCP  docker03:31526 rr</span><br><span class="line">  -&gt; 10.42.0.3:webcache           Masq    1      0          0         </span><br><span class="line">  -&gt; 10.42.1.3:webcache           Masq    1      0          0         </span><br><span class="line">  -&gt; 10.42.2.2:webcache           Masq    1      0          0         </span><br><span class="line">TCP  10.96.0.1:https rr persistent 10800</span><br><span class="line">  -&gt; 192.168.0.32:sun-sr-https    Masq    1      0          0         </span><br><span class="line">TCP  10.96.0.10:domain rr</span><br><span class="line">  -&gt; 10.42.1.2:domain             Masq    1      0          0         </span><br><span class="line">TCP  10.111.69.75:webcache rr</span><br><span class="line">  -&gt; 10.42.0.3:webcache           Masq    1      0          0         </span><br><span class="line">  -&gt; 10.42.1.3:webcache           Masq    1      0          0         </span><br><span class="line">  -&gt; 10.42.2.2:webcache           Masq    1      0          0         </span><br><span class="line">UDP  10.96.0.10:domain rr</span><br><span class="line">  -&gt; 10.42.1.2:domain             Masq    1      0          0</span><br></pre></td></tr></table></figure><h2><span id="添加-workload-节点"> 添加 workload 节点</span></h2><p>以上配置均为 master节点，下面添加  workload 节点<br>执行初始化操作<br>kubeadm join --token <token> <master-ip>:<master-port> --discovery-token-ca-cert-hash sha256:<hash><br>语句即为master节点 初始化操作的最后一步：<br>kubeadm join --token b99a00.a144ef80536d4344 192.168.0.32:6443 --discovery-token-ca-cert-hash sha256:5a754d4f646da0519301a482534db6147debfbf718202e0d85155da933e46a21</hash></master-port></master-ip></token></p><h2><span id="kubernetes-dashboard-安装"> kubernetes dashboard 安装</span></h2><blockquote><p>一旦Dashboard安装并可访问，我们就可以专注于为用户配置对群集资源的访问控制。 从版本1.7仪表板不再具有默认授予的完全管理权限。 所有权限都被撤销，只有授予的最小权限才能使Dashboard正常工作。<br>重要提示：本说明仅针对使用Dashboard 1.7及以上版本的用户。 如果Dashboard只能由可信任的人员访问，所有人都可以使用完全管理权限授予管理员权限 。 请注意，其他应用程序不应直接访问仪表板，因为它可能导致特权升级。 确保集群内流量仅限于名称空间或仅撤销对集群内其他应用程序的Dashboard访问。</p></blockquote><h3><span id="kubernetes-dashboard-介绍"> kubernetes dashboard 介绍</span></h3><h4><span id="最小权限原则"> 最小权限原则</span></h4><p><a href="https://github.com/kubernetes/dashboard/wiki/Access-control#default-dashboard-privileges" target="_blank" rel="noopener">https://github.com/kubernetes/dashboard/wiki/Access-control#default-dashboard-privileges</a><br>V1.8<br>在创建kubernetes-dashboard-key-holder秘密所需的kube-system名称空间中创建秘密权限。<br>get ， update和delete kube-system名称空间中名为kubernetes-dashboard-key-holder和kubernetes-dashboard-certs秘密的权限。<br>get和update kube-system名称空间中名为kubernetes-dashboard-settings配置映射的权限。<br>proxy权限，以允许从heapster获取指标所需的kube-system名称空间中的heapster服务。</p><h4><span id="认证方式"> 认证方式</span></h4><p><a href="https://github.com/kubernetes/dashboard/wiki/Access-control#authentication" target="_blank" rel="noopener">https://github.com/kubernetes/dashboard/wiki/Access-control#authentication</a><br>从版本1.7开始，仪表板支持基于以下用户的身份验证：<br>Authorization: Bearer <token>每个请求传递给仪表板的 Authorization: Bearer <token>标头。 从版本1.6开始支持。 具有最高优先级。 如果存在，登录视图将不会显示。<br>可以在仪表板登录视图上使用的无记名令牌 。<br>可在仪表板登录视图上使用的用户名/密码 。<br>可在仪表板登录视图中使用的Kubeconfig文件。</token></token></p><p>下面的认证，我们采用 Authorization: Bearer <token>  配合 http 方式。</token></p><h5><span id="authorization-header-认证方式介绍"> Authorization header 认证方式介绍</span></h5><p><a href="https://github.com/kubernetes/dashboard/wiki/Access-control#authorization-header" target="_blank" rel="noopener">https://github.com/kubernetes/dashboard/wiki/Access-control#authorization-header</a><br><a href="https://kubernetes.io/docs/admin/authentication/#service-account-tokens" target="_blank" rel="noopener">https://kubernetes.io/docs/admin/authentication/#service-account-tokens</a><br>使用Authorization header是使Dashboard在通过HTTP访问时充当用户的唯一方式。 请注意，由于普通HTTP流量易受MITM攻击，因此存在一些风险。<br>要使仪表板使用Authorization header，只需将每个请求中的  Authorization: Bearer <token>  传递给仪表板。 这可以通过在仪表板前配置反向代理来实现。 代理将负责身份提供者身份验证，并将请求头中生成的令牌传递给仪表板。<br>反向代理 配置 proxy_set_header Authorization &quot;Bearer <token>&quot;;</token></token></p><h4><span id="kubernetes-dashboard-安装方式"> kubernetes dashboard 安装方式</span></h4><p><a href="https://github.com/kubernetes/dashboard/wiki/Installation" target="_blank" rel="noopener">https://github.com/kubernetes/dashboard/wiki/Installation</a><br>两种安装方式：<a href="https://github.com/kubernetes/dashboard/wiki/Installation#recommended-setup" target="_blank" rel="noopener">使用有效证书建立安全的HTTPS连接方式</a>（官方推荐方式），以及<a href="https://github.com/kubernetes/dashboard/wiki/Installation#alternative-setup" target="_blank" rel="noopener">不使用证书并且Dashboard只通过HTTP公开的方式</a>。<br>考虑到HTTPS连接方式 中复杂的 RBAC 权限控制，这里考虑使用 HTTP 方式部署dashboard，前端使用nginx proxy 配置用户和权限。</p><h3><span id="kubernetes-dashboard-部署"> kubernetes dashboard 部署</span></h3><p><a href="https://github.com/kubernetes/dashboard/wiki/Installation#alternative-setup" target="_blank" rel="noopener">不使用证书并且Dashboard只通过HTTP公开的方式</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/alternative/kubernetes-dashboard.yaml</span><br></pre></td></tr></table></figure><p>kubernetes-dashboard.yaml文件中的ServiceAccount kubernetes-dashboard遵循的是最小权限原则，<br>因此我们需要创建一个kubernetes-dashboard-admin的ServiceAccount并授予集群admin的权限，创建kubernetes-dashboard-admin.rbac.yaml：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"># cat kubernetes-dashboard-admin.rbac.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard-admin</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  </span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: kubernetes-dashboard-admin</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: kubernetes-dashboard-admin</span><br><span class="line">  namespace: kube-system</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f kubernetes-dashboard-admin.rbac.yaml</span><br></pre></td></tr></table></figure><p>查看kubernete-dashboard-admin的token:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@docker01 k8srpm]# kubectl -n kube-system get secret | grep kubernetes-dashboard-admin</span><br><span class="line">kubernetes-dashboard-admin-token-s5jmv           kubernetes.io/service-account-token   3         1h</span><br><span class="line">[root@docker01 k8srpm]# kubectl -n kube-system describe secret kubernetes-dashboard-admin-token-s5jmv </span><br><span class="line">Name:         kubernetes-dashboard-admin-token-s5jmv</span><br><span class="line">Namespace:    kube-system</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  kubernetes.io/service-account.name=kubernetes-dashboard-admin</span><br><span class="line">              kubernetes.io/service-account.uid=03b1f483-3195-11e8-87de-0026b954b21d</span><br><span class="line"></span><br><span class="line">Type:  kubernetes.io/service-account-token</span><br><span class="line"></span><br><span class="line">Data</span><br><span class="line">====</span><br><span class="line">ca.crt:     1025 bytes</span><br><span class="line">namespace:  11 bytes</span><br><span class="line">token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc（后面的省略了）</span><br></pre></td></tr></table></figure><p>创建 nginx proxy kubernete-dashboard deployment：<br>首先创建 nginx配置文件 configmap，在其中定义一个default.conf文件 ：<br>通过 nginx default.conf， 可以定义允许执行哪些操作(GET/PUT/DELETE/),以及具体的操作路径，或者添加用户认证等</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"># cat nginx-proxy-kubernetes-dashboard-configmap.conf </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-proxy-kubernetes-dashboard-default.conf </span><br><span class="line">  namespace: kube-system</span><br><span class="line">data:</span><br><span class="line">  default.conf: |</span><br><span class="line">    upstream backend &#123;</span><br><span class="line">        server kubernetes-dashboard:80 ;</span><br><span class="line">    </span><br><span class="line">    &#125;</span><br><span class="line">    map $request_method $allowed &#123;</span><br><span class="line">            default deny;</span><br><span class="line">            GET allow;</span><br><span class="line">            # PUT allow;</span><br><span class="line">            # DELETE allow;</span><br><span class="line">    &#125;</span><br><span class="line">    server &#123;</span><br><span class="line">        listen       80;</span><br><span class="line">        server_name  localhost;</span><br><span class="line">    </span><br><span class="line">        location / &#123;</span><br><span class="line">            if ( $allowed = &quot;deny&quot;) &#123; return 405; &#125;</span><br><span class="line"></span><br><span class="line">            set $flag 0;</span><br><span class="line">            if ( $request_method = &quot;DELETE&quot;) &#123; set $flag &quot;$&#123;flag&#125;1&quot;; &#125;</span><br><span class="line">            if ( $uri !~ &quot;^/api/v1/_raw/pod/.*$&quot; ) &#123; set $flag &quot;$&#123;flag&#125;2&quot;; &#125;</span><br><span class="line">            if ( $flag = &quot;012&quot; )&#123; return 405; &#125;</span><br><span class="line"></span><br><span class="line">            proxy_pass http://backend;</span><br><span class="line">            proxy_set_header Authorization &quot;Bearer eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc（后面的省略了）&quot;;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>然后，部署nginx deployment</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-proxy-kubernetes-dashboard</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80</span><br><span class="line">    targetPort: 80</span><br><span class="line">    protocol: TCP</span><br><span class="line">    name: http</span><br><span class="line">  selector:</span><br><span class="line">    app: nginx-proxy-kubernetes-dashboard</span><br><span class="line">---</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-proxy-kubernetes-dashboard-deployment</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx-proxy-kubernetes-dashboard</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx-proxy-kubernetes-dashboard</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      namespace: kube-system</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx-proxy-kubernetes-dashboard</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: nginx:1.7.9</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: default-conf</span><br><span class="line">          mountPath: /etc/nginx/conf.d/</span><br><span class="line">          readOnly: true</span><br><span class="line">        readinessProbe:</span><br><span class="line">          httpGet:</span><br><span class="line">            path: /metrics</span><br><span class="line">            port: 80</span><br><span class="line">          initialDelaySeconds: 15</span><br><span class="line">          periodSeconds: 60</span><br><span class="line">          successThreshold: 1</span><br><span class="line">          failureThreshold: 5</span><br><span class="line">        livenessProbe:</span><br><span class="line">          httpGet:</span><br><span class="line">            path: /metrics</span><br><span class="line">            port: 80</span><br><span class="line">          initialDelaySeconds: 30</span><br><span class="line">          periodSeconds: 300</span><br><span class="line">          successThreshold: 1</span><br><span class="line">          failureThreshold: 2</span><br><span class="line">      imagePullSecrets:</span><br><span class="line">        - name: private-docker-harbor-images-pull</span><br><span class="line">      volumes:</span><br><span class="line">        - name: default-conf</span><br><span class="line">          configMap:</span><br><span class="line">            name: nginx-proxy-kubernetes-dashboard-default.conf </span><br><span class="line">            items:</span><br><span class="line">            - key: default.conf</span><br><span class="line">              path: default.conf</span><br></pre></td></tr></table></figure><p>加载配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f nginx-proxy-kubernetes-dashboard-configmap.conf  </span><br><span class="line">kubectl apply -f nginx-proxy-kubernetes-dashboard-deployment.conf</span><br></pre></td></tr></table></figure><p>查看状态</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># kubectl  -n kube-system get pod -o wide | grep nginx</span><br><span class="line">nginx-proxy-kubernetes-dashboard-deployment-86df98cb56-w8qwj   1/1       Running   0          5m        10.42.1.9      docker03</span><br><span class="line"># kubectl  -n kube-system get svc | grep nginx</span><br><span class="line">nginx-proxy-kubernetes-dashboard   NodePort    10.108.161.225   &lt;none&gt;        80:31883/TCP    1h</span><br></pre></td></tr></table></figure><p>通过 NodePort 访问 kubernetes-dashboard<br><a href="http://192.168.0.31:31883" target="_blank" rel="noopener">http://192.168.0.31:31883</a></p><p>kubernetes-dashboard 配置完毕</p><h2><span id="监控插件-heapster-安装"> 监控插件 heapster 安装</span></h2><blockquote><p>Heapster为 Kubernetes（版本v1.0.6和更高版本）以及包含它的平台启用容器集群监控和性能分析。<br>Heapster支持多种数据源和存储后端。 github 位置： <a href="https://github.com/kubernetes/heapster/tree/master/deploy" target="_blank" rel="noopener">https://github.com/kubernetes/heapster/tree/master/deploy</a><br>heapster 分两种部署方式，一种带存储后端及展示前端，一种是单独安装 heapster。<br>下面 是 两种方式的安装部署：（任选一种部署即可）</p></blockquote><h3><span id="在-kubernetes-中部署heapster"> 在 Kubernetes 中部署heapster</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rbac/heapster-rbac.yaml 角色权限</span><br><span class="line">influxdb/influxdb.yaml 存储后端</span><br><span class="line">influxdb/heapster.yaml heapster主服务</span><br><span class="line">influxdb/grafana.yaml 前端展示</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p ~/heapster</span><br><span class="line">cd ~/heapster</span><br><span class="line">wget https://raw.githubusercontent.com/kubernetes/heapster/master/deploy/kube-config/rbac/heapster-rbac.yaml</span><br><span class="line">wget https://raw.githubusercontent.com/kubernetes/heapster/master/deploy/kube-config/influxdb/influxdb.yaml</span><br><span class="line">wget https://raw.githubusercontent.com/kubernetes/heapster/master/deploy/kube-config/influxdb/heapster.yaml</span><br><span class="line">wget https://raw.githubusercontent.com/kubernetes/heapster/master/deploy/kube-config/influxdb/grafana.yaml</span><br><span class="line">kubectl apply -f ~/heapster</span><br></pre></td></tr></table></figure><h3><span id="独立部署-heapster"> 独立部署 heapster</span></h3><p>如果不需要 grafana 和 influxdb ，可以单独部署 heapster</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p ~/heapster_standalone</span><br><span class="line">cd ~/heapster_standalone</span><br><span class="line">wget https://raw.githubusercontent.com/kubernetes/heapster/master/deploy/kube-config/rbac/heapster-rbac.yaml</span><br><span class="line">wget https://raw.githubusercontent.com/kubernetes/heapster/master/deploy/kube-config/standalone/heapster-controller.yaml</span><br><span class="line">kubectl apply -f ~/heapster_standalone</span><br></pre></td></tr></table></figure><p>确认所有的pod都处于running状态，打开Dashboard,集群的使用统计会以仪表盘的形式显示出来</p><h2><span id="使用træfik作为kubernetes集群的ingress控制器"> 使用Træfik作为Kubernetes集群的Ingress控制器</span></h2><p>代码示例位置： <a href="https://github.com/containous/traefik/tree/master/examples/k8s" target="_blank" rel="noopener">https://github.com/containous/traefik/tree/master/examples/k8s</a></p><h3><span id="rbac-访问控制配置"> RBAC 访问控制配置</span></h3><blockquote><p>为了简单起见，本指南将使用ClusterRoleBinding</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/traefik-rbac.yaml</span><br></pre></td></tr></table></figure><h3><span id="daemonset部署træfik"> DaemonSet部署Træfik</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/traefik-ds.yaml</span><br><span class="line">修改镜像版本</span><br><span class="line">sed -i &apos;s/image: traefik$/image: traefik:v1.5.4-alpine/&apos; traefik-ds.yaml</span><br><span class="line">kubectl apply -f  traefik-ds.yaml</span><br></pre></td></tr></table></figure><p>查看pod、service启动状态</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@docker01 k8srpm]# kubectl -n kube-system  get pod -o wide | grep traefik     </span><br><span class="line">traefik-ingress-controller-rh6vl                               1/1       Running   0          51s       192.168.0.31   docker03</span><br><span class="line">traefik-ingress-controller-vdmsf                               1/1       Running   0          51s       192.168.0.65   docker01</span><br><span class="line">traefik-ingress-controller-wtn7t                               1/1       Running   0          51s       192.168.0.67   docker02</span><br><span class="line">[root@docker01 k8srpm]# kubectl -n kube-system  get svc | grep traefik </span><br><span class="line">traefik-ingress-service            NodePort    10.100.102.205   &lt;none&gt;        80:30902/TCP,8080:31881/TCP   55s</span><br></pre></td></tr></table></figure><p>查看 traefik 管理界面</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://192.168.0.65:31881</span><br></pre></td></tr></table></figure><h3><span id="向群集提交-一个-ingress"> 向群集提交 一个 ingress</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f   https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/ui.yaml</span><br></pre></td></tr></table></figure><p>在 /etc/hosts 文件中设置一个条目，将 traefik-ui.minikube 路由到我们的集群。<br>我们现在应该可以在浏览器中访问traefik-ui.minikube并查看TræfikWeb UI。</p><p>为上面的 myip创建一个 ingress，注意修改 namespace</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># cat myip-ingress.yaml </span><br><span class="line">---</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: myip-portal</span><br><span class="line">  namespace: default</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io/ingress.class: traefik</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: a.b.cn</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: /</span><br><span class="line">        backend:</span><br><span class="line">          serviceName: myip</span><br><span class="line">          servicePort: 8080</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f  myip-ingress.yaml</span><br></pre></td></tr></table></figure><p>再次查看 TræfikWeb UI ，发现已经新增了一个域名<br>增加 host ，或者在 linux 上使用curl测试访问：默认为wrr 加权轮询</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># curl -H &apos;host:a.b.cn&apos; http://192.168.0.65/</span><br><span class="line">HOSTNAME:myip-859c596bbf-228z2 IP:10.42.1.3</span><br><span class="line"># curl -H &apos;host:a.b.cn&apos; http://192.168.0.65/</span><br><span class="line">HOSTNAME:myip-859c596bbf-4jdvg IP:10.42.0.3</span><br><span class="line"># curl -H &apos;host:a.b.cn&apos; http://192.168.0.65/</span><br><span class="line">HOSTNAME:myip-859c596bbf-vnt82 IP:10.42.2.2</span><br></pre></td></tr></table></figure><h3><span id="添加认证"> 添加认证</span></h3><p>生成密码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># htpasswd -c ./auth admin</span><br><span class="line"># cat auth</span><br><span class="line">admin:$apr1$V92e8PWE$DuOCneYOHY/D9h35cZE/S/</span><br></pre></td></tr></table></figure><p>为密码创建secret</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create secret generic secret4myip --from-file auth --namespace=default</span><br></pre></td></tr></table></figure><p>将以下注释附加到Ingress对象</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ingress.kubernetes.io/auth-type: &quot;basic&quot;</span><br><span class="line">ingress.kubernetes.io/auth-secret: &quot;secret4myip&quot;</span><br></pre></td></tr></table></figure><p>完整示例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># cat myip-ingress.yaml </span><br><span class="line">---</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: myip-portal</span><br><span class="line">  namespace: default</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io/ingress.class: traefik</span><br><span class="line">    ingress.kubernetes.io/auth-type: &quot;basic&quot;</span><br><span class="line">    ingress.kubernetes.io/auth-secret: &quot;secret4myip&quot;</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: a.b.cn</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: /</span><br><span class="line">        backend:</span><br><span class="line">          serviceName: myip</span><br><span class="line">          servicePort: 8080</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f  myip-ingress.yaml</span><br></pre></td></tr></table></figure><p>再次访问</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># curl -H &apos;host:a.b.cn&apos; http://192.168.0.65/</span><br><span class="line">401 Unauthorized</span><br><span class="line"># curl -H &apos;host:a.b.cn&apos; -u admin:admin http://192.168.0.65/</span><br><span class="line">HOSTNAME:myip-859c596bbf-228z2 IP:10.42.1.3</span><br></pre></td></tr></table></figure><p>traefik-dashboard 如下</p><img src="/2018/03/28/K8s19-cluster/traefik-dashboard.png" title="traefik-dashboard.png"><h2><span id="参考资料"> 参考资料</span></h2><ul><li>官方文档： <a href="https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/" target="_blank" rel="noopener">Using kubeadm to Create a Cluster</a></li><li>关于集群网络的选择安装 <a href="https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/#pod-network" target="_blank" rel="noopener">Installing a pod network</a></li><li>使用kubeadm 部署 kube-router <a href="https://github.com/cloudnativelabs/kube-router/blob/master/Documentation/kubeadm.md" target="_blank" rel="noopener">Deploying kube-router with kubeadm</a></li><li>kube-router github地址 <a href="https://github.com/cloudnativelabs/kube-router" target="_blank" rel="noopener">https://github.com/cloudnativelabs/kube-router</a></li><li>Kube-router IPVS，网络路由控制，网络策略控制，<a href="https://www.kubernetes.org.cn/3360.html" target="_blank" rel="noopener">中文翻译文档</a></li><li><a href="https://www.kubernetes.org.cn/3536.html" target="_blank" rel="noopener">Kubeadm HA 1.9 高可用 集群 本地离线部署</a></li><li><a href="https://blog.frognew.com/2017/09/kubeadm-install-kubernetes-1.8.html" target="_blank" rel="noopener">使用kubeadm安装Kubernetes 1.8</a></li><li>kubernetes dashboard 访问控制 <a href="https://github.com/kubernetes/dashboard/wiki/Access-control" target="_blank" rel="noopener">kubernetes/dashboard Access control</a></li><li>kubernetes/dashboard 权限 <a href="https://github.com/kubernetes/dashboard/wiki/Access-control#default-dashboard-privileges" target="_blank" rel="noopener">最小权限原则  </a></li><li>kubernetes/dashboard 认证方式 <a href="https://github.com/kubernetes/dashboard/wiki/Access-control#authentication" target="_blank" rel="noopener">仪表板支持几种用户的身份验证</a></li><li>kubernetes/dashboard 认证方式 <a href="https://github.com/kubernetes/dashboard/wiki/Access-control#authorization-header" target="_blank" rel="noopener">Authorization header </a></li><li>kubernetes/dashboard https <a href="https://github.com/kubernetes/dashboard/wiki/Installation#recommended-setup" target="_blank" rel="noopener">方式安装 </a></li><li>kubernetes/dashboard http  <a href="https://github.com/kubernetes/dashboard/wiki/Installation#alternative-setup" target="_blank" rel="noopener">方式安装 </a></li><li>Træfik for Kubernetes Ingress Controller  <a href="https://docs.traefik.io/user-guide/kubernetes/" target="_blank" rel="noopener">Kubernetes Ingress Controller</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;Kubeadm是为提供kubeadm init 和 kubeadm join而创建的工具，它是创建Kubernetes集群的最佳实践“快速路径”。&lt;br&gt;
Kubeadm执行必要的操作以启动并运行最小的可用群集。 按照设计，它只关心引导，而不关心配
      
    
    </summary>
    
      <category term="Kubernetes" scheme="yunke.science/categories/Kubernetes/"/>
    
    
      <category term="Kubernetes" scheme="yunke.science/tags/Kubernetes/"/>
    
      <category term="docker" scheme="yunke.science/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes Ingress Controller traefik</title>
    <link href="yunke.science/2018/03/28/Ingress-traefik/"/>
    <id>yunke.science/2018/03/28/Ingress-traefik/</id>
    <published>2018-03-28T08:56:37.000Z</published>
    <updated>2018-03-28T09:00:18.028Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本指南介绍了如何使用Træfik作为Kubernetes集群的Ingress控制器。<br>如果您不熟悉Kubernetes中的Ingress，则可能需要阅读Kubernetes用户指南</p></blockquote><p><ul class="markdownIt-TOC"><li><a href="#%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C">准备工作</a><ul><li><a href="#%E5%9F%BA%E4%BA%8E%E8%A7%92%E8%89%B2%E7%9A%84%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6%E9%85%8D%E7%BD%AE%E4%BB%85%E9%99%90kubernetes-16">基于角色的访问控制配置（仅限Kubernetes 1.6+）</a></li></ul></li><li><a href="#%E4%BD%BF%E7%94%A8deployment%E6%88%96daemonset%E9%83%A8%E7%BD%B2tr%C3%A6fik">使用Deployment或DaemonSet部署Træfik</a><ul><li><a href="#deployment">Deployment</a></li><li><a href="#daemonset">DaemonSet</a></li><li><a href="#%E6%A3%80%E6%9F%A5pod-%E8%BF%90%E8%A1%8C">检查pod 运行</a></li></ul></li><li><a href="#deploy-tr%C3%A6fik-using-helm-chart">Deploy Træfik using Helm Chart</a></li><li><a href="#%E5%90%91%E7%BE%A4%E9%9B%86%E6%8F%90%E4%BA%A4-%E4%B8%80%E4%B8%AA-ingress">向群集提交 一个 ingress</a></li><li><a href="#%E6%B7%BB%E5%8A%A0%E8%AE%A4%E8%AF%81">添加认证</a></li><li><a href="#%E5%9F%BA%E4%BA%8E%E5%9F%9F%E5%90%8D%E7%9A%84%E8%B7%AF%E7%94%B1%E6%A8%A1%E5%BC%8F">基于域名的路由模式</a></li><li><a href="#%E5%9F%BA%E4%BA%8E-path%E8%B7%AF%E5%BE%84-%E7%9A%84%E8%B7%AF%E7%94%B1%E6%A8%A1%E5%BC%8F">基于 PATH路径 的路由模式</a></li><li><a href="#%E6%8C%87%E5%AE%9A%E8%B7%AF%E7%94%B1%E4%BC%98%E5%85%88%E7%BA%A7">指定路由优先级</a></li><li><a href="#%E8%BD%AC%E5%8F%91%E5%88%B0-externalname">转发到 ExternalName</a></li><li><a href="#%E7%A6%81%E6%AD%A2%E4%BC%A0%E9%80%92host-header">禁止传递Host Header</a><ul><li><a href="#%E5%85%A8%E5%B1%80%E7%A6%81%E7%94%A8">全局禁用</a></li><li><a href="#%E5%9C%A8%E6%AF%8F%E4%B8%80%E4%B8%AAingress-%E4%B8%AD%E7%A6%81%E7%94%A8">在每一个Ingress 中禁用</a></li></ul></li><li><a href="#%E5%88%86%E5%89%B2ingress%E5%AF%B9%E8%B1%A1%E7%A9%BA%E9%97%B4">分割Ingress对象空间</a><ul><li><a href="#%E5%9C%A8tr%C3%A6fik%E5%92%8C%E5%85%B6%E4%BB%96ingress%E6%8E%A7%E5%88%B6%E5%99%A8%E5%90%8C%E6%97%B6%E8%BF%90%E8%A1%8C">在Træfik和其他Ingress控制器同时运行</a></li><li><a href="#%E5%9C%A8%E5%A4%9A%E4%B8%AAtr%C3%A6fik%E9%83%A8%E7%BD%B2%E4%B9%8B%E9%97%B4">在多个Træfik部署之间</a></li></ul></li><li><a href="#%E7%94%9F%E4%BA%A7%E5%BB%BA%E8%AE%AE">生产建议</a><ul><li><a href="#%E8%B5%84%E6%BA%90%E9%99%90%E5%88%B6">资源限制</a></li></ul></li></ul></p><h2><span id="准备工作"> 准备工作</span></h2><p>正常工作的Kubernetes群集。<br>kubectl 已经安装并配置。</p><h3><span id="基于角色的访问控制配置仅限kubernetes-16"> 基于角色的访问控制配置（仅限Kubernetes 1.6+）</span></h3><p>Kubernetes在1.6+中引入了基于角色的访问控制（RBAC），以允许对Kubernetes资源和API进行精细控制。</p><p>如果您的集群配置了RBAC，则需要授权Træfik使用Kubernetes API。 有两种方法可以设置适当的权限：通过特定于命名空间的RoleBindings或单个全局ClusterRoleBinding。</p><p>每个命名空间的RoleBindings能够限制只有Træfik正在监视的命名空间的授予权限，从而遵循最小权限原则。 如果Træfik不应该观察所有命名空间，并且这组命名空间不会动态更改，则这是首选方法。 否则，必须使用一个ClusterRoleBinding。</p><blockquote><p>为了简单起见，本指南将使用ClusterRoleBinding：<a href="https://github.com/containous/traefik/blob/master/examples/k8s/traefik-rbac.yaml" target="_blank" rel="noopener">示例位置examples/k8s/traefik-rbac.yaml</a></p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">kind: ClusterRole</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: traefik-ingress-controller</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - &quot;&quot;</span><br><span class="line">    resources:</span><br><span class="line">      - services</span><br><span class="line">      - endpoints</span><br><span class="line">      - secrets</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - extensions</span><br><span class="line">    resources:</span><br><span class="line">      - ingresses</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">---</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: traefik-ingress-controller</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: traefik-ingress-controller</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: traefik-ingress-controller</span><br><span class="line">  namespace: kube-system</span><br></pre></td></tr></table></figure><h2><span id="使用deployment或daemonset部署træfik"> 使用Deployment或DaemonSet部署Træfik</span></h2><p>可以使用Deployment或DaemonSet部署Træfik，而这两个选项都有自己的优点和缺点：</p><p>使用Deployment时可扩展性要好得多，因为在使用DeaemonSet时，您将拥有单节点单机节点模型。<br>可以专门在专用的一组机器上运行一个服务，这些机器使用带有DaemonSet的tag。<br>另一方面，DaemonSet允许您直接在端口80和443上访问任何节点，而使用Deployment则必须设置service对象。</p><h3><span id="deployment"> Deployment</span></h3><p><a href="https://github.com/containous/traefik/tree/master/examples/k8s/traefik-deployment.yaml" target="_blank" rel="noopener">examples/k8s/traefik-deployment.yaml</a></p><h3><span id="daemonset"> DaemonSet</span></h3><p><a href="https://github.com/containous/traefik/tree/master/examples/k8s/traefik-ds.yaml" target="_blank" rel="noopener">examples/k8s/traefik-ds.yaml</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: traefik-ingress-controller</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">kind: DaemonSet</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: traefik-ingress-controller</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: traefik-ingress-lb</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: traefik-ingress-lb</span><br><span class="line">        name: traefik-ingress-lb</span><br><span class="line">    spec:</span><br><span class="line">      serviceAccountName: traefik-ingress-controller</span><br><span class="line">      terminationGracePeriodSeconds: 60</span><br><span class="line">      hostNetwork: true</span><br><span class="line">      containers:</span><br><span class="line">      - image: traefik</span><br><span class="line">        name: traefik-ingress-lb</span><br><span class="line">        ports:</span><br><span class="line">        - name: http</span><br><span class="line">          containerPort: 80</span><br><span class="line">          hostPort: 80</span><br><span class="line">        - name: admin</span><br><span class="line">          containerPort: 8080</span><br><span class="line">        securityContext:</span><br><span class="line">          privileged: true</span><br><span class="line">        args:</span><br><span class="line">        - --api</span><br><span class="line">        - --kubernetes</span><br><span class="line">        - --logLevel=INFO</span><br><span class="line">---</span><br><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: traefik-ingress-service</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: traefik-ingress-lb</span><br><span class="line">  ports:</span><br><span class="line">    - protocol: TCP</span><br><span class="line">      port: 80</span><br><span class="line">      name: web</span><br><span class="line">    - protocol: TCP</span><br><span class="line">      port: 8080</span><br><span class="line">      name: admin</span><br><span class="line">  type: NodePort</span><br></pre></td></tr></table></figure><p>Deployment 具有更容易的上下扩展可能性。 它可以实现完整的pod生命周期并支持来自Kubernetes 1.2的滚动更新。 运行部署至少需要一个Pod。<br>DaemonSet会自动扩展到满足特定选择器的所有节点，并保证一次只更新一个节点。 对于DaemonSets，Kubernetes 1.7也完全支持滚动更新。</p><h3><span id="检查pod-运行"> 检查pod 运行</span></h3><p>您应该看到，在将DaemonSet提交给Kubernetes之后，它已经启动了一个Pod，并且它现在正在运行。 kubernetes可能需要一些时间才能拉出Træfik图像并启动容器。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl --namespace=kube-system get pods</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">NAME                                         READY     STATUS    RESTARTS   AGE</span><br><span class="line">kube-addon-manager-minikubevm                1/1       Running   0          4h</span><br><span class="line">kubernetes-dashboard-s8krj                   1/1       Running   0          4h</span><br><span class="line">traefik-ingress-controller-678226159-eqseo   1/1       Running   0          7m</span><br></pre></td></tr></table></figure><p>使用DaemonSet的话，您现在应该能够在实例的端口80上访问Træfik：<br>curl $(minikube ip)</p><p>也可以通过 services 的nodeport 端口进行访问</p><h2><span id="deploy-træfik-using-helm-chart"> Deploy Træfik using Helm Chart</span></h2><p>除了直接通过Kubernetes对象安装Træfik，您还可以使用TræfikHelm图表。</p><p><a href="https://github.com/kubernetes/charts/tree/master/stable/traefik" target="_blank" rel="noopener">通过以下方式安装Træfik图表：</a></p><p>helm install stable/traefik</p><h2><span id="向群集提交-一个-ingress"> 向群集提交 一个 ingress</span></h2><p>让我们开始创建一个服务和一个会暴露TræfikWeb UI的Ingress。<br><a href="https://github.com/containous/traefik/tree/master/examples/k8s/ui.yaml" target="_blank" rel="noopener">examples/k8s/ui.yaml</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: traefik-web-ui</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: traefik-ingress-lb</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80</span><br><span class="line">    targetPort: 8080</span><br><span class="line">---</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: traefik-web-ui</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io/ingress.class: traefik</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: traefik-ui.minikube</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - backend:</span><br><span class="line">          serviceName: traefik-web-ui</span><br><span class="line">          servicePort: 80</span><br></pre></td></tr></table></figure><p>现在让我们在 /etc/hosts 文件中设置一个条目，将 traefik-ui.minikube 路由到我们的集群。</p><p>在生产中，您会想要设置真正的DNS条目。</p><p>我们现在应该可以在浏览器中访问traefik-ui.minikube并查看TræfikWeb UI。</p><h2><span id="添加认证"> 添加认证</span></h2><p>A 生成密码文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">htpasswd -c ./auth myusername</span><br><span class="line">cat auth</span><br><span class="line">myusername:$apr1$78Jyn/1K$ERHKVRPPlzAX8eBtLuvRZ0</span><br></pre></td></tr></table></figure><p>B 为密码创建secret<br>注意： 以下是在 monitoring 命名空间中创建的mysecret</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create secret generic mysecret --from-file auth --namespace=monitoring</span><br></pre></td></tr></table></figure><p>C 将以下注释附加到Ingress对象：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ingress.kubernetes.io/auth-type: &quot;basic&quot;</span><br><span class="line">ingress.kubernetes.io/auth-secret: &quot;mysecret&quot;</span><br></pre></td></tr></table></figure><p>他们指定基本身份验证并引用包含凭据的secret ：mysecret。</p><p>以下是基于Prometheus的完整Ingress示例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line"> name: prometheus-dashboard</span><br><span class="line"> namespace: monitoring</span><br><span class="line"> annotations:</span><br><span class="line">   kubernetes.io/ingress.class: traefik</span><br><span class="line">   ingress.kubernetes.io/auth-type: &quot;basic&quot;</span><br><span class="line">   ingress.kubernetes.io/auth-secret: &quot;mysecret&quot;</span><br><span class="line">spec:</span><br><span class="line"> rules:</span><br><span class="line"> - host: dashboard.prometheus.example.com</span><br><span class="line">   http:</span><br><span class="line">     paths:</span><br><span class="line">     - backend:</span><br><span class="line">         serviceName: prometheus</span><br><span class="line">         servicePort: 9090</span><br></pre></td></tr></table></figure><p>创建ingeress<br>kubectl create -f prometheus-ingress.yaml -n monitoring</p><h2><span id="基于域名的路由模式"> 基于域名的路由模式</span></h2><p>创建 deployment<br><a href="https://github.com/containous/traefik/tree/master/examples/k8s/cheese-deployments.yaml" target="_blank" rel="noopener">examples/k8s/cheese-deployments.yaml</a></p><p>创建 service<br><a href="https://github.com/containous/traefik/tree/master/examples/k8s/cheese-services.yaml" target="_blank" rel="noopener">examples/k8s/cheese-services.yaml</a></p><p>创建 ingress<br><a href="https://github.com/containous/traefik/tree/master/examples/k8s/cheese-ingress.yaml" target="_blank" rel="noopener">examples/k8s/cheese-ingress.yaml</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: cheese</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io/ingress.class: traefik</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: stilton.minikube</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: /</span><br><span class="line">        backend:</span><br><span class="line">          serviceName: stilton</span><br><span class="line">          servicePort: http</span><br><span class="line">  - host: cheddar.minikube</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: /</span><br><span class="line">        backend:</span><br><span class="line">          serviceName: cheddar</span><br><span class="line">          servicePort: http</span><br><span class="line">  - host: wensleydale.minikube</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: /</span><br><span class="line">        backend:</span><br><span class="line">          serviceName: wensleydale</span><br><span class="line">          servicePort: http</span><br></pre></td></tr></table></figure><h2><span id="基于-path路径-的路由模式"> 基于 PATH路径 的路由模式</span></h2><p>所有3个站点托管在一个域中。<br><a href="https://github.com/containous/traefik/tree/master/examples/k8s/cheeses-ingress.yaml" target="_blank" rel="noopener">examples/k8s/cheeses-ingress.yaml</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: cheeses</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io/ingress.class: traefik</span><br><span class="line">    traefik.frontend.rule.type: PathPrefixStrip</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: cheeses.minikube</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: /stilton</span><br><span class="line">        backend:</span><br><span class="line">          serviceName: stilton</span><br><span class="line">          servicePort: http</span><br><span class="line">      - path: /cheddar</span><br><span class="line">        backend:</span><br><span class="line">          serviceName: cheddar</span><br><span class="line">          servicePort: http</span><br><span class="line">      - path: /wensleydale</span><br><span class="line">        backend:</span><br><span class="line">          serviceName: wensleydale</span><br><span class="line">          servicePort: http</span><br></pre></td></tr></table></figure><p>我们正在配置Træfik通过traefik.frontend.rule.type注释去掉url路径中的前缀，以便我们可以在不修改的情况下使用前一个示例中的容器。</p><h2><span id="指定路由优先级"> 指定路由优先级</span></h2><p>有时您需要为 ingress 路由指定优先级，特别是在处理通配符路由时。 这可以通过添加 traefik.frontend.priority 注释来完成，即：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: wildcard-cheeses</span><br><span class="line">  annotations:</span><br><span class="line">    traefik.frontend.priority: &quot;1&quot;</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: *.minikube</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: /</span><br><span class="line">        backend:</span><br><span class="line">          serviceName: stilton</span><br><span class="line">          servicePort: http</span><br><span class="line"></span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: specific-cheeses</span><br><span class="line">  annotations:</span><br><span class="line">    traefik.frontend.priority: &quot;2&quot;</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: specific.minikube</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: /</span><br><span class="line">        backend:</span><br><span class="line">          serviceName: stilton</span><br><span class="line">          servicePort: http</span><br></pre></td></tr></table></figure><p>请注意，数字必须使用引号括起来。  数值越大，优先级越高。</p><h2><span id="转发到-externalname"> 转发到 ExternalName</span></h2><p>指定<a href="https://kubernetes.io/docs/concepts/services-networking/service/#services-without-selectors" target="_blank" rel="noopener">ExternalName</a>时，Træfik将相应地转发请求到给定主机，并在服务端口匹配443时使用HTTPS。这仍然需要在服务上从入口端口到（外部）服务端口设置正确的端口映射。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: my-service</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - protocol: TCP</span><br><span class="line">    port: 80</span><br><span class="line">    targetPort: 9376</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">kind: Endpoints</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: my-service</span><br><span class="line">subsets:</span><br><span class="line">  - addresses:</span><br><span class="line">      - ip: 1.2.3.4</span><br><span class="line">    ports:</span><br><span class="line">      - port: 9376</span><br></pre></td></tr></table></figure><h2><span id="禁止传递host-header"> 禁止传递Host Header</span></h2><p>默认情况下，Træfik将传入的主机头传递给上游资源。</p><p>但是，有些时候你可能不希望这种情况发生。 例如，如果您的服务是ExternalName类型的。</p><h3><span id="全局禁用"> 全局禁用</span></h3><p>将以下内容添加到您的TOML配置文件中：<br>disablePassHostHeaders = true</p><h3><span id="在每一个ingress-中禁用"> 在每一个Ingress 中禁用</span></h3><p>添加注释 traefik.frontend.passHostHeader: “false”</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: example</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io/ingress.class: traefik</span><br><span class="line">    traefik.frontend.passHostHeader: &quot;false&quot;</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: example.com</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: /static</span><br><span class="line">        backend:</span><br><span class="line">          serviceName: static</span><br><span class="line">          servicePort: https</span><br></pre></td></tr></table></figure><p>还有一个示例服务定义：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: static</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - name: https</span><br><span class="line">    port: 443</span><br><span class="line">  type: ExternalName</span><br><span class="line">  externalName: static.otherdomain.com</span><br></pre></td></tr></table></figure><blockquote><p>如果您要访问 <a href="http://example.com/static" target="_blank" rel="noopener">example.com/static</a> ，则请求将传递给 <a href="http://static.otherdomain.com/static" target="_blank" rel="noopener">static.otherdomain.com/static</a> ，并且static.otherdomain.com将收到请求，并且Host标头为 <a href="http://static.otherdomain.com" target="_blank" rel="noopener">static.otherdomain.com</a> 。</p></blockquote><blockquote><p>每个 ingress 注释将覆盖任何全局值设置。 因此，您可以在TOML配置文件中将disablePassHostHeaders设置为true，然后根据需要启用每个 ingress 传递主机头。</p></blockquote><h2><span id="分割ingress对象空间"> 分割Ingress对象空间</span></h2><p>默认情况下，Træfik处理它观察到的每个Ingress对象。 然而，有时可能需要忽略某些对象。 以下小节介绍常见用例以及如何使用Træfik处理它们。</p><h3><span id="在træfik和其他ingress控制器同时运行"> 在Træfik和其他Ingress控制器同时运行</span></h3><p>有时Træfik会与其他Ingress控制器一起运行。 其中一个例子是Træfik和云供应商Ingress控制器都处于活动状态。</p><p><a href="http://kubernetes.io/ingress.class%E6%B3%A8%E9%87%8A%E5%8F%AF%E4%BB%A5%E9%99%84%E5%8A%A0%E5%88%B0%E4%BB%BB%E4%BD%95Ingress%E5%AF%B9%E8%B1%A1%EF%BC%8C%E4%BB%A5%E6%8E%A7%E5%88%B6Tr%C3%A6fik%E6%98%AF%E5%90%A6%E5%BA%94%E8%AF%A5%E5%A4%84%E7%90%86%E5%AE%83%E3%80%82" target="_blank" rel="noopener">kubernetes.io/ingress.class注释可以附加到任何Ingress对象，以控制Træfik是否应该处理它。</a></p><p>如果注释缺失，包含空值或者 为 traefik，则Træfik控制器将负责并处理相关的Ingress对象。 如果注释包含任何其他值（通常是不同的Ingress控制器的名称），则Træfik将忽略该对象。</p><h3><span id="在多个træfik部署之间"> 在多个Træfik部署之间</span></h3><p>有时多个Træfik部署应该同时运行。 例如，可以想象有一个部署处理内部，另一个部署处理外部流量。</p><p>对于这种情况，建议通过标签对Ingress对象进行分类，并相应地为每个Træfik部署配置labelSelector选项。 要坚持上面的内部/外部示例，所有用于内部流量的Ingress对象都可以接收流量类型：内部标签，而指定用于外部流量的对象会接收流量类型：外部标签。 TræfikDeployments上的标签选择器将分别为traffic-type = internal和traffic-type = external。</p><h2><span id="生产建议"> 生产建议</span></h2><h3><span id="资源限制"> 资源限制</span></h3><p>所示的示例故意没有指定任何资源限制，因为没有一个适合所有人的尺寸。</p><p>但是，在生产环境中，设置适当的边界非常重要，特别是在CPU方面：</p><p>太严格并且Traefik在服务请求时会受到限制（因为Kubernetes实施了严格限额）<br>太松并且Traefik可能浪费其他容器不可用的资源<br>如有疑问，您应该测量您的资源需求，并相应调整请求和限制。</p><p>本指南中使用的配置文件可以在<a href="https://github.com/containous/traefik/tree/master/examples/k8s" target="_blank" rel="noopener">示例目录中找到 </a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;本指南介绍了如何使用Træfik作为Kubernetes集群的Ingress控制器。&lt;br&gt;
如果您不熟悉Kubernetes中的Ingress，则可能需要阅读Kubernetes用户指南&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;ul clas
      
    
    </summary>
    
      <category term="Kubernetes" scheme="yunke.science/categories/Kubernetes/"/>
    
    
      <category term="Kubernetes" scheme="yunke.science/tags/Kubernetes/"/>
    
      <category term="docker" scheme="yunke.science/tags/docker/"/>
    
      <category term="traefik" scheme="yunke.science/tags/traefik/"/>
    
  </entry>
  
  <entry>
    <title>elk5+, 取消String类型，使用keyword和text代替</title>
    <link href="yunke.science/2018/01/22/elk5-strings/"/>
    <id>yunke.science/2018/01/22/elk5-strings/</id>
    <published>2018-01-22T02:08:17.000Z</published>
    <updated>2018-01-22T02:12:42.712Z</updated>
    
    <content type="html"><![CDATA[<p>随着Elasticsearch 5.0的发布接近，现在是时候介绍这个即将发布的版本的发布亮点之一：删除string类型。 这种变化的背景是我们认为string类型很混乱：Elasticsearch有两种非常不同的方式来搜索字符串。 您可以搜索整个值，我们通常将其称为关键字 keyword 搜索，也可以搜索我们通常称为全文搜索的单个令牌tokens。 如果您熟悉Elasticsearch，您应该知道前面的字符串应该被映射为not_analyzed字符串，而后者应该被映射为analyzed字符串。</p><p><ul class="markdownIt-TOC"><li><a href="#text-vs-keyword">Text vs. keyword</a></li><li><a href="#new-defaults">New defaults</a></li><li><a href="#how-to-migrate">How to migrate</a></li><li><a href="#%E5%90%91%E5%90%8E%E5%85%BC%E5%AE%B9">向后兼容</a></li></ul></p><h2><span id="text-vs-keyword"> Text vs. keyword</span></h2><p>对于这两种截然不同的用例使用相同的字段类型这一事实会产生问题，因为某些选项只对某个用例有意义。 例如， position_increment_gap 对于 not_analyzed 字符串没有什么意义，在 analyzed 字符串的情况下 ignore_above 是否适用于整个值或单个标记并不明显（如果您想知道：它是否适用于整个值，个别令牌可以与限制令牌过滤器一起应用）。</p><p>为了避免这些问题， string字段分为两种新类型：应该用于全文搜索的文本和用于关键字搜索的关键字。</p><h2><span id="new-defaults"> New defaults</span></h2><p>因此，我们做了这个分割，我们决定改变字符串字段的默认动态映射。 当开始使用 Elasticsearch 时，一个常见的沮丧情况是您必须重新编制索引，以便能够汇总整个字段值。 例如，想象一下，你正在索引一个city领域的文件。 在这个领域的聚合会给york和york带来不同的计数，而不是york的单一计数，这通常是预期的行为。 不幸的是，解决这个问题需要重新索引字段，以便索引具有正确的结构来回答这个问题。</p><p>为了使事情变得更好，Elasticsearch决定借用一个最初源于Logstash的思想：字符串默认情况下将被映射为text和keyword 。 例如，如果您编制以下简单的文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;foo&quot;: &quot;bar&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后将创建以下动态映射：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;foo&quot;: &#123;</span><br><span class="line">    &quot;type&quot; &quot;text&quot;,</span><br><span class="line">    &quot;fields&quot;: &#123;</span><br><span class="line">      &quot;keyword&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;keyword&quot;,</span><br><span class="line">        &quot;ignore_above&quot;: 256</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>因此，可以使用foo.keyword字段对foo执行全文搜索，并执行关键字搜索和聚合。</p><p>禁用此功能很简单：您只需要显式映射字符串字段或使用与所有字符串字段匹配的动态模板。 例如，下面的动态模板可以用来恢复在Elasticsearch 2.x中使用的相同的动态映射：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;match_mapping_type&quot;: &quot;string&quot;,</span><br><span class="line">  &quot;mapping&quot;: &#123;</span><br><span class="line">    &quot;type&quot;: &quot;text&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2><span id="how-to-migrate"> How to migrate</span></h2><p>在大多数情况下，迁移应该是非常简单的。 过去被映射为analyzed字符串的字段</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;foo&quot;: &#123;</span><br><span class="line">    &quot;type&quot; &quot;string&quot;,</span><br><span class="line">    &quot;index&quot;: &quot;analyzed&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>现在需要被映射为一个text字段：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;foo&quot;: &#123;</span><br><span class="line">    &quot;type&quot; &quot;text&quot;,</span><br><span class="line">    &quot;index&quot;: true</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>曾经被映射为not_analyzed字符串的not_analyzed<br>现在需要被映射为keyword字段</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;foo&quot;: &#123;</span><br><span class="line">    &quot;type&quot; &quot;keyword&quot;,</span><br><span class="line">    &quot;index&quot;: true</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>正如你所看到的那样，现在string字段已经被分割成了text和keyword ，我们不需要为index属性设置3个状态（ analyzed ， not_analyzed和no ），它们只存在于string字段中。 我们可以使用一个简单的布尔值来告诉Elasticsearch是否可以搜索字段。</p><h2><span id="向后兼容"> 向后兼容</span></h2><p>由于主要升级通常都有自己的挑战，因此我们尽最大努力不要求在升级群集到Elasticsearch 5.0的同时升级所有映射。 首先， string字段将继续在现有的2.x索引上工作。 当涉及到新的索引时，Elasticsearch有一些逻辑，它会自动将字符串映射转换为等价的text或keyword映射。 如果您有索引模板添加与字符串字段的映射，这是特别有用的：这些模板将继续使用Elasticsearch 5.x。 也就是说，我们仍然应该考虑升级它们，因为我们计划在发布Elasticsearch 6.0时删除这个向后兼容层。</p><blockquote><p>来自：<a href="https://www.elastic.co/blog/strings-are-dead-long-live-strings" target="_blank" rel="noopener">Strings are dead, long live strings!</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;随着Elasticsearch 5.0的发布接近，现在是时候介绍这个即将发布的版本的发布亮点之一：删除string类型。 这种变化的背景是我们认为string类型很混乱：Elasticsearch有两种非常不同的方式来搜索字符串。 您可以搜索整个值，我们通常将其称为关键字 
      
    
    </summary>
    
      <category term="elk" scheme="yunke.science/categories/elk/"/>
    
    
      <category term="elk" scheme="yunke.science/tags/elk/"/>
    
  </entry>
  
  <entry>
    <title>Elastic x-pack plugin watches Features</title>
    <link href="yunke.science/2018/01/21/Elastic-watch/"/>
    <id>yunke.science/2018/01/21/Elastic-watch/</id>
    <published>2018-01-21T05:46:23.000Z</published>
    <updated>2018-01-21T05:52:29.273Z</updated>
    
    <content type="html"><![CDATA[<p>关于elk群集和索引事件的警报<br>X-Pack警报是一组管理功能，使您能够监视数据中的更改或异常，并执行必要的响应操作<br>相关的数据或数据的变化可以用定期的Elasticsearch查询来识别。<br>查询的结果可以根据条件进行检查。<br>如果条件为真，则执行一个或多个操作 - 发送电子邮件，通知第三方系统或存储查询结果。<br>当您将X-Pack安装到Elasticsearch和Kibana时，Watcher会自动启用。</p><blockquote><p>来自： <a href="https://github.com/chenryn/ELKstack-guide-cn/blob/master/elasticsearch/other/watcher.md" target="_blank" rel="noopener">https://github.com/chenryn/ELKstack-guide-cn/blob/master/elasticsearch/other/watcher.md</a></p></blockquote><h2><span id="watcher-产品"> Watcher 产品</span></h2><h2><span id="watches-四个模块"> watches 四个模块</span></h2><ul><li>Schedule<br>A schedule for running a query and checking the condition.</li><li>Query<br>The query to run as input to the condition. Watches support the full Elasticsearch query language, including aggregations.</li><li>Condition<br>A condition that determines whether or not to execute the actions. You can use simple conditions (always true), or use scripting for more sophisticated scenarios.</li><li>Actions<br>One or more actions, such as sending email, pushing data to 3rd party systems through a webhook, or indexing the results of the query.</li></ul><p>Watcher 也是 <a href="http://Elastic.co" target="_blank" rel="noopener">Elastic.co</a> 公司的商业产品，和 Shield，Marvel 一样插件式安装即可：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bin/plugin -i elasticsearch/license/latest</span><br><span class="line">bin/plugin -i elasticsearch/watcher/latest</span><br></pre></td></tr></table></figure><p>Watcher 使用方面，也提供标准的 RESTful 接口，示例如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"># curl -XPUT http://127.0.0.1:9200/_watcher/watch/error_status -d&apos;</span><br><span class="line">&#123;</span><br><span class="line">    &quot;trigger&quot;: &#123;</span><br><span class="line">        &quot;schedule&quot; : &#123; &quot;cron&quot; : &quot;0/5 * * * * ?&quot; &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;input&quot; : &#123;</span><br><span class="line">        &quot;search&quot; : &#123;</span><br><span class="line">            &quot;request&quot; : &#123;</span><br><span class="line">                &quot;indices&quot; : [ &quot;&lt;logstash-&#123;now/d&#125;&gt;&quot;, &quot;&lt;logstash-&#123;now/d-1d&#125;&gt;&quot; ],</span><br><span class="line">                &quot;body&quot; : &#123;</span><br><span class="line">                    &quot;query&quot; : &#123;</span><br><span class="line">                        &quot;filtered&quot; : &#123;</span><br><span class="line">                            &quot;query&quot; : &#123; &quot;match&quot; : &#123; &quot;status&quot; : &quot;error&quot; &#125;&#125;,</span><br><span class="line">                            &quot;filter&quot; : &#123; &quot;range&quot; : &#123; &quot;@timestamp&quot; : &#123; &quot;from&quot; : &quot;now-5m&quot; &#125;&#125;&#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;condition&quot; : &#123;</span><br><span class="line">        &quot;compare&quot; : &#123; &quot;ctx.payload.hits.total&quot; : &#123; &quot;gt&quot; : 0 &#125;&#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;transform&quot; : &#123;</span><br><span class="line">        &quot;search&quot; : &#123;</span><br><span class="line">            &quot;request&quot; : &#123;</span><br><span class="line">                &quot;indices&quot; : [ &quot;&lt;logstash-&#123;now/d&#125;&gt;&quot;, &quot;&lt;logstash-&#123;now/d-1d&#125;&gt;&quot; ],</span><br><span class="line">                &quot;body&quot; : &#123;</span><br><span class="line">                    &quot;query&quot; : &#123;</span><br><span class="line">                        &quot;filtered&quot; : &#123;</span><br><span class="line">                            &quot;query&quot; : &#123; &quot;match&quot; : &#123; &quot;status&quot; : &quot;error&quot; &#125;&#125;,</span><br><span class="line">                            &quot;filter&quot; : &#123; &quot;range&quot; : &#123; &quot;@timestamp&quot; : &#123; &quot;from&quot; : &quot;now-5m&quot; &#125;&#125;&#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &quot;aggs&quot; : &#123;</span><br><span class="line">                        &quot;topn&quot; : &#123;</span><br><span class="line">                            &quot;terms&quot; : &#123;</span><br><span class="line">                                &quot;field&quot; : &quot;userid&quot;</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;actions&quot; : &#123;</span><br><span class="line">        &quot;email_admin&quot; : &#123;</span><br><span class="line">            &quot;throttle_period&quot; : &quot;15m&quot;,</span><br><span class="line">            &quot;email&quot; : &#123;</span><br><span class="line">                &quot;to&quot; : &quot;admin@domain&quot;,</span><br><span class="line">                &quot;subject&quot; : &quot;Found &#123;&#123;ctx.payload.hits.total&#125;&#125; Error Events at &#123;&#123;ctx.trigger.triggered_time&#125;&#125;&quot;,</span><br><span class="line">                &quot;priority&quot; : &quot;high&quot;,</span><br><span class="line">                &quot;body&quot; : &quot;Top10 users:\n&#123;&#123;#ctx.payload.aggregations.topn.buckets&#125;&#125;\t&#123;&#123;key&#125;&#125; &#123;&#123;doc_count&#125;&#125;\n&#123;&#123;/ctx.payload.aggregations.topn.buckets&#125;&#125;&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><p>上面这行命令，意即:</p><ol><li>每 5 分钟，向最近两天的 <code>logstash-yyyy.MM.dd</code> 索引发起一次条件为最近五分钟，status 字段内容为 error 的查询请求;</li><li>对查询结果做 hits 总数大于 0 的判断;</li><li>如果为真，再请求一次上述条件下，userid 字段的 Top 10 数据集作为后续处理的来源;</li><li>如果最近 15 分钟内未发送过报警，则向 <code>admin@domain</code> 邮箱发送一个标题为 “Found N erroneous events at yyyy-MM-ddTHH:mm:ssZ”，内容为 “Top10 users” 列表的报警邮件。</li></ol><p>整个请求体顺序执行。目前 trigger 只支持 scheduler 方式(但是 schedule 下有 crontab、interval、hourly、daily、weekly、monthly、yearly 等多种写法)，input 支持 search 和 http 方式，actions 支持 email，logging，webhook 方式，transform 是可选项，而且可以设置在 actions 里，不同 actions 做不同的 payload 转换。</p><p>crontab 定义语法和 Linux 标准不太一致，采用的是 Quartz，文件见：<a href="http://www.quartz-scheduler.org/documentation/quartz-1.x/tutorials/crontrigger" target="_blank" rel="noopener">http://www.quartz-scheduler.org/documentation/quartz-1.x/tutorials/crontrigger</a>。</p><p>condition, transform 和 actions 中，默认使用 Watcher 增强版的 xmustache 模板语言（示例中的数组循环就是一例）。也可以使用固化的脚本文件，比如有 <code>threshold_hits.groovy</code> 的话，可以执行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&quot;condition&quot; : &#123;</span><br><span class="line">  &quot;script&quot; : &#123;</span><br><span class="line">    &quot;file&quot; : &quot;threshold_hits&quot;,</span><br><span class="line">    &quot;params&quot; : &#123;</span><br><span class="line">      &quot;threshold&quot; : 0</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Watcher 中可用的 <code>ctx</code> 变量包括：</p><ul><li><code>ctx.watch_id</code></li><li><code>ctx.execution_time</code></li><li><code>ctx.trigger.triggered_time</code></li><li><code>ctx.trigger.scheduled_time</code></li><li><code>ctx.metadata.*</code></li><li><code>ctx.payload.*</code></li></ul><p>完整的 Watcher 插件内部执行流程如下图。相信有编程能力的读者都可以用 crontab/at 配合 curl，email 工具仿造出来类似功能的 shell 脚本。</p><p><img src="https://www.elastic.co/guide/en/watcher/current/images/watch-execution.jpg" alt=""></p><p><strong>注意</strong>：</p><p>在 search 中，对 indices 内容可以写完整的索引名比如 <code>syslog</code>，也可以写通配符比如 <code>logstash-*</code>，也可以写时序索引动态定义方式如 <code>&lt;logstash-{now/d}&gt;</code>。而这个动态定义，Watcher 是支持根据时区来确定的，这个需要在 <code>elasticsearch.yml</code> 里配置一行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">watcher.input.search.dynamic_indices.time_zone: &apos;+08:00&apos;</span><br></pre></td></tr></table></figure><p>笔者仿照 watcher 的配置语法，开源了一个基于 Kibana 扩展的类 watcher 监控项目，本书稍后 Kibana 章节将会有详细介绍。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;关于elk群集和索引事件的警报&lt;br&gt;
X-Pack警报是一组管理功能，使您能够监视数据中的更改或异常，并执行必要的响应操作&lt;br&gt;
相关的数据或数据的变化可以用定期的Elasticsearch查询来识别。&lt;br&gt;
查询的结果可以根据条件进行检查。&lt;br&gt;
如果条件为真，则
      
    
    </summary>
    
      <category term="elk" scheme="yunke.science/categories/elk/"/>
    
    
      <category term="elk" scheme="yunke.science/tags/elk/"/>
    
  </entry>
  
  <entry>
    <title>钉钉webhook实现消息推送</title>
    <link href="yunke.science/2018/01/14/ding-webhook/"/>
    <id>yunke.science/2018/01/14/ding-webhook/</id>
    <published>2018-01-14T10:00:23.000Z</published>
    <updated>2018-01-14T10:01:14.136Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>之前的运维告警多通过SMS、mail 等方式通知到相应的人员。不过虽着 IM 和手机APP的发展，很多告警也会发送到IM软件上去。目前比较常用的是发送到微信和钉钉上。不过微信发送时，需要开通企业公众号，比较麻烦。而钉钉在今年更新的机器人功能比较易用，只要启用的有钉钉，可以通过官方提供的API，可以很方便的post数据到相应的接收人 。其支持的机器人类型也比较丰富，除支持自定义webhook发送消息外，其还有gitlab、github、jira等机器人。<br>参考：<br><a href="http://www.361way.com/dingding-zabbix-webhook/5526.html" target="_blank" rel="noopener">http://www.361way.com/dingding-zabbix-webhook/5526.html</a><br><a href="https://open-doc.dingtalk.com/docs/doc.htm?spm=a219a.7629140.0.0.j6QoSq&amp;treeId=257&amp;articleId=105735&amp;docType=1" target="_blank" rel="noopener">https://open-doc.dingtalk.com/docs/doc.htm?spm=a219a.7629140.0.0.j6QoSq&amp;treeId=257&amp;articleId=105735&amp;docType=1</a></p></blockquote><p><ul class="markdownIt-TOC"><li><a href="#%E8%8E%B7%E5%8F%96%E8%87%AA%E5%AE%9A%E4%B9%89%E6%9C%BA%E5%99%A8%E4%BA%BAwebhook">获取自定义机器人webhook</a></li><li><a href="#%E4%BD%BF%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89%E6%9C%BA%E5%99%A8%E4%BA%BA">使用自定义机器人</a></li><li><a href="#%E6%B6%88%E6%81%AF%E7%B1%BB%E5%9E%8B%E5%8F%8A%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F">消息类型及数据格式</a></li><li><a href="#%E6%B5%8B%E8%AF%95%E8%87%AA%E5%AE%9A%E4%B9%89%E6%9C%BA%E5%99%A8%E4%BA%BA">测试自定义机器人</a></li><li><a href="#python-%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B">python 代码示例</a></li></ul></p><h2><span id="获取自定义机器人webhook"> 获取自定义机器人webhook</span></h2><p>在机器人管理页面选择“自定义”机器人，输入机器人名字并选择要发送消息的群。如果需要的话，可以为机器人设置一个头像。点击“完成添加”。<br>点击“复制”按钮，即可获得这个机器人对应的Webhook地址，其格式如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://oapi.dingtalk.com/robot/send?access_token=xxxxxxxx</span><br></pre></td></tr></table></figure><h2><span id="使用自定义机器人"> 使用自定义机器人</span></h2><ul><li>获取到Webhook地址后，用户可以使用任何方式向这个地址发起HTTP POST 请求，即可实现给该群组发送消息。注意，发起POST请求时，必须将字符集编码设置成UTF-8。</li><li>当前自定义机器人支持文本（text）、连接（link）、markdown（markdown）三种消息类型，大家可以根据自己的使用场景选择合适的消息类型，达到最好的展示样式。- 具体的消息类型参考下一节内容。</li><li>自定义机器人发送消息时，可以通过手机号码指定“被@人列表”。在“被@人列表”里面的人员，在收到该消息时，会有@消息提醒（免打扰会话仍然通知提醒，首屏出现“有人@你”）</li></ul><h2><span id="消息类型及数据格式"> 消息类型及数据格式</span></h2><p>这里只介绍 markdown类型</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">     &quot;msgtype&quot;: &quot;markdown&quot;,</span><br><span class="line">     &quot;markdown&quot;: &#123;</span><br><span class="line">         &quot;title&quot;:&quot;杭州天气&quot;,</span><br><span class="line">         &quot;text&quot;: &quot;#### 杭州天气 @156xxxx8827\n&quot; +</span><br><span class="line">                 &quot;&gt; 9度，西北风1级，空气良89，相对温度73%\n\n&quot; +</span><br><span class="line">                 &quot;&gt; ![screenshot](http://image.jpg)\n&quot;  +</span><br><span class="line">                 &quot;&gt; ###### 10点20分发布 [天气](http://www.thinkpage.cn/) \n&quot;</span><br><span class="line">     &#125;,</span><br><span class="line">    &quot;at&quot;: &#123;</span><br><span class="line">        &quot;atMobiles&quot;: [</span><br><span class="line">            &quot;156xxxx8827&quot;, </span><br><span class="line">            &quot;189xxxx8325&quot;</span><br><span class="line">        ], </span><br><span class="line">        &quot;isAtAll&quot;: false</span><br><span class="line">    &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><table><thead><tr><th>参数</th><th>必选</th><th>类型</th><th>说明</th></tr></thead><tbody><tr><td>msgtype</td><td>true</td><td>string</td><td>此消息类型为固定markdown</td></tr><tr><td>title</td><td>true</td><td>string</td><td>首屏会话透出的展示内容</td></tr><tr><td>text</td><td>true</td><td>string</td><td>markdown格式的消息</td></tr><tr><td>atMobiles</td><td>Array</td><td>否</td><td>被@人的手机号(在text内容里要有@手机号)</td></tr><tr><td>isAtAll</td><td>bool</td><td>否</td><td>@所有人时:true,否则为:false</td></tr></tbody></table><p>说明：目前只支持md语法的子集，具体支持的元素如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">标题</span><br><span class="line"># 一级标题</span><br><span class="line">## 二级标题</span><br><span class="line">### 三级标题</span><br><span class="line">#### 四级标题</span><br><span class="line">##### 五级标题</span><br><span class="line">###### 六级标题</span><br><span class="line"> </span><br><span class="line">引用</span><br><span class="line">&gt; A man who stands for nothing will fall for anything.</span><br><span class="line"> </span><br><span class="line">文字加粗、斜体</span><br><span class="line">**bold**</span><br><span class="line">*italic*</span><br><span class="line"> </span><br><span class="line">链接</span><br><span class="line">[this is a link](http://name.com)</span><br><span class="line"> </span><br><span class="line">图片</span><br><span class="line">![](http://name.com/pic.jpg)</span><br><span class="line"> </span><br><span class="line">无序列表</span><br><span class="line">- item1</span><br><span class="line">- item2</span><br><span class="line"> </span><br><span class="line">有序列表</span><br><span class="line">1. item1</span><br><span class="line">2. item2</span><br></pre></td></tr></table></figure><h2><span id="测试自定义机器人"> 测试自定义机器人</span></h2><p>通过下面方法，可以快速验证自定义机器人是否可以正常工作：<br>使用命令行工具curl（版本用最新:7.29.0）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">curl &apos;https://oapi.dingtalk.com/robot/send?access_token=xxxxxxxx&apos; \</span><br><span class="line">   -H &apos;Content-Type: application/json&apos; \</span><br><span class="line">   -d &apos;</span><br><span class="line">  &#123;&quot;msgtype&quot;: &quot;text&quot;, </span><br><span class="line">    &quot;text&quot;: &#123;</span><br><span class="line">        &quot;content&quot;: &quot;我就是我, 是不一样的烟火&quot;</span><br><span class="line">     &#125;</span><br><span class="line">  &#125;&apos;</span><br></pre></td></tr></table></figure><h2><span id="python-代码示例"> python 代码示例</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">def send2robot(access_token, title, text ):</span><br><span class="line">    headers = &#123;</span><br><span class="line">        &quot;Content-Type&quot;: &quot;application/json&quot;,</span><br><span class="line">        &quot;charset&quot;:&quot;utf-8&quot;</span><br><span class="line">    &#125;</span><br><span class="line">    oapi_url = &quot;https://oapi.dingtalk.com/robot/send?access_token=%s&quot;%(access_token)</span><br><span class="line">    post_data = &#123;</span><br><span class="line">        &quot;msgtype&quot;: &quot;markdown&quot;,</span><br><span class="line">        &quot;markdown&quot;: &#123;</span><br><span class="line">            # title 没有在信息中体现, 貌似没什么用</span><br><span class="line">            &quot;title&quot;: title,</span><br><span class="line">            &quot;text&quot;: text</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    result = requests.post(oapi_url, data=json.dumps(post_data), headers=headers)</span><br><span class="line">    errmsg = result.json().get(&apos;errmsg&apos;)</span><br><span class="line">    if errmsg != &quot;ok&quot;:</span><br><span class="line">        print (&quot;post error :%s&quot;%(errmsg))</span><br><span class="line">    else:</span><br><span class="line">        print (&quot;post OK !&quot;)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;之前的运维告警多通过SMS、mail 等方式通知到相应的人员。不过虽着 IM 和手机APP的发展，很多告警也会发送到IM软件上去。目前比较常用的是发送到微信和钉钉上。不过微信发送时，需要开通企业公众号，比较麻烦。而钉钉在今年更新的机器人功能比较易用
      
    
    </summary>
    
      <category term="python" scheme="yunke.science/categories/python/"/>
    
    
      <category term="python" scheme="yunke.science/tags/python/"/>
    
      <category term="monitor" scheme="yunke.science/tags/monitor/"/>
    
  </entry>
  
  <entry>
    <title>利用Python获取动态网页截图</title>
    <link href="yunke.science/2018/01/14/pythons-shots/"/>
    <id>yunke.science/2018/01/14/pythons-shots/</id>
    <published>2018-01-14T09:31:04.000Z</published>
    <updated>2018-01-14T09:32:52.468Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Selenium 是什么？一句话，自动化测试工具。它支持各种浏览器，包括 Chrome，Safari，Firefox 等主流界面式浏览器，如果你在这些浏览器里面安装一个 Selenium 的插件，那么便可以方便地实现Web界面的测试。换句话说叫 Selenium 支持这些浏览器驱动。<br>Selenium 通过相应的驱动拉取相应浏览器，进行测试，截屏等操作。<br>参考 ：<br><a href="https://www.jianshu.com/p/d7a966ec1189" target="_blank" rel="noopener">https://www.jianshu.com/p/d7a966ec1189</a><br><a href="https://cuiqingcai.com/2599.html" target="_blank" rel="noopener">https://cuiqingcai.com/2599.html</a></p></blockquote><p><ul class="markdownIt-TOC"><li><a href="#%E4%BB%80%E4%B9%88%E6%98%AFwebdriver">什么是Webdriver？</a></li><li><a href="#%E5%AE%89%E8%A3%85selenium">安装Selenium</a></li><li><a href="#%E5%AE%89%E8%A3%85firefox%E6%B5%8F%E8%A7%88%E5%99%A8">安装Firefox浏览器</a></li><li><a href="#%E5%AE%89%E8%A3%85firefox%E5%AF%B9%E5%BA%94%E7%9A%84webdriver%E9%A9%B1%E5%8A%A8">安装firefox对应的webdriver（驱动）</a></li><li><a href="#%E5%AE%9E%E6%88%98">实战</a></li><li><a href="#%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B">代码示例</a></li><li><a href="#selenium%E5%AE%9E%E7%8E%B0%E6%B5%8F%E8%A7%88%E5%99%A8%E8%87%AA%E5%8A%A8%E7%99%BB%E5%BD%95">selenium实现浏览器自动登录</a></li><li><a href="#zabbix-%E8%87%AA%E5%8A%A8%E7%99%BB%E5%BD%95%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B">zabbix 自动登录代码示例</a></li></ul></p><h2><span id="什么是webdriver"> 什么是Webdriver？</span></h2><p>Selenium 2，又名 WebDriver，它的主要新功能是集成了 Selenium 1.0 以及 WebDriver（WebDriver 曾经是 Selenium 的竞争对手）。也就是说 Selenium 2 是 Selenium 和 WebDriver 两个项目的合并，即 Selenium 2 兼容 Selenium，它既支持 Selenium API 也支持 WebDriver API。   WebDriver是一个用来进行复杂重复的web自动化测试的工具。意在提供一种比Selenium1.0更简单易学，有利于维护的API。它没有和任何测试框架进行绑定，所以他可以很好的在单元测试和main方法中调用。一旦创建好一个Selenium工程，你马上会发现WebDriver和其他类库一样：它是完全独立的，你可以直接使用而不需要考虑其他配置，这个Selenium RC是截然相反的。</p><blockquote><p>以下在windows 平台实际操作，linux系统执行时没有无法调用firefox浏览器，测试失败。</p></blockquote><h2><span id="安装selenium"> 安装Selenium</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install selenium</span><br></pre></td></tr></table></figure><h2><span id="安装firefox浏览器"> 安装Firefox浏览器</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum install firefox -y</span><br><span class="line"></span><br><span class="line">windows下 安装 firefox浏览器</span><br></pre></td></tr></table></figure><h2><span id="安装firefox对应的webdriver驱动"> 安装firefox对应的webdriver（驱动）</span></h2><p><a href="https://github.com/mozilla/geckodriver/releases" target="_blank" rel="noopener">https://github.com/mozilla/geckodriver/releases</a><br>下载对应系统的版本。<br>windows64 下载https://github.com/mozilla/geckodriver/releases/download/v0.19.1/geckodriver-v0.19.1-win64.zip<br>解压放置于Firefox 安装目录，如 D:\Program Files\Mozilla Firefox<br>把 D:\Program Files\Mozilla Firefox 目录加入系统PATH。</p><h2><span id="实战"> 实战</span></h2><ol><li>从 selenium 导入 webdriver 库</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver</span><br></pre></td></tr></table></figure><ol start="2"><li>实例化一个浏览器</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">browser = webdriver.Firefox(executable_path = r&apos;D:\Program Files\Mozilla Firefox\geckodriver.exe&apos;)</span><br></pre></td></tr></table></figure><ol start="3"><li>执行浏览器操作，打开网址需要使用get方法</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">browser.get(url)</span><br></pre></td></tr></table></figure><p>对网页进行截图</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">browser.save_screenshot(imageNname)</span><br></pre></td></tr></table></figure><ol start="4"><li>关闭浏览器</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">browser.close()</span><br></pre></td></tr></table></figure><h2><span id="代码示例"> 代码示例</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"># Process by python27</span><br><span class="line">#!/bin/env python</span><br><span class="line"></span><br><span class="line">import time</span><br><span class="line">from selenium import webdriver</span><br><span class="line">def screen_shot( driver, url ):</span><br><span class="line">    driver.get(url)</span><br><span class="line">    #等待10s,否则动态页面可能未加载完成</span><br><span class="line">    time.sleep(10)</span><br><span class="line">    driver.save_screenshot(&apos;home.png&apos;)</span><br><span class="line">    driver.close()</span><br><span class="line">if __name__  ==  &quot;__main__&quot;:</span><br><span class="line">    browser = webdriver.Firefox(executable_path = r&apos;D:\Program Files\Mozilla Firefox\geckodriver.exe&apos;)</span><br><span class="line">    browser.set_window_size(1710, 4250)</span><br><span class="line">    screen_shot(browser, &apos;http://domain/monitor/monitor.html&apos;)</span><br></pre></td></tr></table></figure><h2><span id="selenium实现浏览器自动登录"> selenium实现浏览器自动登录</span></h2><ol><li>打开网址需要使用get方法</li><li>获取元素<br>元素的方法有很多种：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">find_element_by_id</span><br><span class="line">find_element_by_name</span><br><span class="line">find_element_by_xpath</span><br><span class="line">find_element_by_link_text</span><br><span class="line">find_element_by_partial_link_text</span><br><span class="line">find_element_by_tag_name</span><br><span class="line">find_element_by_class_name</span><br><span class="line">find_element_by_css_selector</span><br></pre></td></tr></table></figure><p>右键登录按钮，点击检查元素，我们就可以定位到元素了<br>以下三个元素分别对应name，password，enter</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;input type=&quot;text&quot; id=&quot;name&quot; name=&quot;name&quot; value=&quot;&quot; maxlength=&quot;255&quot; autofocus=&quot;autofocus&quot;&gt;</span><br><span class="line">&lt;input type=&quot;password&quot; id=&quot;password&quot; name=&quot;password&quot; value=&quot;&quot; maxlength=&quot;255&quot;&gt;</span><br><span class="line">&lt;button type=&quot;submit&quot; id=&quot;enter&quot; name=&quot;enter&quot; value=&quot;Sign in&quot;&gt;Sign in&lt;/button&gt;</span><br></pre></td></tr></table></figure><p>可以查看到他有着name属性，id属性<br>定位元素的方法多种多样，没有规定一定要用哪一种，适合即可。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">name = browser.find_element_by_name(&quot;name&quot;)</span><br><span class="line">#亦或者</span><br><span class="line">name = browser.find_element_by_id(&quot;name&quot;)</span><br></pre></td></tr></table></figure><p>于是乎，我们已经定位到账号的输入框了。<br>接下来是输入内容，输入内容可以使用send_keys的方法</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">name.send_keys(&quot;hello&quot;)</span><br></pre></td></tr></table></figure><p>运行试试看，我们会发现已经成功在输入框中输入我们所要的内容。<br>同理我们可以定位到密码框</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">passwd = browser.find_element_by_name(&quot;password&quot;)</span><br></pre></td></tr></table></figure><p>以及往里面填充内容</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">passwd.send_keys(&quot;hello&quot;)</span><br></pre></td></tr></table></figure><p>输入完账号密码，最后一步便是点击登录按钮了</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">login_button = browser.find_element_by_id(&quot;enter&quot;)</span><br><span class="line">login_button.click()</span><br></pre></td></tr></table></figure><h2><span id="zabbix-自动登录代码示例"> zabbix 自动登录代码示例</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">def login_web(driver, url ,):</span><br><span class="line">    driver.get(url)</span><br><span class="line">    Username = driver.find_element_by_name(&quot;name&quot;)</span><br><span class="line">    Username.send_keys(&quot;name&quot;)</span><br><span class="line">    Password = driver.find_element_by_name(&quot;password&quot;)</span><br><span class="line">    Password.send_keys(&quot;#password&quot;)</span><br><span class="line">    login_button = driver.find_element_by_id(&quot;enter&quot;)</span><br><span class="line">    login_button.click()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;Selenium 是什么？一句话，自动化测试工具。它支持各种浏览器，包括 Chrome，Safari，Firefox 等主流界面式浏览器，如果你在这些浏览器里面安装一个 Selenium 的插件，那么便可以方便地实现Web界面的测试。换句话说叫 S
      
    
    </summary>
    
      <category term="python" scheme="yunke.science/categories/python/"/>
    
    
      <category term="python" scheme="yunke.science/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>Lua模块的包管理器LuaRocks</title>
    <link href="yunke.science/2018/01/03/Lua-LuaRocks/"/>
    <id>yunke.science/2018/01/03/Lua-LuaRocks/</id>
    <published>2018-01-03T05:40:23.000Z</published>
    <updated>2018-01-03T05:44:51.228Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>LuaRocks是Lua模块的包管理器。<br>它允许你创建和安装Lua模块，作为独立包名为rocks。 您可以在Unix和Windows上下载并安装LuaRocks。<br>LuaRocks是免费软件，使用与Lua相同的许可证。</p></blockquote><p><ul class="markdownIt-TOC"><li><a href="#linux%E7%B3%BB%E7%BB%9F%E4%B8%8B%E5%AE%89%E8%A3%85">linux系统下安装</a><ul><li><a href="#%E7%AE%80%E5%8D%95%E5%AE%89%E8%A3%85">简单安装</a></li><li><a href="#openresty-%E5%AE%89%E8%A3%85-luarocks-%E7%A4%BA%E4%BE%8B">openresty 安装 luarocks 示例</a></li></ul></li><li><a href="#%E5%9C%A8-openresty-%E4%B8%AD%E4%BD%BF%E7%94%A8-luarocks">在 OpenResty 中使用 LuaRocks</a><ul><li><a href="#%E5%AE%89%E8%A3%85-luarocks">安装 LuaRocks</a></li><li><a href="#%E9%80%9A%E8%BF%87-luarocks%E5%AE%89%E8%A3%85-lua-md5-%E5%BA%93">通过 LuaRocks安装 Lua MD5 库</a></li><li><a href="#%E9%85%8D%E7%BD%AE%E6%88%91%E4%BB%AC%E7%9A%84-openresty-%E5%BA%94%E7%94%A8">配置我们的 OpenResty 应用</a></li><li><a href="#%E5%BC%80%E5%90%AF-nginx-%E6%9C%8D%E5%8A%A1">开启 Nginx 服务</a></li><li><a href="#%E6%B5%8B%E8%AF%95%E6%88%91%E4%BB%AC%E7%9A%84%E5%BA%94%E7%94%A8">测试我们的应用</a></li></ul></li></ul></p><p>官方 ：<a href="https://luarocks.org/" target="_blank" rel="noopener">https://luarocks.org/</a></p><h2><span id="linux系统下安装"> linux系统下安装</span></h2><p>安装包列表：<br><a href="http://luarocks.github.io/luarocks/releases/" target="_blank" rel="noopener">http://luarocks.github.io/luarocks/releases/</a></p><h3><span id="简单安装"> 简单安装</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ wget https://luarocks.org/releases/luarocks-2.4.3.tar.gz</span><br><span class="line">$ tar zxpf luarocks-2.4.3.tar.gz</span><br><span class="line">$ cd luarocks-2.4.3</span><br><span class="line">$ ./configure; sudo make bootstrap</span><br><span class="line">$ sudo luarocks install luasocket</span><br><span class="line">$ lua</span><br><span class="line">Lua 5.3.4 Copyright (C) 1994-2017 Lua.org, PUC-Rio</span><br><span class="line">&gt; require &quot;socket&quot;</span><br></pre></td></tr></table></figure><p>设置prefix会自动将Luarocks以及往后使用Luarocks安装的Lua包，LuaC包都安装到Luarocks安装路径下的相应位置，否则相关的包文件散落在文件系统中，显得杂乱不便于管理。<br>如果所安装的Lua模板包含bin文件，则会自动安装到此目录下的bin路径，与Luarocks可执行文件同一路径，更便于管理、使用。</p><h3><span id="openresty-安装-luarocks-示例"> openresty 安装 luarocks 示例</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">tar xzf luarocks-$&#123;RESTY_LUAROCKS_VERSION&#125;.tar.gz</span><br><span class="line">cd luarocks-$&#123;RESTY_LUAROCKS_VERSION&#125;</span><br><span class="line">./configure \</span><br><span class="line"> --prefix=/usr/local/openresty/luajit \</span><br><span class="line"> --with-lua=/usr/local/openresty/luajit \</span><br><span class="line"> --lua-suffix=jit-2.1.0-beta3 \</span><br><span class="line"> --with-lua-include=/usr/local/openresty/luajit/include/luajit-2.1</span><br><span class="line">make build</span><br><span class="line">make install</span><br></pre></td></tr></table></figure><h2><span id="在-openresty-中使用-luarocks"> 在 OpenResty 中使用 LuaRocks</span></h2><p><a href="https://openresty.org/cn/using-luarocks.html" target="_blank" rel="noopener">https://openresty.org/cn/using-luarocks.html</a></p><h3><span id="安装-luarocks"> 安装 LuaRocks</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">wget http://luarocks.org/releases/luarocks-2.0.4.1.tar.gz</span><br><span class="line">tar -xzvf luarocks-2.0.4.1.tar.gz</span><br><span class="line">cd luarocks-2.0.4.1/</span><br><span class="line">./configure</span><br><span class="line">make</span><br><span class="line">sudo make install</span><br></pre></td></tr></table></figure><h3><span id="通过-luarocks安装-lua-md5-库"> 通过 LuaRocks安装 Lua MD5 库</span></h3><p>在本示例中, 我们将使用 Lua MD5 library 作为服务器上的一个例子, 所以我们需要通过 LuaRocks 来安装它:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo luarocks install md5</span><br></pre></td></tr></table></figure><h3><span id="配置我们的-openresty-应用"> 配置我们的 OpenResty 应用</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/openresty/nginx/</span><br></pre></td></tr></table></figure><p>编辑 conf/nginx.conf 文件:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">worker_processes  1;   # we could enlarge this setting on a multi-core machine</span><br><span class="line">error_log  logs/error.log warn;</span><br><span class="line"></span><br><span class="line">events &#123;</span><br><span class="line">    worker_connections  1024;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">http &#123;</span><br><span class="line">    lua_package_path &apos;conf/?.lua;;&apos;;</span><br><span class="line"></span><br><span class="line">    server &#123;</span><br><span class="line">        listen       80;</span><br><span class="line">        server_name  localhost;</span><br><span class="line"></span><br><span class="line">        location = /luarocks &#123;</span><br><span class="line">            content_by_lua &apos;</span><br><span class="line">                local foo = require(&quot;foo&quot;)</span><br><span class="line">                foo.say(&quot;hello, luarocks!&quot;)</span><br><span class="line">            &apos;;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最后,我们创建下面两个 Lua 模块文件 conf/foo.lua</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">-- conf/foo.lua</span><br><span class="line"></span><br><span class="line">module(&quot;foo&quot;, package.seeall)</span><br><span class="line"></span><br><span class="line">local bar = require &quot;bar&quot;</span><br><span class="line"></span><br><span class="line">ngx.say(&quot;bar loaded&quot;)</span><br><span class="line"></span><br><span class="line">function say (var)</span><br><span class="line">    bar.say(var)</span><br><span class="line">end</span><br></pre></td></tr></table></figure><p>和 conf/bar.lua 文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">-- conf/bar.lua</span><br><span class="line"></span><br><span class="line">module(&quot;bar&quot;, package.seeall)</span><br><span class="line"></span><br><span class="line">local rocks = require &quot;luarocks.loader&quot;</span><br><span class="line">local md5 = require &quot;md5&quot;</span><br><span class="line"></span><br><span class="line">ngx.say(&quot;rocks and md5 loaded&quot;)</span><br><span class="line"></span><br><span class="line">function say (a)</span><br><span class="line">    ngx.say(md5.sumhexa(a))</span><br><span class="line">end</span><br></pre></td></tr></table></figure><h3><span id="开启-nginx-服务"> 开启 Nginx 服务</span></h3><p>现在我们通过 Nginx 开启我们的应用:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ulimit -n1024   # increase the maximal fd count limit per process</span><br><span class="line">./sbin/nginx</span><br></pre></td></tr></table></figure><p>如果您已经开启了 Nginx 服务,请先关闭后在重新开启:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./sbin/nginx -s stop  #（译注:我们也可以使用平滑重启命令完成此操作 ./sbin/nginx -s reload）</span><br></pre></td></tr></table></figure><h3><span id="测试我们的应用"> 测试我们的应用</span></h3><p>现在我们通过curl 工具或者任意兼容HTTP协议的浏览器测试我们的应用:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl http://localhost/luarocks</span><br></pre></td></tr></table></figure><p>我们在第一次运行的时候得到以下的内容:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rocks and md5 loaded</span><br><span class="line">bar loaded</span><br><span class="line">85e73df5c41378f830c031b81e4453d2</span><br></pre></td></tr></table></figure><p>第二次运行的时候得到以下内容:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">85e73df5c41378f830c031b81e4453d2</span><br></pre></td></tr></table></figure><p>之所以会出现这样的输出数据是因为 Lua Nginx Module 默认缓存了已经加载过的Lua模块 并且这些输出数据的代码是在 Lua 加载时运行的因此他们将不会在执行.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;LuaRocks是Lua模块的包管理器。&lt;br&gt;
它允许你创建和安装Lua模块，作为独立包名为rocks。 您可以在Unix和Windows上下载并安装LuaRocks。&lt;br&gt;
LuaRocks是免费软件，使用与Lua相同的许可证。&lt;/p&gt;
&lt;/
      
    
    </summary>
    
      <category term="nginx" scheme="yunke.science/categories/nginx/"/>
    
    
      <category term="nginx" scheme="yunke.science/tags/nginx/"/>
    
      <category term="openresty" scheme="yunke.science/tags/openresty/"/>
    
      <category term="LuaRocks" scheme="yunke.science/tags/LuaRocks/"/>
    
  </entry>
  
  <entry>
    <title>docker-crond</title>
    <link href="yunke.science/2017/12/29/docker-crond/"/>
    <id>yunke.science/2017/12/29/docker-crond/</id>
    <published>2017-12-29T01:51:39.000Z</published>
    <updated>2018-01-03T05:43:31.259Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>容器技术给我们带来极大便利的同时也带来一些必须要做的改变，比如以前在应用服务器中运行的cron定时任务就不能用原有的方式运行。<br>本文基于 alpine ，介绍如何解决使用容器技术时的定时任务问题。</p></blockquote><p><ul class="markdownIt-TOC"><li><a href="#dcoekrfile">Dcoekrfile</a></li><li><a href="#%E7%BC%96%E8%AF%91docker%E9%95%9C%E5%83%8F">编译docker镜像</a></li><li><a href="#%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1">定时任务</a></li></ul></p><h2><span id="dcoekrfile"> Dcoekrfile</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">FROM alpine:3.6</span><br><span class="line">RUN apk -v --update add \</span><br><span class="line">        groff \</span><br><span class="line">        less \</span><br><span class="line">        mailcap \</span><br><span class="line">        dcron \</span><br><span class="line">        bash \</span><br><span class="line">        tzdata \</span><br><span class="line">        unzip \</span><br><span class="line">        &amp;&amp; \</span><br><span class="line">    apk -v --purge del py-pip &amp;&amp; \</span><br><span class="line">    rm /var/cache/apk/*</span><br><span class="line">RUN cp -f  /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span><br><span class="line">CMD [&quot;su&quot;, &quot;-c&quot;, &quot;/usr/sbin/crond -l 2 -f&quot;]</span><br></pre></td></tr></table></figure><h2><span id="编译docker镜像"> 编译docker镜像</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"># docker build -t crond ./</span><br><span class="line">Sending build context to Docker daemon  2.048kB</span><br><span class="line">Step 1/4 : FROM alpine:3.6</span><br><span class="line"> ---&gt; e2cd449cde75</span><br><span class="line">Step 2/4 : RUN apk -v --update add         groff         less         mailcap         dcron         bash         tzdata         unzip         &amp;&amp;     apk -v --purge del py-pip &amp;&amp;     rm /var/cache/apk/*</span><br><span class="line"> ---&gt; Running in ccb510bb91a6</span><br><span class="line">fetch http://dl-cdn.alpinelinux.org/alpine/v3.6/main/x86_64/APKINDEX.tar.gz</span><br><span class="line">fetch http://dl-cdn.alpinelinux.org/alpine/v3.6/community/x86_64/APKINDEX.tar.gz</span><br><span class="line">(1/13) Installing ncurses-terminfo-base (6.0_p20170930-r0)</span><br><span class="line">(2/13) Installing ncurses-terminfo (6.0_p20170930-r0)</span><br><span class="line">(3/13) Installing ncurses-libs (6.0_p20170930-r0)</span><br><span class="line">(4/13) Installing readline (6.3.008-r5)</span><br><span class="line">(5/13) Installing bash (4.3.48-r1)</span><br><span class="line">Executing bash-4.3.48-r1.post-install</span><br><span class="line">(6/13) Installing dcron (4.5-r3)</span><br><span class="line">(7/13) Installing libgcc (6.3.0-r4)</span><br><span class="line">(8/13) Installing libstdc++ (6.3.0-r4)</span><br><span class="line">(9/13) Installing groff (1.22.3-r1)</span><br><span class="line">(10/13) Installing less (487-r0)</span><br><span class="line">(11/13) Installing mailcap (2.1.47-r0)</span><br><span class="line">(12/13) Installing tzdata (2017a-r0)</span><br><span class="line">(13/13) Installing unzip (6.0-r2)</span><br><span class="line">Executing busybox-1.26.2-r9.trigger</span><br><span class="line">OK: 24 packages, 210 dirs, 4442 files, 26 MiB</span><br><span class="line">OK: 24 packages, 210 dirs, 4442 files, 26 MiB</span><br><span class="line"> ---&gt; bf766a50b13b</span><br><span class="line">Removing intermediate container ccb510bb91a6</span><br><span class="line">Step 3/4 : RUN cp -f  /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span><br><span class="line"> ---&gt; Running in df6b2d6df1fd</span><br><span class="line"> ---&gt; 814dc03e94dc</span><br><span class="line">Removing intermediate container df6b2d6df1fd</span><br><span class="line">Step 4/4 : CMD su -c /usr/sbin/crond -l 2 -f</span><br><span class="line"> ---&gt; Running in 933ea5993fdf</span><br><span class="line"> ---&gt; 71fa188657eb</span><br><span class="line">Removing intermediate container 933ea5993fdf</span><br><span class="line">Successfully built 71fa188657eb</span><br><span class="line">Successfully tagged crond:latest</span><br></pre></td></tr></table></figure><h2><span id="定时任务"> 定时任务</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">定时任务添加到文件：/etc/crontabs/root</span><br><span class="line"></span><br><span class="line"># cat /etc/crontabs/root </span><br><span class="line">* * * * * echo $(date) &gt;&gt; /tmp/time</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;容器技术给我们带来极大便利的同时也带来一些必须要做的改变，比如以前在应用服务器中运行的cron定时任务就不能用原有的方式运行。&lt;br&gt;
本文基于 alpine ，介绍如何解决使用容器技术时的定时任务问题。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;
      
    
    </summary>
    
      <category term="docker" scheme="yunke.science/categories/docker/"/>
    
    
      <category term="docker" scheme="yunke.science/tags/docker/"/>
    
      <category term="crond" scheme="yunke.science/tags/crond/"/>
    
      <category term="alpine" scheme="yunke.science/tags/alpine/"/>
    
  </entry>
  
  <entry>
    <title>宝妈语录</title>
    <link href="yunke.science/2017/12/22/MomQuotations/"/>
    <id>yunke.science/2017/12/22/MomQuotations/</id>
    <published>2017-12-22T14:23:16.000Z</published>
    <updated>2017-12-29T01:57:40.695Z</updated>
    
    <content type="html"><![CDATA[<p>听妈妈的话 别让她受伤 想快快长大 才能保护她</p><img src="/2017/12/22/MomQuotations/BingWallpaper-2017-12-22.jpg" title="天青色等烟雨"><ul><li>妈妈说，电视回家吃饭去了，等吃完饭了才能看。 --2017-12-22</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;听妈妈的话 别让她受伤 想快快长大 才能保护她&lt;/p&gt;
&lt;img src=&quot;/2017/12/22/MomQuotations/BingWallpaper-2017-12-22.jpg&quot; title=&quot;天青色等烟雨&quot;&gt;
&lt;ul&gt;
&lt;li&gt;妈妈说，电视回家吃饭去了，等吃完饭了
      
    
    </summary>
    
      <category term="其他" scheme="yunke.science/categories/%E5%85%B6%E4%BB%96/"/>
    
    
      <category term="love" scheme="yunke.science/tags/love/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="yunke.science/2017/12/20/hello-world/"/>
    <id>yunke.science/2017/12/20/hello-world/</id>
    <published>2017-12-20T09:01:34.000Z</published>
    <updated>2017-12-29T01:57:22.569Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2><span id="quick-start"> Quick Start</span></h2><h3><span id="create-a-new-post"> Create a new post</span></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3><span id="run-server"> Run server</span></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3><span id="generate-static-files"> Generate static files</span></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3><span id="deploy-to-remote-sites"> Deploy to remote sites</span></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
      <category term="其他" scheme="yunke.science/categories/%E5%85%B6%E4%BB%96/"/>
    
    
  </entry>
  
  <entry>
    <title>Alpine Linux 教程和 Howtos</title>
    <link href="yunke.science/2017/12/20/Alpine-Tutorials/"/>
    <id>yunke.science/2017/12/20/Alpine-Tutorials/</id>
    <published>2017-12-20T07:16:25.000Z</published>
    <updated>2017-12-29T02:02:41.026Z</updated>
    
    <content type="html"><![CDATA[<p>欢迎来到教程和Howtos，这是您的Alpine Linux的基本和高级配置任务。<br>这些教程是亲身实践的，读者可以借助一个很好的例子尝试实现每一步中描述的目标。 一步输出是下一步的起点。<br>这些小文章解释了如何使用Alpine Linux来执行特定的任务。<br><a href="https://wiki.alpinelinux.org/wiki/Tutorials_and_Howtos" target="_blank" rel="noopener">https://wiki.alpinelinux.org/wiki/Tutorials_and_Howtos</a></p><p><ul class="markdownIt-TOC"><li><a href="#%E5%AD%98%E5%82%A8">存储</a><ul><li><a href="#%E4%BD%BF%E7%94%A8lvm%E8%AE%BE%E7%BD%AE%E9%80%BB%E8%BE%91%E5%8D%B7">使用LVM设置逻辑卷</a></li></ul></li><li><a href="#%E8%81%94%E7%BD%91">联网</a></li><li><a href="#%E5%AE%89%E8%A3%85%E5%90%8E">安装后</a></li><li><a href="#%E8%99%9A%E6%8B%9F%E5%8C%96">虚拟化</a></li><li><a href="#%E6%A1%8C%E9%9D%A2%E7%8E%AF%E5%A2%83">桌面环境</a></li><li><a href="#%E5%BA%94%E7%94%A8">应用</a><ul><li><a href="#%E9%82%AE%E4%BB%B6">邮件</a></li><li><a href="#http">HTTP</a></li><li><a href="#%E5%85%B6%E4%BB%96%E6%9C%8D%E5%8A%A1%E5%99%A8">其他服务器</a></li><li><a href="#%E7%9B%91%E6%8E%A7">监控</a></li><li><a href="#%E5%AE%8C%E6%95%B4%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88">完整解决方案</a></li></ul></li></ul></p><h2><span id="存储"> 存储</span></h2><h3><span id="使用lvm设置逻辑卷"> 使用LVM设置逻辑卷</span></h3><p><a href="https://wiki.alpinelinux.org/wiki/Setting_up_Logical_Volumes_with_LVM" target="_blank" rel="noopener">https://wiki.alpinelinux.org/wiki/Setting_up_Logical_Volumes_with_LVM</a></p><blockquote><p>本文档介绍如何使用lvm2在Alpine中创建逻辑卷。<br>LVM是程序的集合，允许将更大的物理磁盘重新组合成“逻辑”磁盘，随着数据需求的变化，这些磁盘可以收缩或扩展。<br>在本文档中，我们将使用软件RAID1设备作为逻辑卷的物理存储。 我们将为vserver设置一个交换分区和一个数据分区</p></blockquote><p>加载内核驱动 dm-mod , 配置重启时被加载，添加 用户空间程序</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">modprobe dm-mod</span><br><span class="line"></span><br><span class="line">echo dm-mod &gt;&gt; /etc/modules</span><br><span class="line"></span><br><span class="line">apk add lvm2</span><br></pre></td></tr></table></figure><p>准备物理磁盘，创建物理卷，卷组，逻辑卷</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">pvcreate /dev/md0</span><br><span class="line"></span><br><span class="line">vgcreate vg0 /dev/md0</span><br><span class="line"></span><br><span class="line">lvcreate -n swap -L 1G vg0</span><br><span class="line">lvcreate -n vservers -L 6G vg0</span><br></pre></td></tr></table></figure><p>Display Logical Volumes</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lvdisplay</span><br></pre></td></tr></table></figure><p>Rename Logical Volumes</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lvrename /dev/vg0/vservers /dev/vg0/database</span><br></pre></td></tr></table></figure><p>Extend Logical Volumes</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">在原有基础上增加 50G</span><br><span class="line">lvextend -L +50G /dev/vg0/vservers</span><br><span class="line">将空间设置为 10G</span><br><span class="line">lvextend -L 10G /dev/vg0/vservers</span><br></pre></td></tr></table></figure><p>Start LVM during Boot<br>我们希望lvm在启动时启动逻辑卷。 有一个名为lvm的引导服务来执行此操作。 如果您的卷在RAID上，请确保在mdadm-raid之后启动了/etc/init.d/lvm 。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rc-update add lvm</span><br><span class="line"></span><br><span class="line">Or, on Alpine Linux 1.8 or earlier:</span><br><span class="line">rc_add -s 12 -k lvm</span><br></pre></td></tr></table></figure><p>Setting up swap</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mkswap /dev/vg0/swap</span><br><span class="line"></span><br><span class="line">Add the following line to your /etc/fstab:</span><br><span class="line">/dev/vg0/swap   none            swap     sw    0 0</span><br></pre></td></tr></table></figure><p>Setting up /vservers partition<br>我们要为/ vserver设置一个XFS分区，创建文件系统。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">apk add xfsprogs</span><br><span class="line"></span><br><span class="line">Create filesystem on /dev/vg0/vservers.</span><br><span class="line">mkfs.xfs /dev/vg0/vservers</span><br><span class="line"></span><br><span class="line">将挂载信息添加到/ etc / fstab中：</span><br><span class="line">/dev/vg0/vservers /vservers     xfs     noatime,tagxid 0 0</span><br></pre></td></tr></table></figure><p>Starting localmount and swap<br>确保我们在启动时也运行localmount ，并且在lvm之后完成。 在Alpine Linux 1.9及更高版本中，这不再需要</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mount /vservers</span><br></pre></td></tr></table></figure><p>启动交换服务，并确保它在下次重启时启动，并在 lvm 之后启动。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/etc/init.d/swap start rc-update add swap</span><br></pre></td></tr></table></figure><h2><span id="联网"> 联网</span></h2><h2><span id="安装后"> 安装后</span></h2><h2><span id="虚拟化"> 虚拟化</span></h2><h2><span id="桌面环境"> 桌面环境</span></h2><h2><span id="应用"> 应用</span></h2><h3><span id="邮件"> 邮件</span></h3><h3><span id="http"> HTTP</span></h3><h3><span id="其他服务器"> 其他服务器</span></h3><h3><span id="监控"> 监控</span></h3><h3><span id="完整解决方案"> 完整解决方案</span></h3>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;欢迎来到教程和Howtos，这是您的Alpine Linux的基本和高级配置任务。&lt;br&gt;
这些教程是亲身实践的，读者可以借助一个很好的例子尝试实现每一步中描述的目标。 一步输出是下一步的起点。&lt;br&gt;
这些小文章解释了如何使用Alpine Linux来执行特定的任务。&lt;b
      
    
    </summary>
    
    
  </entry>
  
</feed>
